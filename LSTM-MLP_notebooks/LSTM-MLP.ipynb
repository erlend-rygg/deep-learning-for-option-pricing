{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and Biases\n",
    "!pip install -q wandb\n",
    "# Tensorflow\n",
    "!pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 11:05:02.705446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, Concatenate, Dense, BatchNormalization, LeakyReLU\n",
    "from keras.activations import tanh\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tensorflow import square, reduce_mean\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.math import multiply\n",
    "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvinje\u001b[0m (\u001b[33mavogadro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/hjalmarjacobvinje/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If running in colab, insert your wandb key here\n",
    "\n",
    "import config\n",
    "#Erlend\n",
    "#wandb.login(key=config.erlend_key)\n",
    "# Hjalmar\n",
    "wandb.login(key=config.hjalmar_key)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, split and normalize data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Quote_date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Underlying_last</th>\n",
       "      <th>Strike</th>\n",
       "      <th>TTM</th>\n",
       "      <th>R</th>\n",
       "      <th>Moneyness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6701729</td>\n",
       "      <td>6701729</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1755.645</td>\n",
       "      <td>3258.14</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.172093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6701730</td>\n",
       "      <td>6701730</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1655.955</td>\n",
       "      <td>3258.14</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.036338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6701731</td>\n",
       "      <td>6701731</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1556.195</td>\n",
       "      <td>3258.14</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.916553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6701732</td>\n",
       "      <td>6701732</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1456.210</td>\n",
       "      <td>3258.14</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.810078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6701733</td>\n",
       "      <td>6701733</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1406.200</td>\n",
       "      <td>3258.14</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.761157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185540</th>\n",
       "      <td>12459146</td>\n",
       "      <td>12459146</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>415.150</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.853291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185541</th>\n",
       "      <td>12459147</td>\n",
       "      <td>12459147</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>375.050</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.834741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185542</th>\n",
       "      <td>12459148</td>\n",
       "      <td>12459148</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>337.350</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.816981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185543</th>\n",
       "      <td>12459149</td>\n",
       "      <td>12459149</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>302.650</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.799960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185544</th>\n",
       "      <td>12459150</td>\n",
       "      <td>12459150</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>270.450</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.783635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5185545 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0.1  Unnamed: 0  Quote_date     Price  Underlying_last  \\\n",
       "0             6701729     6701729  2020-01-02  1755.645          3258.14   \n",
       "1             6701730     6701730  2020-01-02  1655.955          3258.14   \n",
       "2             6701731     6701731  2020-01-02  1556.195          3258.14   \n",
       "3             6701732     6701732  2020-01-02  1456.210          3258.14   \n",
       "4             6701733     6701733  2020-01-02  1406.200          3258.14   \n",
       "...               ...         ...         ...       ...              ...   \n",
       "5185540      12459146    12459146  2022-12-30   415.150          3839.81   \n",
       "5185541      12459147    12459147  2022-12-30   375.050          3839.81   \n",
       "5185542      12459148    12459148  2022-12-30   337.350          3839.81   \n",
       "5185543      12459149    12459149  2022-12-30   302.650          3839.81   \n",
       "5185544      12459150    12459150  2022-12-30   270.450          3839.81   \n",
       "\n",
       "         Strike   TTM     R  Moneyness  \n",
       "0        1500.0     1  1.53   2.172093  \n",
       "1        1600.0     1  1.53   2.036338  \n",
       "2        1700.0     1  1.53   1.916553  \n",
       "3        1800.0     1  1.53   1.810078  \n",
       "4        1850.0     1  1.53   1.761157  \n",
       "...         ...   ...   ...        ...  \n",
       "5185540  4500.0  1085  4.22   0.853291  \n",
       "5185541  4600.0  1085  4.22   0.834741  \n",
       "5185542  4700.0  1085  4.22   0.816981  \n",
       "5185543  4800.0  1085  4.22   0.799960  \n",
       "5185544  4900.0  1085  4.22   0.783635  \n",
       "\n",
       "[5185545 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "google_colab = False\n",
    "\n",
    "if google_colab:\n",
    "    import tensorflow as tf\n",
    "    # Pring info\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "        print('Not connected to a GPU')\n",
    "    else:\n",
    "        print(gpu_info)\n",
    "    \n",
    "    from psutil import virtual_memory\n",
    "    ram_gb = virtual_memory().total / 1e9\n",
    "    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "    if ram_gb < 20:\n",
    "        print('Not using a high-RAM runtime')\n",
    "    else:\n",
    "        print('You are using a high-RAM runtime!')\n",
    "\n",
    "    # Code to read csv file into Colaboratory:\n",
    "    !pip install -U -q PyDrive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    # Authenticate and create the PyDrive client.\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "    id = \"16SwdE7VcT6UCzVNQmtOM3914nwWJMOmN\"\n",
    "    downloaded = drive.CreateFile({'id':id}) \n",
    "    downloaded.GetContentFile('2020_2022_moneyness_filtere.csv')  \n",
    "    df_read = pd.read_csv('2020_2022_moneyness_filtere.csv')\n",
    "else:\n",
    "    file = \"../data/processed_data/2020_2022_moneyness_filtere.csv\"\n",
    "    df_read = pd.read_csv(file)\n",
    "\n",
    "display(df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_read\n",
    "del df_read\n",
    "\n",
    "# Group the data by Quote Date and calculate the mean for Underlying Price\n",
    "df_agg = df.groupby('Quote_date').mean().reset_index()\n",
    "\n",
    "# Values to returns\n",
    "df_agg[\"Underlying_return\"] = df_agg[\"Underlying_last\"].pct_change()\n",
    "\n",
    "lags = 90\n",
    "\n",
    "# Add the Underlying Price Lag column\n",
    "for i in range(1, lags + 1):\n",
    "    df_agg['Underlying_' + str(i)] = df_agg['Underlying_return'].shift(i)\n",
    "\n",
    "df = pd.merge(df, df_agg[['Quote_date', \"Underlying_return\"] + ['Underlying_' + str(i) for i in range(1, lags + 1)]], on='Quote_date', how='left')\n",
    "\n",
    "# Filter df between 2021-01-01 and 2022-12-31\n",
    "df = df[(df[\"Quote_date\"] >= \"2021-01-01\") & (df[\"Quote_date\"] <= \"2022-12-31\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Quote_date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Underlying_last</th>\n",
       "      <th>Strike</th>\n",
       "      <th>TTM</th>\n",
       "      <th>R</th>\n",
       "      <th>Moneyness</th>\n",
       "      <th>Underlying_return</th>\n",
       "      <th>...</th>\n",
       "      <th>Underlying_81</th>\n",
       "      <th>Underlying_82</th>\n",
       "      <th>Underlying_83</th>\n",
       "      <th>Underlying_84</th>\n",
       "      <th>Underlying_85</th>\n",
       "      <th>Underlying_86</th>\n",
       "      <th>Underlying_87</th>\n",
       "      <th>Underlying_88</th>\n",
       "      <th>Underlying_89</th>\n",
       "      <th>Underlying_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1532925</th>\n",
       "      <td>8400702</td>\n",
       "      <td>8400702</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2002.205</td>\n",
       "      <td>3701.38</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.177282</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034736</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532926</th>\n",
       "      <td>8400703</td>\n",
       "      <td>8400703</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>1902.150</td>\n",
       "      <td>3701.38</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.056322</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034736</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532927</th>\n",
       "      <td>8400704</td>\n",
       "      <td>8400704</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>1801.895</td>\n",
       "      <td>3701.38</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.948095</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034736</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532928</th>\n",
       "      <td>8400705</td>\n",
       "      <td>8400705</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>1701.855</td>\n",
       "      <td>3701.38</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.850690</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034736</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532929</th>\n",
       "      <td>8400706</td>\n",
       "      <td>8400706</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>1602.055</td>\n",
       "      <td>3701.38</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.762562</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034736</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185540</th>\n",
       "      <td>12459146</td>\n",
       "      <td>12459146</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>415.150</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.853291</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>-0.003593</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.010776</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>-0.033678</td>\n",
       "      <td>0.014386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185541</th>\n",
       "      <td>12459147</td>\n",
       "      <td>12459147</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>375.050</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.834741</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>-0.003593</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.010776</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>-0.033678</td>\n",
       "      <td>0.014386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185542</th>\n",
       "      <td>12459148</td>\n",
       "      <td>12459148</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>337.350</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.816981</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>-0.003593</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.010776</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>-0.033678</td>\n",
       "      <td>0.014386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185543</th>\n",
       "      <td>12459149</td>\n",
       "      <td>12459149</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>302.650</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.799960</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>-0.003593</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.010776</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>-0.033678</td>\n",
       "      <td>0.014386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185544</th>\n",
       "      <td>12459150</td>\n",
       "      <td>12459150</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>270.450</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>1085</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.783635</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>-0.003593</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>-0.010776</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>-0.033678</td>\n",
       "      <td>0.014386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3652620 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0.1  Unnamed: 0  Quote_date     Price  Underlying_last  \\\n",
       "1532925       8400702     8400702  2021-01-04  2002.205          3701.38   \n",
       "1532926       8400703     8400703  2021-01-04  1902.150          3701.38   \n",
       "1532927       8400704     8400704  2021-01-04  1801.895          3701.38   \n",
       "1532928       8400705     8400705  2021-01-04  1701.855          3701.38   \n",
       "1532929       8400706     8400706  2021-01-04  1602.055          3701.38   \n",
       "...               ...         ...         ...       ...              ...   \n",
       "5185540      12459146    12459146  2022-12-30   415.150          3839.81   \n",
       "5185541      12459147    12459147  2022-12-30   375.050          3839.81   \n",
       "5185542      12459148    12459148  2022-12-30   337.350          3839.81   \n",
       "5185543      12459149    12459149  2022-12-30   302.650          3839.81   \n",
       "5185544      12459150    12459150  2022-12-30   270.450          3839.81   \n",
       "\n",
       "         Strike   TTM     R  Moneyness  Underlying_return  ...  Underlying_81  \\\n",
       "1532925  1700.0     2  0.09   2.177282          -0.014623  ...      -0.034736   \n",
       "1532926  1800.0     2  0.09   2.056322          -0.014623  ...      -0.034736   \n",
       "1532927  1900.0     2  0.09   1.948095          -0.014623  ...      -0.034736   \n",
       "1532928  2000.0     2  0.09   1.850690          -0.014623  ...      -0.034736   \n",
       "1532929  2100.0     2  0.09   1.762562          -0.014623  ...      -0.034736   \n",
       "...         ...   ...   ...        ...                ...  ...            ...   \n",
       "5185540  4500.0  1085  4.22   0.853291          -0.002300  ...       0.017866   \n",
       "5185541  4600.0  1085  4.22   0.834741          -0.002300  ...       0.017866   \n",
       "5185542  4700.0  1085  4.22   0.816981          -0.002300  ...       0.017866   \n",
       "5185543  4800.0  1085  4.22   0.799960          -0.002300  ...       0.017866   \n",
       "5185544  4900.0  1085  4.22   0.783635          -0.002300  ...       0.017866   \n",
       "\n",
       "         Underlying_82  Underlying_83  Underlying_84  Underlying_85  \\\n",
       "1532925       0.015046       0.007654      -0.002161       0.006698   \n",
       "1532926       0.015046       0.007654      -0.002161       0.006698   \n",
       "1532927       0.015046       0.007654      -0.002161       0.006698   \n",
       "1532928       0.015046       0.007654      -0.002161       0.006698   \n",
       "1532929       0.015046       0.007654      -0.002161       0.006698   \n",
       "...                ...            ...            ...            ...   \n",
       "5185540      -0.003593      -0.000262      -0.010776       0.003305   \n",
       "5185541      -0.003593      -0.000262      -0.010776       0.003305   \n",
       "5185542      -0.003593      -0.000262      -0.010776       0.003305   \n",
       "5185543      -0.003593      -0.000262      -0.010776       0.003305   \n",
       "5185544      -0.003593      -0.000262      -0.010776       0.003305   \n",
       "\n",
       "         Underlying_86  Underlying_87  Underlying_88  Underlying_89  \\\n",
       "1532925       0.001618       0.010257       0.003357       0.010258   \n",
       "1532926       0.001618       0.010257       0.003357       0.010258   \n",
       "1532927       0.001618       0.010257       0.003357       0.010258   \n",
       "1532928       0.001618       0.010257       0.003357       0.010258   \n",
       "1532929       0.001618       0.010257       0.003357       0.010258   \n",
       "...                ...            ...            ...            ...   \n",
       "5185540      -0.007857      -0.011077      -0.006737      -0.033678   \n",
       "5185541      -0.007857      -0.011077      -0.006737      -0.033678   \n",
       "5185542      -0.007857      -0.011077      -0.006737      -0.033678   \n",
       "5185543      -0.007857      -0.011077      -0.006737      -0.033678   \n",
       "5185544      -0.007857      -0.011077      -0.006737      -0.033678   \n",
       "\n",
       "         Underlying_90  \n",
       "1532925       0.003477  \n",
       "1532926       0.003477  \n",
       "1532927       0.003477  \n",
       "1532928       0.003477  \n",
       "1532929       0.003477  \n",
       "...                ...  \n",
       "5185540       0.014386  \n",
       "5185541       0.014386  \n",
       "5185542       0.014386  \n",
       "5185543       0.014386  \n",
       "5185544       0.014386  \n",
       "\n",
       "[3652620 rows x 100 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1655728, 90, 1), (1655728, 4)\n",
      "Val shape: (184525, 90, 1), (184525, 4)\n",
      "Test shape: (165072, 90, 1), (165072, 4)\n"
     ]
    }
   ],
   "source": [
    "# Format settings\n",
    "max_timesteps = lags\n",
    "moneyness = False\n",
    "bs_vars = ['Moneyness', 'TTM', 'R'] if moneyness else ['Underlying_last', 'Strike', 'TTM', 'R']\n",
    "underlying_lags = ['Underlying_last'] + [f'Underlying_{i}' for i in range (1, max_timesteps)]\n",
    "\n",
    "def create_rw_dataset(window_number = 0, df = df):\n",
    "    '''Creates dataset for a single rolling window period offsett by the window number'''\n",
    "\n",
    "    # Create train, validation and test set split points\n",
    "    train_start = datetime(2021,1,1) + relativedelta(months=window_number)\n",
    "    val_start = train_start + relativedelta(months=11) \n",
    "    test_start = val_start + relativedelta(months=1)\n",
    "    test_end = test_start + relativedelta(months=1)\n",
    "    train_start = str(train_start.date())\n",
    "    val_start = str(val_start.date())\n",
    "    test_start = str(test_start.date())\n",
    "    test_end = str(test_end.date())\n",
    "\n",
    "    # Split train and validation data\n",
    "    df_train = df[(df['Quote_date'] >= train_start) & (df['Quote_date'] < val_start)]\n",
    "    df_val = df[(df['Quote_date'] >= val_start) & (df['Quote_date'] < test_start)]\n",
    "    df_test = df[(df['Quote_date'] >= test_start) & (df['Quote_date'] < test_end)]\n",
    "\n",
    "    del df\n",
    "    # Extract target values\n",
    "    train_y = (df_train['Price'] / df_train['Strike']).to_numpy() if moneyness else df_train['Price'].to_numpy()\n",
    "    val_y = (df_val['Price'] / df_val['Strike']).to_numpy() if moneyness else df_val['Price'].to_numpy()\n",
    "    test_y = (df_test['Price'] / df_test['Strike']).to_numpy() if moneyness else df_test['Price'].to_numpy()\n",
    "\n",
    "    # If usining moneyness, extract strike\n",
    "    if moneyness:\n",
    "        train_strike = df_train['Strike'].to_numpy()\n",
    "        val_strike = df_val['Strike'].to_numpy()\n",
    "        test_strike = df_test['Strike'].to_numpy()\n",
    "\n",
    "    # Convert dataframes to numpy arrays\n",
    "    train_x = [df_train[underlying_lags].to_numpy(), df_train[bs_vars].to_numpy()]\n",
    "    val_x = [df_val[underlying_lags].to_numpy(), df_val[bs_vars].to_numpy()]\n",
    "    test_x = [df_test[underlying_lags].to_numpy(), df_test[bs_vars].to_numpy()]\n",
    "\n",
    "    del df_train\n",
    "    del df_val\n",
    "\n",
    "    # Scale features based on training set\n",
    "    underlying_scaler = MinMaxScaler()\n",
    "    train_x[0] = underlying_scaler.fit_transform(train_x[0])\n",
    "    val_x[0] = underlying_scaler.transform(val_x[0])\n",
    "    test_x[0] = underlying_scaler.transform(test_x[0])\n",
    "\n",
    "    bs_scaler = MinMaxScaler()\n",
    "    train_x[1] = bs_scaler.fit_transform(train_x[1])\n",
    "    val_x[1] = bs_scaler.transform(val_x[1])\n",
    "    test_x[1] = bs_scaler.transform(test_x[1])\n",
    "\n",
    "\n",
    "    # Shuffle training set\n",
    "    np.random.seed(0)\n",
    "    shuffle = np.random.permutation(len(train_x[0]))\n",
    "    train_x = [train_x[0][shuffle], train_x[1][shuffle]]\n",
    "    train_y = train_y[shuffle]\n",
    "    if moneyness:\n",
    "        train_strike = train_strike[shuffle]\n",
    "\n",
    "    # Reshape data to fit LSTM\n",
    "    train_x = [train_x[0].reshape(len(train_x[0]), max_timesteps, 1), train_x[1]]\n",
    "    val_x = [val_x[0].reshape(len(val_x[0]), max_timesteps, 1), val_x[1]]\n",
    "    test_x = [test_x[0].reshape(len(test_x[0]), max_timesteps, 1), test_x[1]]\n",
    "\n",
    "    print(f'Train shape: {train_x[0].shape}, {train_x[1].shape}')\n",
    "    print(f'Val shape: {val_x[0].shape}, {val_x[1].shape}')\n",
    "    print(f'Test shape: {test_x[0].shape}, {test_x[1].shape}')\n",
    "\n",
    "    if moneyness:\n",
    "        return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike,\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test\n",
    "\n",
    "# Create the dataset for the first rolling window period\n",
    "if moneyness:\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike = create_rw_dataset()\n",
    "else:\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config):\n",
    "    '''Builds an LSTM-MLP model of minimum 2 layers sequentially from a given config dictionary'''\n",
    "\n",
    "    # Input layers\n",
    "    underlying_history = Input((config.LSTM_timesteps,1))\n",
    "    bs_vars = Input((config.Num_features,))\n",
    "\n",
    "    # LSTM layers\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        units = config.LSTM_units,\n",
    "        activation = tanh,\n",
    "        input_shape = (config.LSTM_timesteps, 1),\n",
    "        return_sequences = True\n",
    "    ))\n",
    "\n",
    "    for _ in range(config.LSTM_layers - 2):\n",
    "        model.add(LSTM(\n",
    "            units = config.LSTM_units,\n",
    "            activation = tanh,\n",
    "            return_sequences = True\n",
    "        ))\n",
    "    \n",
    "    model.add(LSTM(\n",
    "        units = config.LSTM_units,\n",
    "        activation = tanh,\n",
    "        return_sequences = False\n",
    "    ))\n",
    "\n",
    "    # MLP layers\n",
    "    layers = Concatenate()([model(underlying_history), model(underlying_history), model(underlying_history), model(underlying_history), model(underlying_history), bs_vars])\n",
    "    \n",
    "    for _ in range(config.MLP_layers - 1):\n",
    "        layers = Dense(config.MLP_units)(layers)\n",
    "        layers = BatchNormalization(momentum=config.Bn_momentum)(layers)\n",
    "        layers = LeakyReLU()(layers)\n",
    "\n",
    "    output = Dense(1, activation='relu')(layers)\n",
    "\n",
    "    # Exponential decaying learning rate\n",
    "    lr_schedule = ExponentialDecay(\n",
    "        initial_learning_rate = config.Lr,\n",
    "        decay_steps = int(len(train_x[0])/config.Minibatch_size),\n",
    "        decay_rate=config.Lr_decay\n",
    "    )\n",
    "\n",
    "    # Compile model\n",
    "    model = Model(inputs=[underlying_history, bs_vars], outputs=output)\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=lr_schedule))\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Lr uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. Lr_decay uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: qdp3o069\n",
      "Sweep URL: https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20test%20area/sweeps/qdp3o069\n"
     ]
    }
   ],
   "source": [
    "# Configuring the sweep hyperparameter search space\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'name': 'LSTM-MLP v4.0: fix nan issue',\n",
    "    'metric': {\n",
    "        'goal': 'minimize', \n",
    "        'name': 'val_loss'\n",
    "\t\t},\n",
    "    'parameters': {\n",
    "        'LSTM_units': {\n",
    "            'values': [4, 8, 16, 32]},\n",
    "        'MLP_units': {\n",
    "            'values': [50, 100, 200, 400, 600]},\n",
    "        'LSTM_timesteps': {\n",
    "            'values': [10, 20, 40, 60, 90, 150]},\n",
    "        'LSTM_layers': {\n",
    "            'distribution': 'int_uniform',\n",
    "            'max': 8, 'min': 2},\n",
    "        'MLP_layers': {\n",
    "            'distribution': 'int_uniform',\n",
    "            'max': 8, 'min': 2},\n",
    "        'Bn_momentum': {\n",
    "            'values': [0.1, 0.4, 0.7, 0.99]},\n",
    "        'Lr': {\n",
    "            'distribution': 'log_uniform',\n",
    "            'max': log(0.1), 'min': log(0.0001)},\n",
    "        'Lr_decay': {\n",
    "            'distribution': 'log_uniform',\n",
    "            'max': log(1), 'min': log(0.8)},        \n",
    "        'Minibatch_size': {\n",
    "            'value': 4096},\n",
    "        'Min_delta': {\n",
    "            'value': 0.01 if moneyness else 1},\n",
    "        'Patience': {\n",
    "            'value': 20},\n",
    "        'Num_features': {\n",
    "            'value': 3 if moneyness else 4},\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize sweep and creating sweepID\n",
    "\n",
    "# If new sweep, uncomment the line below and comment the line after it\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project='Deep learning for option pricing - test area') \n",
    "#sweep_id = '98bxt6oq'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP\n",
    "class MSE_LossCallback(Callback):\n",
    "    def __init__(self, train_x, train_y, train_strike, val_x, val_y, val_strike):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.train_strike = train_strike\n",
    "        self.val_x = val_x\n",
    "        self.val_y = val_y\n",
    "        self.val_strike = val_strike\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        train_pred = self.model(train_x)\n",
    "        val_pred = self.model(val_x)\n",
    "\n",
    "        train_mse = reduce_mean(square(multiply(train_pred[:,0] - self.train_y, self.train_strike)))\n",
    "        val_mse = reduce_mean(square(multiply(val_pred[:,0] - self.val_y, self.val_strike)))\n",
    "\n",
    "        print(f' Training scaled MSE: {train_mse}, Validation scaled MSE: {val_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training and validation MSE loss on the actual option price when using price/strike as the target\n",
    "def MSE_loss(model, train_x, train_y, train_strike, val_x, val_y, val_strike):\n",
    "    train_pred = model(train_x)\n",
    "    val_pred = model(val_x)\n",
    "\n",
    "    train_mse = reduce_mean(square((train_pred[:,0] - train_y)*train_strike))\n",
    "    val_mse = reduce_mean(square((val_pred[:,0] - val_y)*val_strike))\n",
    "\n",
    "    print(f' Training scaled MSE: {train_mse}, Validation scaled MSE: {val_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras import backend as k\n",
    "\n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating trainer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_x = train_x, train_y = train_y, val_x = val_x, val_y = val_y, config = None, project = None, checkpoint_path = None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config, project = project):\n",
    "\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "\n",
    "        # Build model and create callbacks\n",
    "        model = create_model(config)\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            min_delta = config.Min_delta,\n",
    "            patience = config.Patience,\n",
    "        )\n",
    "        \n",
    "        wandb_callback = WandbCallback(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_model=False\n",
    "        )\n",
    "\n",
    "        # Checkpoints\n",
    "        \n",
    "        # Check if the checkpoint folder exists\n",
    "        if checkpoint_path and not os.path.exists(checkpoint_path):\n",
    "            # Create the checkpoint folder if it does not exist\n",
    "            os.makedirs(checkpoint_path)\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "\n",
    "        # Adapt sequence length to config\n",
    "        train_x_adjusted = [train_x[0][:, :config.LSTM_timesteps, :], train_x[1]]\n",
    "        val_x_adjusted = [val_x[0][:, :config.LSTM_timesteps, :], val_x[1]]\n",
    "        print(f'Train shape: {train_x_adjusted[0].shape}, {train_x_adjusted[0].shape}')\n",
    "        print(f'Val shape: {val_x_adjusted[0].shape}, {val_x_adjusted[0].shape}')\n",
    "\n",
    "        # Train model\n",
    "        model.fit(\n",
    "            train_x_adjusted,\n",
    "            train_y,\n",
    "            batch_size = config.Minibatch_size,\n",
    "            validation_data = (val_x_adjusted, val_y),\n",
    "            epochs = 1000,\n",
    "            callbacks = [early_stopping, wandb_callback, checkpoint, ClearMemory()] if checkpoint_path else [early_stopping, wandb_callback, ClearMemory()],\n",
    "        )\n",
    "\n",
    "        if moneyness:\n",
    "            MSE_loss(model, train_x, train_y, train_strike, val_x, val_y, val_strike)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run full sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.agent(sweep_id=sweep_id, function=trainer, project='Deep learning for option pricing - test area', count = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(predictions, original):\n",
    "    m = MeanSquaredError()\n",
    "    m.update_state(predictions, original)\n",
    "    print(\"MSE:\", m.result().numpy())\n",
    "    m = RootMeanSquaredError()\n",
    "    m.update_state(predictions, original)\n",
    "    print(\"RMSE:\", m.result().numpy())\n",
    "\n",
    "class config_object:\n",
    "    def __init__(self, config):\n",
    "        self.LSTM_units = config['LSTM_units']\n",
    "        self.MLP_units = config['MLP_units']\n",
    "        self.LSTM_timesteps = config['LSTM_timesteps']\n",
    "        self.LSTM_layers = config['LSTM_layers']\n",
    "        self.MLP_layers = config['MLP_layers']\n",
    "        self.Bn_momentum = config['Bn_momentum']\n",
    "        self.Lr = config['Lr']\n",
    "        self.Lr_decay = config['Lr_decay']\n",
    "        self.Minibatch_size = config['Minibatch_size']\n",
    "        self.Min_delta = config['Min_delta']\n",
    "        self.Patience = config['Patience']\n",
    "        self.Num_features = config['Num_features']\n",
    "        self.Architecture = config['Architecture']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1655728, 90, 1), (1655728, 4)\n",
      "Val shape: (184525, 90, 1), (184525, 4)\n",
      "Test shape: (165072, 90, 1), (165072, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d068c3a58546f097c3fe3d554372a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016701173933324754, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hjalmarjacobvinje/Documents/deep-learning-for-option-pricing/LSTM-MLP_notebooks/wandb/run-20230321_110814-mfb0ilmy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/mfb0ilmy\" target=\"_blank\">deft-energy-16</a></strong> to <a href=\"https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows\" target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/mfb0ilmy\" target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/mfb0ilmy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 8)            1408        ['input_3[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 44)           0           ['sequential_1[0][0]',           \n",
      "                                                                  'sequential_1[1][0]',           \n",
      "                                                                  'sequential_1[2][0]',           \n",
      "                                                                  'sequential_1[3][0]',           \n",
      "                                                                  'sequential_1[4][0]',           \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 2)            90          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 2)           8           ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 2)            0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 2)            6           ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2)           8           ['dense_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 2)            0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 2)            6           ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2)           8           ['dense_9[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 2)            0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 2)            6           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2)           8           ['dense_10[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 2)            0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 2)            6           ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2)           8           ['dense_11[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 2)            0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 2)            6           ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2)           8           ['dense_12[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 2)            0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            3           ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,579\n",
      "Trainable params: 1,555\n",
      "Non-trainable params: 24\n",
      "__________________________________________________________________________________________________\n",
      "Train shape: (1655728, 10, 1), (1655728, 10, 1)\n",
      "Val shape: (184525, 10, 1), (184525, 10, 1)\n",
      "Epoch 1/3\n",
      "308/405 [=====================>........] - ETA: 23s - loss: 639485.3125"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a51a219c244feba31f39e5117b423b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-energy-16</strong> at: <a href=\"https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/mfb0ilmy\" target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/mfb0ilmy</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230321_110814-mfb0ilmy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m checkpoint_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./checkpoint/\u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_time\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtrain_start\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     31\u001b[0m config[\u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtrain_start\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mval_start\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mtest_start\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 33\u001b[0m trainer(config \u001b[39m=\u001b[39;49m config, project \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mDeep learning for option pricing - rolling windows\u001b[39;49m\u001b[39m'\u001b[39;49m, checkpoint_path \u001b[39m=\u001b[39;49m checkpoint_path)\n\u001b[1;32m     34\u001b[0m co \u001b[39m=\u001b[39m config_object(config)\n\u001b[1;32m     35\u001b[0m c_model \u001b[39m=\u001b[39m create_model(co)\n",
      "Cell \u001b[0;32mIn[13], line 47\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(train_x, train_y, val_x, val_y, config, project, checkpoint_path)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVal shape: \u001b[39m\u001b[39m{\u001b[39;00mval_x_adjusted[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mval_x_adjusted[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     48\u001b[0m     train_x_adjusted,\n\u001b[1;32m     49\u001b[0m     train_y,\n\u001b[1;32m     50\u001b[0m     batch_size \u001b[39m=\u001b[39;49m config\u001b[39m.\u001b[39;49mMinibatch_size,\n\u001b[1;32m     51\u001b[0m     validation_data \u001b[39m=\u001b[39;49m (val_x_adjusted, val_y),\n\u001b[1;32m     52\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     53\u001b[0m     callbacks \u001b[39m=\u001b[39;49m [early_stopping, wandb_callback, checkpoint, ClearMemory()] \u001b[39mif\u001b[39;49;00m checkpoint_path \u001b[39melse\u001b[39;49;00m [early_stopping, wandb_callback, ClearMemory()],\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m moneyness:\n\u001b[1;32m     57\u001b[0m     MSE_loss(model, train_x, train_y, train_strike, val_x, val_y, val_strike)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_windows = 3\n",
    "\n",
    "config = {\n",
    "    'LSTM_units': 8,\n",
    "    'MLP_units': 2,\n",
    "    'LSTM_timesteps': 10,\n",
    "    'LSTM_layers': 3,\n",
    "    'MLP_layers': 7,\n",
    "    'Bn_momentum': 0.99,\n",
    "    'Lr': 0.0001,\n",
    "    'Lr_decay': 0.92,\n",
    "    'Minibatch_size': 4096,\n",
    "    'Min_delta': 0.01 if moneyness else 1,\n",
    "    'Patience': 20,\n",
    "    'Num_features': 3 if moneyness else 4, \n",
    "    'Architecture': 'LSTM-MLP v.1.0',\n",
    "}\n",
    "\n",
    "df_test_combined = pd.DataFrame()\n",
    "\n",
    "checkpoint_time = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
    "\n",
    "for window in range(num_windows):\n",
    "    if moneyness:\n",
    "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike, = create_rw_dataset(window)\n",
    "    else:\n",
    "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset(window)\n",
    "\n",
    "    checkpoint_path = f'./checkpoint/{checkpoint_time}/{train_start}/'\n",
    "\n",
    "    config['Dataset'] = f'{train_start} - {val_start} - {test_start}'\n",
    "\n",
    "    trainer(config = config, project = 'Deep learning for option pricing - rolling windows', checkpoint_path = checkpoint_path)\n",
    "    co = config_object(config)\n",
    "    c_model = create_model(co)\n",
    "    c_model.load_weights(checkpoint_path)\n",
    "    predictions = np.array(c_model(test_x))\n",
    "    print(f'--- Predictions for test_start {test_start} ---')\n",
    "    calculate_error(predictions, test_y)\n",
    "    print('-------------------------------------------')\n",
    "    df_test[\"Prediction\"] = predictions\n",
    "    df_test_combined = pd.concat([df_test_combined, df_test[[\"Quote_date\", \"Price\", \"Prediction\"] + bs_vars]])\n",
    "\n",
    "\n",
    "print(f\"--- All model predictions ---\")\n",
    "calculate_error(df_test_combined[\"Prediction\"], df_test_combined[\"Price\"])\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "predictions_path = './predictions/'\n",
    "if checkpoint_path and not os.path.exists(predictions_path):\n",
    "    os.makedirs(predictions_path)\n",
    "df_test_combined.to_csv(f'{predictions_path}{datetime.now().strftime(\"%m-%d_%H-%M\")}.csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1714570, 10, 1), (1714570, 4)\n",
      "Val shape: (165072, 10, 1), (165072, 4)\n",
      "Test shape: (144106, 10, 1), (144106, 4)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 4)            384         ['input_5[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 24)           0           ['sequential_2[0][0]',           \n",
      "                                                                  'sequential_2[1][0]',           \n",
      "                                                                  'sequential_2[2][0]',           \n",
      "                                                                  'sequential_2[3][0]',           \n",
      "                                                                  'sequential_2[4][0]',           \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 2)            50          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 2)           8           ['dense_14[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 2)            0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 2)            6           ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 2)           8           ['dense_15[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 2)            0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 2)            6           ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 2)           8           ['dense_16[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 2)            0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 2)            6           ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 2)           8           ['dense_17[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 2)            0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 2)            6           ['leaky_re_lu_15[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 2)           8           ['dense_18[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 2)            0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 2)            6           ['leaky_re_lu_16[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 2)           8           ['dense_19[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 2)            0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1)            3           ['leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 515\n",
      "Trainable params: 491\n",
      "Non-trainable params: 24\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (32,) when attempting to restore variable with shape (16,) and name layer_with_weights-0/layer_with_weights-0/cell/bias/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m co \u001b[39m=\u001b[39m config_object(config)\n\u001b[1;32m     26\u001b[0m c_model \u001b[39m=\u001b[39m create_model(co)\n\u001b[0;32m---> 27\u001b[0m c_model\u001b[39m.\u001b[39;49mload_weights(checkpoint_path)\n\u001b[1;32m     28\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(c_model(test_x))\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--- Predictions for \u001b[39m\u001b[39m{\u001b[39;00mtest_start\u001b[39m}\u001b[39;00m\u001b[39m ---\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py:139\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    136\u001b[0m   assigned_variable \u001b[39m=\u001b[39m resource_variable_ops\u001b[39m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[1;32m    137\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_op, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_shape, restored_tensor)\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 139\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived incompatible tensor with shape \u001b[39m\u001b[39m{\u001b[39;00mrestored_tensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen attempting to restore variable with shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_shape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand name \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[0;31mValueError\u001b[0m: Received incompatible tensor with shape (32,) when attempting to restore variable with shape (16,) and name layer_with_weights-0/layer_with_weights-0/cell/bias/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'LSTM_units': 4,\n",
    "    'MLP_units': 600,\n",
    "    'LSTM_timesteps': 10,\n",
    "    'LSTM_layers': 3,\n",
    "    'MLP_layers': 7,\n",
    "    'Bn_momentum': 0.99,\n",
    "    'Lr': 0.0001,\n",
    "    'Lr_decay': 0.92,\n",
    "    'Minibatch_size': 4096,\n",
    "    'Min_delta': 0.01 if moneyness else 1,\n",
    "    'Patience': 20,\n",
    "    'Num_features': 3 if moneyness else 4, \n",
    "    'Architecture': 'LSTM-MLP v.1.0',\n",
    "}\n",
    "\n",
    "window = 1\n",
    "if moneyness:\n",
    "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike, = create_rw_dataset(window)\n",
    "else:\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset(window)\n",
    "\n",
    "checkpoint_path = f'./checkpoint/03-20_12-35/{train_start}/'\n",
    "\n",
    "co = config_object(config)\n",
    "c_model = create_model(co)\n",
    "c_model.load_weights(checkpoint_path)\n",
    "predictions = np.array(c_model(test_x))\n",
    "print(f'--- Predictions for {test_start} ---')\n",
    "calculate_error(predictions, test_y)\n",
    "print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
