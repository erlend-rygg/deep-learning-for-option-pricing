{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2MNO3kPTnkd"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOQkqhqFTnkg"
      },
      "outputs": [],
      "source": [
        "# Weights and Biases\n",
        "!pip install -q wandb\n",
        "# Tensorflow\n",
        "!pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfwvf6vGTnki"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, LSTM, Concatenate, Dense, BatchNormalization, LeakyReLU\n",
        "from keras.activations import tanh\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from tensorflow import square, reduce_mean\n",
        "from tensorflow.keras.losses import MSE\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.math import multiply\n",
        "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fduF6iTTnkj",
        "outputId": "e258dd19-1414-490b-e11a-16e21de7855f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# If running in colab, insert your wandb key here\n",
        "\n",
        "#import config\n",
        "#Erlend\n",
        "#wandb.login(key=config.erlend_key)\n",
        "# Hjalmar\n",
        "wandb.login(key=\"b47bcf387a0571c5520c58a13be35cda8ada0a99\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJGDiGMLTnkl"
      },
      "source": [
        "# Load, split and normalize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI1j3mQWTnkl"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "OKcl8WWJTnkl",
        "outputId": "1f903256-d32c-464c-f339-7d4995b3175a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 12 21:07:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    26W /  70W |   1249MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Unnamed: 0  Quote_date    Price  Underlying_last  Strike   TTM     R\n",
              "0                  0  2013-01-02  361.355          1462.33  1100.0     2  0.07\n",
              "1                  1  2013-01-02  336.600          1462.33  1125.0     2  0.07\n",
              "2                  2  2013-01-02  311.350          1462.33  1150.0     2  0.07\n",
              "3                  3  2013-01-02  286.345          1462.33  1175.0     2  0.07\n",
              "4                  4  2013-01-02  281.345          1462.33  1180.0     2  0.07\n",
              "...              ...         ...      ...              ...     ...   ...   ...\n",
              "12459173    12459173  2022-12-30    6.950          3839.81  8400.0  1085  4.22\n",
              "12459174    12459174  2022-12-30    5.950          3839.81  8600.0  1085  4.22\n",
              "12459175    12459175  2022-12-30    5.450          3839.81  8800.0  1085  4.22\n",
              "12459176    12459176  2022-12-30    4.500          3839.81  9000.0  1085  4.22\n",
              "12459177    12459177  2022-12-30    4.025          3839.81  9200.0  1085  4.22\n",
              "\n",
              "[12459178 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75dbc9f5-ff67-4b8b-b9c3-6fc8a288cf01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Quote_date</th>\n",
              "      <th>Price</th>\n",
              "      <th>Underlying_last</th>\n",
              "      <th>Strike</th>\n",
              "      <th>TTM</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>361.355</td>\n",
              "      <td>1462.33</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>336.600</td>\n",
              "      <td>1462.33</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>311.350</td>\n",
              "      <td>1462.33</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>286.345</td>\n",
              "      <td>1462.33</td>\n",
              "      <td>1175.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>281.345</td>\n",
              "      <td>1462.33</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459173</th>\n",
              "      <td>12459173</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>6.950</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>8400.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459174</th>\n",
              "      <td>12459174</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>5.950</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>8600.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459175</th>\n",
              "      <td>12459175</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>5.450</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>8800.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459176</th>\n",
              "      <td>12459176</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>4.500</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459177</th>\n",
              "      <td>12459177</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>4.025</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>9200.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12459178 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75dbc9f5-ff67-4b8b-b9c3-6fc8a288cf01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75dbc9f5-ff67-4b8b-b9c3-6fc8a288cf01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75dbc9f5-ff67-4b8b-b9c3-6fc8a288cf01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "google_colab = True\n",
        "\n",
        "if google_colab:\n",
        "    import tensorflow as tf\n",
        "    # Pring info\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "        print('Not connected to a GPU')\n",
        "    else:\n",
        "        print(gpu_info)\n",
        "    \n",
        "    from psutil import virtual_memory\n",
        "    ram_gb = virtual_memory().total / 1e9\n",
        "    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "    if ram_gb < 20:\n",
        "        print('Not using a high-RAM runtime')\n",
        "    else:\n",
        "        print('You are using a high-RAM runtime!')\n",
        "\n",
        "    # Code to read csv file into Colaboratory:\n",
        "    !pip install -U -q PyDrive\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    # Authenticate and create the PyDrive client.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    id = \"1Ic73MqpS5ACG1p2oJ_R5cTuEhlQRM_Q6\"\n",
        "    downloaded = drive.CreateFile({'id':id}) \n",
        "    downloaded.GetContentFile('2013-2022_wo_lags.csv')  \n",
        "    df_read = pd.read_csv('2013-2022_wo_lags.csv')\n",
        "else:\n",
        "    file = \"../data/processed_data/2020_2022_moneyness_filtere.csv\"\n",
        "    df_read = pd.read_csv(file)\n",
        "\n",
        "display(df_read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpcmhVq6Tnkm"
      },
      "outputs": [],
      "source": [
        "df = df_read\n",
        "del df_read\n",
        "\n",
        "# Group the data by Quote Date and calculate the mean for Underlying Price\n",
        "df_agg = df.groupby('Quote_date').mean().reset_index()\n",
        "\n",
        "# Values to returns\n",
        "df_agg[\"Underlying_return\"] = df_agg[\"Underlying_last\"].pct_change()\n",
        "\n",
        "lags = 10\n",
        "\n",
        "# Add the Underlying Price Lag column\n",
        "for i in range(1, lags + 1):\n",
        "    df_agg['Underlying_' + str(i)] = df_agg['Underlying_return'].shift(i)\n",
        "\n",
        "df = pd.merge(df, df_agg[['Quote_date', \"Underlying_return\"] + ['Underlying_' + str(i) for i in range(1, lags + 1)]], on='Quote_date', how='left')\n",
        "\n",
        "# Filter df between 2014-01-01 and 2022-12-31\n",
        "df = df[(df[\"Quote_date\"] >= \"2014-01-01\") & (df[\"Quote_date\"] <= \"2022-12-31\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "2eAUxhRsTnkn",
        "outputId": "7581c28c-17e3-4952-b116-b61423b5e621"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Unnamed: 0  Quote_date    Price  Underlying_last  Strike   TTM  \\\n",
              "405271        405271  2014-01-03  555.455          1831.47  1275.0     7   \n",
              "405272        405272  2014-01-03  530.500          1831.47  1300.0     7   \n",
              "405273        405273  2014-01-03  505.495          1831.47  1325.0     7   \n",
              "405274        405274  2014-01-03  480.355          1831.47  1350.0     7   \n",
              "405275        405275  2014-01-03  455.350          1831.47  1375.0     7   \n",
              "...              ...         ...      ...              ...     ...   ...   \n",
              "12459173    12459173  2022-12-30    6.950          3839.81  8400.0  1085   \n",
              "12459174    12459174  2022-12-30    5.950          3839.81  8600.0  1085   \n",
              "12459175    12459175  2022-12-30    5.450          3839.81  8800.0  1085   \n",
              "12459176    12459176  2022-12-30    4.500          3839.81  9000.0  1085   \n",
              "12459177    12459177  2022-12-30    4.025          3839.81  9200.0  1085   \n",
              "\n",
              "             R  Underlying_return  Underlying_1  Underlying_2  Underlying_3  \\\n",
              "405271    0.02          -0.008816      0.003677     -0.000147     -0.000331   \n",
              "405272    0.02          -0.008816      0.003677     -0.000147     -0.000331   \n",
              "405273    0.02          -0.008816      0.003677     -0.000147     -0.000331   \n",
              "405274    0.02          -0.008816      0.003677     -0.000147     -0.000331   \n",
              "405275    0.02          -0.008816      0.003677     -0.000147     -0.000331   \n",
              "...        ...                ...           ...           ...           ...   \n",
              "12459173  4.22          -0.002300      0.017343     -0.012034     -0.004081   \n",
              "12459174  4.22          -0.002300      0.017343     -0.012034     -0.004081   \n",
              "12459175  4.22          -0.002300      0.017343     -0.012034     -0.004081   \n",
              "12459176  4.22          -0.002300      0.017343     -0.012034     -0.004081   \n",
              "12459177  4.22          -0.002300      0.017343     -0.012034     -0.004081   \n",
              "\n",
              "          Underlying_4  Underlying_5  Underlying_6  Underlying_7  \\\n",
              "405271        0.004664      0.002828      0.004721      0.005565   \n",
              "405272        0.004664      0.002828      0.004721      0.005565   \n",
              "405273        0.004664      0.002828      0.004721      0.005565   \n",
              "405274        0.004664      0.002828      0.004721      0.005565   \n",
              "405275        0.004664      0.002828      0.004721      0.005565   \n",
              "...                ...           ...           ...           ...   \n",
              "12459173      0.000096      0.005621     -0.014208      0.014673   \n",
              "12459174      0.000096      0.005621     -0.014208      0.014673   \n",
              "12459175      0.000096      0.005621     -0.014208      0.014673   \n",
              "12459176      0.000096      0.005621     -0.014208      0.014673   \n",
              "12459177      0.000096      0.005621     -0.014208      0.014673   \n",
              "\n",
              "          Underlying_8  Underlying_9  Underlying_10  \n",
              "405271       -0.000508      0.016502      -0.003006  \n",
              "405272       -0.000508      0.016502      -0.003006  \n",
              "405273       -0.000508      0.016502      -0.003006  \n",
              "405274       -0.000508      0.016502      -0.003006  \n",
              "405275       -0.000508      0.016502      -0.003006  \n",
              "...                ...           ...            ...  \n",
              "12459173      0.001048     -0.020257      -0.024582  \n",
              "12459174      0.001048     -0.020257      -0.024582  \n",
              "12459175      0.001048     -0.020257      -0.024582  \n",
              "12459176      0.001048     -0.020257      -0.024582  \n",
              "12459177      0.001048     -0.020257      -0.024582  \n",
              "\n",
              "[12053907 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2afae59c-fbd7-4ded-8e0f-8d681194b651\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Quote_date</th>\n",
              "      <th>Price</th>\n",
              "      <th>Underlying_last</th>\n",
              "      <th>Strike</th>\n",
              "      <th>TTM</th>\n",
              "      <th>R</th>\n",
              "      <th>Underlying_return</th>\n",
              "      <th>Underlying_1</th>\n",
              "      <th>Underlying_2</th>\n",
              "      <th>Underlying_3</th>\n",
              "      <th>Underlying_4</th>\n",
              "      <th>Underlying_5</th>\n",
              "      <th>Underlying_6</th>\n",
              "      <th>Underlying_7</th>\n",
              "      <th>Underlying_8</th>\n",
              "      <th>Underlying_9</th>\n",
              "      <th>Underlying_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>405271</th>\n",
              "      <td>405271</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>555.455</td>\n",
              "      <td>1831.47</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.008816</td>\n",
              "      <td>0.003677</td>\n",
              "      <td>-0.000147</td>\n",
              "      <td>-0.000331</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.002828</td>\n",
              "      <td>0.004721</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>-0.003006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405272</th>\n",
              "      <td>405272</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>530.500</td>\n",
              "      <td>1831.47</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.008816</td>\n",
              "      <td>0.003677</td>\n",
              "      <td>-0.000147</td>\n",
              "      <td>-0.000331</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.002828</td>\n",
              "      <td>0.004721</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>-0.003006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405273</th>\n",
              "      <td>405273</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>505.495</td>\n",
              "      <td>1831.47</td>\n",
              "      <td>1325.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.008816</td>\n",
              "      <td>0.003677</td>\n",
              "      <td>-0.000147</td>\n",
              "      <td>-0.000331</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.002828</td>\n",
              "      <td>0.004721</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>-0.003006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405274</th>\n",
              "      <td>405274</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>480.355</td>\n",
              "      <td>1831.47</td>\n",
              "      <td>1350.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.008816</td>\n",
              "      <td>0.003677</td>\n",
              "      <td>-0.000147</td>\n",
              "      <td>-0.000331</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.002828</td>\n",
              "      <td>0.004721</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>-0.003006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405275</th>\n",
              "      <td>405275</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>455.350</td>\n",
              "      <td>1831.47</td>\n",
              "      <td>1375.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.008816</td>\n",
              "      <td>0.003677</td>\n",
              "      <td>-0.000147</td>\n",
              "      <td>-0.000331</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.002828</td>\n",
              "      <td>0.004721</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>-0.000508</td>\n",
              "      <td>0.016502</td>\n",
              "      <td>-0.003006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459173</th>\n",
              "      <td>12459173</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>6.950</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>8400.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.017343</td>\n",
              "      <td>-0.012034</td>\n",
              "      <td>-0.004081</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.005621</td>\n",
              "      <td>-0.014208</td>\n",
              "      <td>0.014673</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>-0.020257</td>\n",
              "      <td>-0.024582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459174</th>\n",
              "      <td>12459174</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>5.950</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>8600.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.017343</td>\n",
              "      <td>-0.012034</td>\n",
              "      <td>-0.004081</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.005621</td>\n",
              "      <td>-0.014208</td>\n",
              "      <td>0.014673</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>-0.020257</td>\n",
              "      <td>-0.024582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459175</th>\n",
              "      <td>12459175</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>5.450</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>8800.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.017343</td>\n",
              "      <td>-0.012034</td>\n",
              "      <td>-0.004081</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.005621</td>\n",
              "      <td>-0.014208</td>\n",
              "      <td>0.014673</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>-0.020257</td>\n",
              "      <td>-0.024582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459176</th>\n",
              "      <td>12459176</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>4.500</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.017343</td>\n",
              "      <td>-0.012034</td>\n",
              "      <td>-0.004081</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.005621</td>\n",
              "      <td>-0.014208</td>\n",
              "      <td>0.014673</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>-0.020257</td>\n",
              "      <td>-0.024582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12459177</th>\n",
              "      <td>12459177</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>4.025</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>9200.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.017343</td>\n",
              "      <td>-0.012034</td>\n",
              "      <td>-0.004081</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.005621</td>\n",
              "      <td>-0.014208</td>\n",
              "      <td>0.014673</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>-0.020257</td>\n",
              "      <td>-0.024582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12053907 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2afae59c-fbd7-4ded-8e0f-8d681194b651')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2afae59c-fbd7-4ded-8e0f-8d681194b651 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2afae59c-fbd7-4ded-8e0f-8d681194b651');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1fuXIvmTnkn"
      },
      "source": [
        "### Format input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKAFyCmTTnko",
        "outputId": "07ee6021-f506-41b9-b64b-d84fb4ecabe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (496184, 10, 1), (496184, 4)\n",
            "Val shape: (61101, 10, 1), (61101, 4)\n",
            "Test shape: (55924, 10, 1), (55924, 4)\n"
          ]
        }
      ],
      "source": [
        "# Format settings\n",
        "max_timesteps = lags\n",
        "moneyness = False\n",
        "bs_vars = ['Moneyness', 'TTM', 'R'] if moneyness else ['Underlying_last', 'Strike', 'TTM', 'R']\n",
        "underlying_lags = ['Underlying_last'] + [f'Underlying_{i}' for i in range (1, max_timesteps)]\n",
        "\n",
        "def create_rw_dataset(window_number = 0, df = df):\n",
        "    '''Creates dataset for a single rolling window period offsett by the window number'''\n",
        "\n",
        "    # Create train, validation and test set split points\n",
        "    train_start = datetime(2014,1,1) + relativedelta(months=window_number)\n",
        "    val_start = train_start + relativedelta(months=11)\n",
        "    test_start = val_start + relativedelta(months=1)\n",
        "    test_end = test_start + relativedelta(months=1)\n",
        "    train_start = str(train_start.date())\n",
        "    val_start = str(val_start.date())\n",
        "    test_start = str(test_start.date())\n",
        "    test_end = str(test_end.date())\n",
        "\n",
        "    # Add moneyness column\n",
        "    if not moneyness:\n",
        "        df['Moneyness'] = df['Underlying_last'] / df['Strike']\n",
        "\n",
        "\n",
        "    # Split train and validation data\n",
        "    df_train = df[(df['Quote_date'] >= train_start) & (df['Quote_date'] < val_start)]\n",
        "    df_val = df[(df['Quote_date'] >= val_start) & (df['Quote_date'] < test_start)]\n",
        "    df_test = df[(df['Quote_date'] >= test_start) & (df['Quote_date'] < test_end)]\n",
        "\n",
        "    del df\n",
        "\n",
        "    # Filter out top and bottom 5% of moneyness in df_train, and using the same filter in df_val and df_test\n",
        "    top = df_train['Moneyness'].quantile(0.95)\n",
        "    bottom = df_train['Moneyness'].quantile(0.05)\n",
        "    df_train = df_train[(df_train['Moneyness'] <= top) & (df_train['Moneyness'] >= bottom)]\n",
        "    df_val = df_val[(df_val['Moneyness'] <= top) & (df_val['Moneyness'] >= bottom)]\n",
        "    df_test = df_test[(df_test['Moneyness'] <= top) & (df_test['Moneyness'] >= bottom)]\n",
        "\n",
        "\n",
        "    # Extract target values\n",
        "    train_y = (df_train['Price'] / df_train['Strike']).to_numpy() if moneyness else df_train['Price'].to_numpy()\n",
        "    val_y = (df_val['Price'] / df_val['Strike']).to_numpy() if moneyness else df_val['Price'].to_numpy()\n",
        "    test_y = (df_test['Price'] / df_test['Strike']).to_numpy() if moneyness else df_test['Price'].to_numpy()\n",
        "\n",
        "    # If usining moneyness, extract strike\n",
        "    if moneyness:\n",
        "        train_strike = df_train['Strike'].to_numpy()\n",
        "        val_strike = df_val['Strike'].to_numpy()\n",
        "        test_strike = df_test['Strike'].to_numpy()\n",
        "\n",
        "    # Convert dataframes to numpy arrays\n",
        "    train_x = [df_train[underlying_lags].to_numpy(), df_train[bs_vars].to_numpy()]\n",
        "    val_x = [df_val[underlying_lags].to_numpy(), df_val[bs_vars].to_numpy()]\n",
        "    test_x = [df_test[underlying_lags].to_numpy(), df_test[bs_vars].to_numpy()]\n",
        "\n",
        "    del df_train\n",
        "    del df_val\n",
        "\n",
        "    # Scale features based on training set\n",
        "    underlying_scaler = MinMaxScaler()\n",
        "    train_x[0] = underlying_scaler.fit_transform(train_x[0])\n",
        "    val_x[0] = underlying_scaler.transform(val_x[0])\n",
        "    test_x[0] = underlying_scaler.transform(test_x[0])\n",
        "\n",
        "    bs_scaler = MinMaxScaler()\n",
        "    train_x[1] = bs_scaler.fit_transform(train_x[1])\n",
        "    val_x[1] = bs_scaler.transform(val_x[1])\n",
        "    test_x[1] = bs_scaler.transform(test_x[1])\n",
        "\n",
        "\n",
        "    # Shuffle training set\n",
        "    np.random.seed(0)\n",
        "    shuffle = np.random.permutation(len(train_x[0]))\n",
        "    train_x = [train_x[0][shuffle], train_x[1][shuffle]]\n",
        "    train_y = train_y[shuffle]\n",
        "    if moneyness:\n",
        "        train_strike = train_strike[shuffle]\n",
        "\n",
        "    # Reshape data to fit LSTM\n",
        "    train_x = [train_x[0].reshape(len(train_x[0]), max_timesteps, 1), train_x[1]]\n",
        "    val_x = [val_x[0].reshape(len(val_x[0]), max_timesteps, 1), val_x[1]]\n",
        "    test_x = [test_x[0].reshape(len(test_x[0]), max_timesteps, 1), test_x[1]]\n",
        "\n",
        "    print(f'Train shape: {train_x[0].shape}, {train_x[1].shape}')\n",
        "    print(f'Val shape: {val_x[0].shape}, {val_x[1].shape}')\n",
        "    print(f'Test shape: {test_x[0].shape}, {test_x[1].shape}')\n",
        "\n",
        "    if moneyness:\n",
        "        return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike,\n",
        "    return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test\n",
        "\n",
        "# Create the dataset for the first rolling window period\n",
        "if moneyness:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike = create_rw_dataset()\n",
        "else:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inutSrd8Tnko"
      },
      "source": [
        "# Model construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gewRG-rHTnkp"
      },
      "outputs": [],
      "source": [
        "def create_model(config):\n",
        "    '''Builds an LSTM-MLP model of minimum 2 layers sequentially from a given config dictionary'''\n",
        "\n",
        "    # Input layers\n",
        "    underlying_history = Input((config.LSTM_timesteps,1))\n",
        "    bs_vars = Input((config.Num_features,))\n",
        "\n",
        "    # LSTM layers\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(\n",
        "        units = config.LSTM_units,\n",
        "        activation = tanh,\n",
        "        input_shape = (config.LSTM_timesteps, 1),\n",
        "        return_sequences = True\n",
        "    ))\n",
        "\n",
        "    for _ in range(config.LSTM_layers - 2):\n",
        "        model.add(LSTM(\n",
        "            units = config.LSTM_units,\n",
        "            activation = tanh,\n",
        "            return_sequences = True\n",
        "        ))\n",
        "    \n",
        "    model.add(LSTM(\n",
        "        units = config.Interface_units,\n",
        "        activation = tanh,\n",
        "        return_sequences = False\n",
        "    ))\n",
        "\n",
        "    # MLP layers\n",
        "    layers = Concatenate()([model(underlying_history), model(underlying_history), model(underlying_history), model(underlying_history), model(underlying_history), bs_vars])\n",
        "    \n",
        "    for _ in range(config.MLP_layers - 1):\n",
        "        layers = Dense(config.MLP_units)(layers)\n",
        "        layers = BatchNormalization(momentum=config.Bn_momentum)(layers)\n",
        "        layers = LeakyReLU()(layers)\n",
        "\n",
        "    output = Dense(1, activation='relu')(layers)\n",
        "\n",
        "    # Exponential decaying learning rate\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate = config.Lr,\n",
        "        decay_steps = int(len(train_x[0])/config.Minibatch_size),\n",
        "        decay_rate=config.Lr_decay\n",
        "    )\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=[underlying_history, bs_vars], outputs=output)\n",
        "    model.compile(loss='mse', optimizer=Adam(learning_rate=lr_schedule))\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqno7WFBTnkp"
      },
      "source": [
        "# Hyperparameter search setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__KmrL9HTnkp",
        "outputId": "938dcc43-9f05-495d-eb52-2164ca7c5cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Lr uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. Lr_decay uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: jufayj7u\n",
            "Sweep URL: https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20test%20area/sweeps/jufayj7u\n"
          ]
        }
      ],
      "source": [
        "# Configuring the sweep hyperparameter search space\n",
        "sweep_configuration = {\n",
        "    'method': 'bayes',\n",
        "    'name': 'LSTM-MLP v4.0: fix nan issue',\n",
        "    'metric': {\n",
        "        'goal': 'minimize', \n",
        "        'name': 'val_loss'\n",
        "\t\t},\n",
        "    'parameters': {\n",
        "        'LSTM_units': {\n",
        "            'values': [4, 8, 16, 32]},\n",
        "        'Interface_units': {\n",
        "            'values': [4, 8, 16, 32]},\n",
        "        'MLP_units': {\n",
        "            'values': [50, 100, 200, 400, 600]},\n",
        "        'LSTM_timesteps': {\n",
        "            'values': [10, 20, 40, 60, 90, 150]},\n",
        "        'LSTM_layers': {\n",
        "            'distribution': 'int_uniform',\n",
        "            'max': 8, 'min': 2},\n",
        "        'MLP_layers': {\n",
        "            'distribution': 'int_uniform',\n",
        "            'max': 8, 'min': 2},\n",
        "        'Bn_momentum': {\n",
        "            'values': [0.1, 0.4, 0.7, 0.99]},\n",
        "        'Lr': {\n",
        "            'distribution': 'log_uniform',\n",
        "            'max': log(0.1), 'min': log(0.0001)},\n",
        "        'Lr_decay': {\n",
        "            'distribution': 'log_uniform',\n",
        "            'max': log(1), 'min': log(0.8)},        \n",
        "        'Minibatch_size': {\n",
        "            'value': 4096},\n",
        "        'Min_delta': {\n",
        "            'value': 0.01 if moneyness else 1},\n",
        "        'Patience': {\n",
        "            'value': 20},\n",
        "        'Num_features': {\n",
        "            'value': 3 if moneyness else 4},\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize sweep and creating sweepID\n",
        "\n",
        "# If new sweep, uncomment the line below and comment the line after it\n",
        "sweep_id = wandb.sweep(sweep=sweep_configuration, project='Deep learning for option pricing - test area') \n",
        "#sweep_id = '98bxt6oq'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AogdJkrRTnkq"
      },
      "source": [
        "# Run hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67l6iqWdTnkq"
      },
      "outputs": [],
      "source": [
        "#WIP\n",
        "class MSE_LossCallback(Callback):\n",
        "    def __init__(self, train_x, train_y, train_strike, val_x, val_y, val_strike):\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.train_strike = train_strike\n",
        "        self.val_x = val_x\n",
        "        self.val_y = val_y\n",
        "        self.val_strike = val_strike\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        train_pred = self.model(train_x)\n",
        "        val_pred = self.model(val_x)\n",
        "\n",
        "        train_mse = reduce_mean(square(multiply(train_pred[:,0] - self.train_y, self.train_strike)))\n",
        "        val_mse = reduce_mean(square(multiply(val_pred[:,0] - self.val_y, self.val_strike)))\n",
        "\n",
        "        print(f' Training scaled MSE: {train_mse}, Validation scaled MSE: {val_mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ogZE0y_Tnkq"
      },
      "outputs": [],
      "source": [
        "# Calculate the training and validation MSE loss on the actual option price when using price/strike as the target\n",
        "def MSE_loss(model, train_x, train_y, train_strike, val_x, val_y, val_strike):\n",
        "    train_pred = model(train_x)\n",
        "    val_pred = model(val_x)\n",
        "\n",
        "    train_mse = reduce_mean(square((train_pred[:,0] - train_y)*train_strike))\n",
        "    val_mse = reduce_mean(square((val_pred[:,0] - val_y)*val_strike))\n",
        "\n",
        "    print(f' Training scaled MSE: {train_mse}, Validation scaled MSE: {val_mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf-ICRDKTnkr"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "from tensorflow.keras import backend as k\n",
        "\n",
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4CRxFJrTnkr"
      },
      "source": [
        "## Creating trainer function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZsaCBmrTnkr"
      },
      "outputs": [],
      "source": [
        "def trainer(train_x = train_x, train_y = train_y, val_x = val_x, val_y = val_y, config = None, project = None, checkpoint_path = None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config, project = project):\n",
        "\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "\n",
        "        # Build model and create callbacks\n",
        "        model = create_model(config)\n",
        "\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            min_delta = config.Min_delta,\n",
        "            patience = config.Patience,\n",
        "        )\n",
        "        \n",
        "        wandb_callback = WandbCallback(\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            save_model=False\n",
        "        )\n",
        "\n",
        "        # Checkpoints\n",
        "        \n",
        "        # Check if the checkpoint folder exists\n",
        "        if checkpoint_path and not os.path.exists(checkpoint_path):\n",
        "            # Create the checkpoint folder if it does not exist\n",
        "            os.makedirs(checkpoint_path)\n",
        "        \n",
        "        checkpoint = ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True\n",
        "        )\n",
        "\n",
        "        # Adapt sequence length to config\n",
        "        train_x_adjusted = [train_x[0][:, :config.LSTM_timesteps, :], train_x[1]]\n",
        "        val_x_adjusted = [val_x[0][:, :config.LSTM_timesteps, :], val_x[1]]\n",
        "        print(f'Train shape: {train_x_adjusted[0].shape}, {train_x_adjusted[0].shape}')\n",
        "        print(f'Val shape: {val_x_adjusted[0].shape}, {val_x_adjusted[0].shape}')\n",
        "\n",
        "        # Train model\n",
        "        model.fit(\n",
        "            train_x_adjusted,\n",
        "            train_y,\n",
        "            batch_size = config.Minibatch_size,\n",
        "            validation_data = (val_x_adjusted, val_y),\n",
        "            epochs = 1000,\n",
        "            callbacks = [early_stopping, wandb_callback, checkpoint, ClearMemory()] if checkpoint_path else [early_stopping, wandb_callback, ClearMemory()],\n",
        "        )\n",
        "\n",
        "        if moneyness:\n",
        "            MSE_loss(model, train_x, train_y, train_strike, val_x, val_y, val_strike)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQyg6eZKTnkr"
      },
      "source": [
        "### Run full sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC5YLKBTTnks"
      },
      "outputs": [],
      "source": [
        "#wandb.agent(sweep_id=sweep_id, function=trainer, project='Deep learning for option pricing - test area', count = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuuoYP4ITnks"
      },
      "source": [
        "### Single run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaS4BiSNTnks"
      },
      "source": [
        "# Rolling window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifDAjXS3Tnks"
      },
      "outputs": [],
      "source": [
        "def calculate_error(predictions, original):\n",
        "    m = MeanSquaredError()\n",
        "    m.update_state(predictions, original)\n",
        "    print(\"MSE:\", m.result().numpy())\n",
        "    m = RootMeanSquaredError()\n",
        "    m.update_state(predictions, original)\n",
        "    print(\"RMSE:\", m.result().numpy())\n",
        "\n",
        "class config_object:\n",
        "    def __init__(self, config):\n",
        "        self.LSTM_units = config['LSTM_units']\n",
        "        self.Interface_units = config['Interface_units']\n",
        "        self.MLP_units = config['MLP_units']\n",
        "        self.LSTM_timesteps = config['LSTM_timesteps']\n",
        "        self.LSTM_layers = config['LSTM_layers']\n",
        "        self.MLP_layers = config['MLP_layers']\n",
        "        self.Bn_momentum = config['Bn_momentum']\n",
        "        self.Lr = config['Lr']\n",
        "        self.Lr_decay = config['Lr_decay']\n",
        "        self.Minibatch_size = config['Minibatch_size']\n",
        "        self.Min_delta = config['Min_delta']\n",
        "        self.Patience = config['Patience']\n",
        "        self.Num_features = config['Num_features']\n",
        "        self.Architecture = config['Architecture']\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0d2a9c27343b49bc9d986128baff0a9a",
            "f81230d00a0b4f2f9ac75b7e8ac85bd0",
            "d665a0b4a5ec4a89a1b15b5907d8a911",
            "1a715a6dad054fffb5405156e915dc6c",
            "7ad538477c664ced95153a740b41a69b",
            "76aaec3b18584034bb7725df913f9ec1",
            "515397ae7e2e4e13b6636ca57713e8ef",
            "c32db6a2ff0a4b928652cee07368b309",
            "a24504366a454e509afbc7db6656f525",
            "18106aa96553436080facdcebc0a36ea",
            "1c40fe5dd9da45109ddbcedef2edc13b",
            "cb0073403edd4e9a834e4c0d0878b547",
            "d53f5b75d24d41ae907ffac6415d8b96",
            "ab014efc18054082b64c36d22288c589",
            "f752fe74cf114e7f80924ead3f15667a",
            "4cb63e85178a4c489dc45736c6aeb033",
            "7e34a05cb5c54e5885dfc082ebcdefe1",
            "f0a58c1d50e04d1f85f85b2e59b24f76"
          ]
        },
        "id": "lRV8wlklTnks",
        "outputId": "f5a3ce0b-bdd1-4f12-f479-e53a9e5fa87b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train shape: (496184, 10, 1), (496184, 4)\n",
            "Val shape: (61101, 10, 1), (61101, 4)\n",
            "Test shape: (55924, 10, 1), (55924, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_210814-95sut8c4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/95sut8c4' target=\"_blank\">leafy-wood-138</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/95sut8c4' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/95sut8c4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 56s 128ms/step - loss: 72052.6016 - val_loss: 91529.9688\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 1506.2207 - val_loss: 118396.1562\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 191.1975 - val_loss: 54017.4023\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 97.9752 - val_loss: 36398.3047\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 89.1910 - val_loss: 29709.2363\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 88.5856 - val_loss: 30465.9844\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 81.5810 - val_loss: 26322.5195\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 65.2308 - val_loss: 18999.9609\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 56.2425 - val_loss: 28864.9844\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 62.2886 - val_loss: 21565.2305\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 51.2212 - val_loss: 37055.7109\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 53.1969 - val_loss: 8220.1162\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 43.0863 - val_loss: 1644.1112\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 47.8282 - val_loss: 9257.9404\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 49.1606 - val_loss: 5703.6821\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 42.0312 - val_loss: 3915.9536\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 39.8234 - val_loss: 2185.7397\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 35.8927 - val_loss: 241.6027\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.6806 - val_loss: 176.4233\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.0468 - val_loss: 536.1674\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.3733 - val_loss: 160.0312\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.4534 - val_loss: 195.2568\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 39.0477 - val_loss: 75.8345\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 36.8333 - val_loss: 102.7472\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.1492 - val_loss: 173.9335\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.7090 - val_loss: 161.5303\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.1479 - val_loss: 212.6465\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 34.3528 - val_loss: 56.5719\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.2191 - val_loss: 92.5717\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.4665 - val_loss: 82.3596\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 40.6373 - val_loss: 75.7645\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.0555 - val_loss: 56.4609\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 36.2129 - val_loss: 49.2485\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.5405 - val_loss: 50.7080\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.4905 - val_loss: 50.7270\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 36.2419 - val_loss: 55.2761\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 31.1552 - val_loss: 47.3676\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 32.9615 - val_loss: 47.4337\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.6229 - val_loss: 48.0283\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 38.7360 - val_loss: 47.1438\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 34.6027 - val_loss: 47.1250\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 35.6130 - val_loss: 45.9273\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 33.2377 - val_loss: 46.6377\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.8772 - val_loss: 46.7043\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 42.5416 - val_loss: 46.9655\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.3281 - val_loss: 46.6376\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.5992 - val_loss: 46.0829\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.6767 - val_loss: 46.6424\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 30.4631 - val_loss: 45.9538\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.2685 - val_loss: 46.6269\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.0548 - val_loss: 45.9824\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 35.3166 - val_loss: 45.7701\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 32.6571 - val_loss: 46.1932\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 34.6642 - val_loss: 46.2373\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.3873 - val_loss: 46.1247\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.7043 - val_loss: 46.0435\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.6023 - val_loss: 46.3607\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.2762 - val_loss: 45.9992\n",
            "Epoch 59/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.2826 - val_loss: 46.0447\n",
            "Epoch 60/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 36.9385 - val_loss: 45.8035\n",
            "Epoch 61/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.1181 - val_loss: 45.9638\n",
            "Epoch 62/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.2341 - val_loss: 46.3569\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d2a9c27343b49bc9d986128baff0a9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.024 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.233526…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆█▃▃▃▂▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>51</td></tr><tr><td>best_val_loss</td><td>45.77011</td></tr><tr><td>epoch</td><td>61</td></tr><tr><td>loss</td><td>32.23409</td></tr><tr><td>val_loss</td><td>46.3569</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">leafy-wood-138</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/95sut8c4' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/95sut8c4</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_210814-95sut8c4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "--- Predictions for test_start 2015-01-01 ---\n",
            "MSE: 54.73269\n",
            "RMSE: 7.3981543\n",
            "-------------------------------------------\n",
            "Train shape: (520744, 10, 1), (520744, 4)\n",
            "Val shape: (55791, 10, 1), (55791, 4)\n",
            "Test shape: (57437, 10, 1), (57437, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_212342-z0y6ha1y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z0y6ha1y' target=\"_blank\">mild-wood-139</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z0y6ha1y' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z0y6ha1y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 55s 127ms/step - loss: 72611.3594 - val_loss: 381576.5312\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 1371.0421 - val_loss: 125300.2266\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 122.0817 - val_loss: 48770.8164\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 114.4192 - val_loss: 37568.4609\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 60.2651 - val_loss: 19154.7812\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 61.4864 - val_loss: 2790.8875\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 66.5632 - val_loss: 5399.4126\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 53.6312 - val_loss: 5796.5503\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 51.5595 - val_loss: 283.7880\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 48.5969 - val_loss: 1826.7334\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 51.2009 - val_loss: 253.5919\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 39.1852 - val_loss: 1026.3433\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 41.1602 - val_loss: 3660.8997\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 49.2181 - val_loss: 300.1478\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 36.7722 - val_loss: 377.5003\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.2832 - val_loss: 1460.2993\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 28.4124 - val_loss: 801.9886\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 33.5871 - val_loss: 2237.3999\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 35.4197 - val_loss: 1301.5770\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.8468 - val_loss: 419.1469\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.2505 - val_loss: 191.2321\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.4332 - val_loss: 1119.9910\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.1374 - val_loss: 262.3407\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 34.7774 - val_loss: 175.3242\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.2667 - val_loss: 2076.6794\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.9850 - val_loss: 405.6492\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.3072 - val_loss: 287.1695\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.6687 - val_loss: 266.7441\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.6997 - val_loss: 226.9932\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.4820 - val_loss: 87.4984\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.1389 - val_loss: 99.1025\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 34.3658 - val_loss: 79.3374\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.0930 - val_loss: 60.0357\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.0937 - val_loss: 59.5707\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.6000 - val_loss: 56.7842\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 32.3724 - val_loss: 55.6998\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.6257 - val_loss: 59.2956\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.0354 - val_loss: 57.2123\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.8893 - val_loss: 60.5368\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.4612 - val_loss: 59.6045\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 22.7098 - val_loss: 59.2143\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.2111 - val_loss: 59.5341\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.8539 - val_loss: 60.6625\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.2182 - val_loss: 59.7228\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.5684 - val_loss: 59.4825\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.6991 - val_loss: 61.0374\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.2570 - val_loss: 59.8938\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.2257 - val_loss: 59.0267\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.7310 - val_loss: 59.8374\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.9118 - val_loss: 59.6522\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.0125 - val_loss: 59.9728\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.9895 - val_loss: 59.7004\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.4924 - val_loss: 59.7999\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.4611 - val_loss: 59.2182\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.0584 - val_loss: 59.2470\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.8678 - val_loss: 60.2459\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>35</td></tr><tr><td>best_val_loss</td><td>55.69981</td></tr><tr><td>epoch</td><td>55</td></tr><tr><td>loss</td><td>31.86776</td></tr><tr><td>val_loss</td><td>60.24586</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">mild-wood-139</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z0y6ha1y' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z0y6ha1y</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_212342-z0y6ha1y/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-02-01 ---\n",
            "MSE: 53.647278\n",
            "RMSE: 7.32443\n",
            "-------------------------------------------\n",
            "Train shape: (541020, 10, 1), (541020, 4)\n",
            "Val shape: (57408, 10, 1), (57408, 4)\n",
            "Test shape: (74416, 10, 1), (74416, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_213748-t4iwa7wy</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/t4iwa7wy' target=\"_blank\">lunar-firebrand-140</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/t4iwa7wy' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/t4iwa7wy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 56s 127ms/step - loss: 74577.8672 - val_loss: 89758.2422\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 1579.3749 - val_loss: 96454.4844\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 139.3574 - val_loss: 44953.1367\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 87.5276 - val_loss: 24082.7578\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 80.2194 - val_loss: 8017.2744\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 63.2769 - val_loss: 1165.7900\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 61.0598 - val_loss: 2102.1956\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 68.3771 - val_loss: 5515.1641\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 56.2496 - val_loss: 1707.2726\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 41.8882 - val_loss: 642.2024\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 40.5798 - val_loss: 346.4499\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 38.0803 - val_loss: 304.0058\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 38.9841 - val_loss: 447.0106\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 41.4932 - val_loss: 192.4373\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.7338 - val_loss: 224.3916\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 36.4847 - val_loss: 65.4328\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 37.8623 - val_loss: 168.7520\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.4483 - val_loss: 392.9511\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.4085 - val_loss: 181.2782\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 32.4859 - val_loss: 588.2456\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.7822 - val_loss: 121.0542\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.1115 - val_loss: 475.1477\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.3279 - val_loss: 79.1476\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.6772 - val_loss: 54.3922\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.4695 - val_loss: 63.8567\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.2735 - val_loss: 64.0338\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.8288 - val_loss: 116.0098\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.0736 - val_loss: 56.4540\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.8230 - val_loss: 57.7387\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.3409 - val_loss: 55.3793\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.6422 - val_loss: 62.9958\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.5507 - val_loss: 62.9503\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.2920 - val_loss: 58.8348\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.5785 - val_loss: 56.4301\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.5782 - val_loss: 52.0447\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 24.7307 - val_loss: 51.7135\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.7142 - val_loss: 53.6211\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.6228 - val_loss: 56.4829\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.4453 - val_loss: 54.4291\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.9479 - val_loss: 53.1195\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.2305 - val_loss: 54.1265\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.7209 - val_loss: 53.3401\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.2809 - val_loss: 53.2789\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.8976 - val_loss: 52.6406\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.1140 - val_loss: 53.1700\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 24.6726 - val_loss: 53.3833\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.1574 - val_loss: 53.5170\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.5581 - val_loss: 53.5350\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.4715 - val_loss: 53.4062\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.1316 - val_loss: 53.3527\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.4651 - val_loss: 52.8963\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.7852 - val_loss: 53.6432\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 31.0294 - val_loss: 53.5658\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.3144 - val_loss: 53.5774\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.5208 - val_loss: 53.3156\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a24504366a454e509afbc7db6656f525",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>35</td></tr><tr><td>best_val_loss</td><td>51.71345</td></tr><tr><td>epoch</td><td>54</td></tr><tr><td>loss</td><td>26.52078</td></tr><tr><td>val_loss</td><td>53.31557</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lunar-firebrand-140</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/t4iwa7wy' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/t4iwa7wy</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_213748-t4iwa7wy/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-03-01 ---\n",
            "MSE: 336.94083\n",
            "RMSE: 18.355947\n",
            "-------------------------------------------\n",
            "Train shape: (556765, 10, 1), (556765, 4)\n",
            "Val shape: (74398, 10, 1), (74398, 4)\n",
            "Test shape: (71379, 10, 1), (71379, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_215138-9zzeukms</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/9zzeukms' target=\"_blank\">stellar-vortex-141</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/9zzeukms' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/9zzeukms</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 55s 126ms/step - loss: 70784.0078 - val_loss: 140621.5781\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 1189.9272 - val_loss: 104410.9609\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 165.1883 - val_loss: 64169.4023\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 131.2587 - val_loss: 18111.9043\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 74.0137 - val_loss: 5459.0747\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 60.3205 - val_loss: 3974.2742\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 64.4937 - val_loss: 116.4648\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 52.8231 - val_loss: 951.1582\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 56.7527 - val_loss: 4646.0840\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 44.8628 - val_loss: 623.1132\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.1702 - val_loss: 2656.2207\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 49.4667 - val_loss: 5789.8569\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.3077 - val_loss: 140.9583\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.9034 - val_loss: 237.8856\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 48.0673 - val_loss: 366.9093\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 37.9324 - val_loss: 213.1624\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 37.3678 - val_loss: 316.2164\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.9729 - val_loss: 109.5982\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.2572 - val_loss: 352.2969\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 36.9023 - val_loss: 127.0733\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 36.5456 - val_loss: 147.7481\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 33.0412 - val_loss: 508.8580\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.8431 - val_loss: 169.4352\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 28.7445 - val_loss: 126.3007\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.8054 - val_loss: 72.8833\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.0221 - val_loss: 116.7094\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.7125 - val_loss: 142.5861\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.9032 - val_loss: 180.7392\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.7331 - val_loss: 103.0157\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.5148 - val_loss: 98.3738\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 34.2531 - val_loss: 79.9926\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.9695 - val_loss: 52.7288\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 32.0093 - val_loss: 74.2840\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.6364 - val_loss: 66.2259\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.4833 - val_loss: 67.2042\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.4627 - val_loss: 64.2159\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.6014 - val_loss: 65.2243\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.8332 - val_loss: 57.5700\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.9709 - val_loss: 64.2855\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.3447 - val_loss: 62.7354\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.0352 - val_loss: 61.1987\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 24.9924 - val_loss: 60.4367\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.2309 - val_loss: 61.7714\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.8530 - val_loss: 64.9012\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.0800 - val_loss: 59.4371\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.8054 - val_loss: 62.2355\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.8111 - val_loss: 62.7271\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.2000 - val_loss: 62.9330\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 39.7112 - val_loss: 61.7875\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.5992 - val_loss: 62.4043\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.0130 - val_loss: 60.9849\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.5316 - val_loss: 61.6615\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18106aa96553436080facdcebc0a36ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>31</td></tr><tr><td>best_val_loss</td><td>52.72877</td></tr><tr><td>epoch</td><td>51</td></tr><tr><td>loss</td><td>30.53163</td></tr><tr><td>val_loss</td><td>61.66154</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stellar-vortex-141</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/9zzeukms' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/9zzeukms</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_215138-9zzeukms/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-04-01 ---\n",
            "MSE: 306.1138\n",
            "RMSE: 17.496107\n",
            "-------------------------------------------\n",
            "Train shape: (591120, 10, 1), (591120, 4)\n",
            "Val shape: (71352, 10, 1), (71352, 4)\n",
            "Test shape: (68404, 10, 1), (68404, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_220459-6wpsiqfl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/6wpsiqfl' target=\"_blank\">jumping-darkness-142</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/6wpsiqfl' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/6wpsiqfl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 56s 128ms/step - loss: 72926.1016 - val_loss: 92424.4453\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 1298.3966 - val_loss: 144077.3594\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 135.5747 - val_loss: 41969.5898\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 85.7741 - val_loss: 20070.8496\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 90.8223 - val_loss: 22430.1113\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 55.7999 - val_loss: 12770.7070\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 58.3449 - val_loss: 11433.1992\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 51.7264 - val_loss: 16057.9326\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 72.7809 - val_loss: 7089.2651\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 52.7260 - val_loss: 1207.5189\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 41.7278 - val_loss: 2306.5637\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 47.5579 - val_loss: 2712.7949\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 42.3049 - val_loss: 1166.7299\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 39.8995 - val_loss: 553.3205\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 44.3652 - val_loss: 325.2915\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 37.3102 - val_loss: 3339.2954\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.7663 - val_loss: 748.8587\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 33.5144 - val_loss: 588.0928\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 37.7796 - val_loss: 959.8071\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 36.1507 - val_loss: 346.8249\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.8236 - val_loss: 1578.2889\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 32.6134 - val_loss: 1453.9167\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.4753 - val_loss: 77.3475\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.7696 - val_loss: 155.8834\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 36.4639 - val_loss: 324.4415\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.2625 - val_loss: 143.3581\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.0441 - val_loss: 97.2967\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.2313 - val_loss: 121.2734\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.0597 - val_loss: 129.6796\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.9319 - val_loss: 100.8217\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.2662 - val_loss: 83.0797\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.1366 - val_loss: 104.4439\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.2340 - val_loss: 113.0635\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.3998 - val_loss: 77.2956\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.5263 - val_loss: 91.4298\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.2979 - val_loss: 57.7665\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.1444 - val_loss: 56.3373\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.1788 - val_loss: 57.2316\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.7182 - val_loss: 60.5126\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.7350 - val_loss: 63.9336\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.2402 - val_loss: 60.0704\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.7575 - val_loss: 65.3363\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.1892 - val_loss: 58.3772\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.9452 - val_loss: 58.4166\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.4755 - val_loss: 59.2835\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.3116 - val_loss: 58.3858\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 21.5002 - val_loss: 57.8562\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.4555 - val_loss: 57.7796\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.0715 - val_loss: 59.3272\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 27.7158 - val_loss: 57.5472\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.4891 - val_loss: 57.0472\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.2640 - val_loss: 56.9108\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.7182 - val_loss: 56.9720\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 23.8746 - val_loss: 56.8865\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.9700 - val_loss: 56.7075\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.1192 - val_loss: 56.1655\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.6520 - val_loss: 55.7467\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c40fe5dd9da45109ddbcedef2edc13b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.024 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.238677…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▅█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>56</td></tr><tr><td>best_val_loss</td><td>55.74666</td></tr><tr><td>epoch</td><td>56</td></tr><tr><td>loss</td><td>25.65199</td></tr><tr><td>val_loss</td><td>55.74666</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">jumping-darkness-142</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/6wpsiqfl' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/6wpsiqfl</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_220459-6wpsiqfl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-05-01 ---\n",
            "MSE: 832.692\n",
            "RMSE: 28.856403\n",
            "-------------------------------------------\n",
            "Train shape: (621554, 10, 1), (621554, 4)\n",
            "Val shape: (68407, 10, 1), (68407, 4)\n",
            "Test shape: (79002, 10, 1), (79002, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_221923-67siv0n7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/67siv0n7' target=\"_blank\">dauntless-darkness-143</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/67siv0n7' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/67siv0n7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 56s 128ms/step - loss: 70739.1172 - val_loss: 162255.8594\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 1131.7830 - val_loss: 72852.3281\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 121.1807 - val_loss: 41155.0117\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 98.3651 - val_loss: 80303.3750\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 89.1020 - val_loss: 24030.0137\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 53.0228 - val_loss: 46049.8555\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 68.1749 - val_loss: 15518.1348\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 57.1275 - val_loss: 1162.3147\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 55.8410 - val_loss: 16866.4785\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 45.5825 - val_loss: 29932.7793\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.1283 - val_loss: 10540.6924\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 40.8305 - val_loss: 37986.1484\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 37.4710 - val_loss: 2127.4048\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 40.1085 - val_loss: 21317.0352\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.4477 - val_loss: 7300.4893\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 34.3150 - val_loss: 4045.7861\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 32.8455 - val_loss: 1909.3224\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.9468 - val_loss: 8968.5674\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.9338 - val_loss: 3838.4976\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.2747 - val_loss: 8055.7676\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.3814 - val_loss: 6522.4756\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.1018 - val_loss: 1371.5627\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 33.4936 - val_loss: 1284.2781\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.8213 - val_loss: 2792.6802\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 26.6847 - val_loss: 777.2249\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.5261 - val_loss: 159.4815\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 22.3838 - val_loss: 732.0197\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.5232 - val_loss: 411.2083\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 33.3780 - val_loss: 685.8807\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 33.4936 - val_loss: 175.0076\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.1234 - val_loss: 76.3316\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.6958 - val_loss: 65.6966\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.2910 - val_loss: 278.0389\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.8605 - val_loss: 97.7197\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.3094 - val_loss: 52.4477\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.3661 - val_loss: 100.5111\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.1777 - val_loss: 46.5840\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 26.9295 - val_loss: 47.9897\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.0904 - val_loss: 55.4837\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.8963 - val_loss: 48.4281\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 24.9823 - val_loss: 53.0097\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.7430 - val_loss: 41.4104\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.5265 - val_loss: 38.7109\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.6156 - val_loss: 38.3138\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 28.3704 - val_loss: 39.2339\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.0090 - val_loss: 39.2384\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.6805 - val_loss: 40.2040\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.0853 - val_loss: 39.9604\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.1692 - val_loss: 38.7442\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 31.4800 - val_loss: 40.6896\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 27.3016 - val_loss: 39.8071\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.7473 - val_loss: 39.5558\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.7262 - val_loss: 39.0775\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 23.9105 - val_loss: 39.7888\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.2867 - val_loss: 39.8333\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.4626 - val_loss: 39.1806\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.6175 - val_loss: 39.8241\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.0852 - val_loss: 39.3957\n",
            "Epoch 59/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 23.3566 - val_loss: 39.3584\n",
            "Epoch 60/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.6262 - val_loss: 39.0141\n",
            "Epoch 61/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 24.4508 - val_loss: 39.3887\n",
            "Epoch 62/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.7840 - val_loss: 39.4852\n",
            "Epoch 63/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.7088 - val_loss: 39.2835\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb0073403edd4e9a834e4c0d0878b547",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▄▂▂▁▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>43</td></tr><tr><td>best_val_loss</td><td>38.31377</td></tr><tr><td>epoch</td><td>62</td></tr><tr><td>loss</td><td>29.7088</td></tr><tr><td>val_loss</td><td>39.2835</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dauntless-darkness-143</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/67siv0n7' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/67siv0n7</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_221923-67siv0n7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-06-01 ---\n",
            "MSE: 772.3603\n",
            "RMSE: 27.79137\n",
            "-------------------------------------------\n",
            "Train shape: (648342, 10, 1), (648342, 4)\n",
            "Val shape: (78975, 10, 1), (78975, 4)\n",
            "Test shape: (78559, 10, 1), (78559, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_223511-hy656ov9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/hy656ov9' target=\"_blank\">electric-vortex-144</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/hy656ov9' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/hy656ov9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 56s 126ms/step - loss: 72401.6250 - val_loss: 62650.8047\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 1279.2488 - val_loss: 82570.2109\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 121.3366 - val_loss: 34782.5977\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 139.1726 - val_loss: 9746.0674\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 80.2374 - val_loss: 12638.2734\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 66.4124 - val_loss: 1894.0933\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 62.2892 - val_loss: 584.8549\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 50.6325 - val_loss: 128.8962\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 51.2800 - val_loss: 998.4935\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 38.5218 - val_loss: 560.4194\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 49.6368 - val_loss: 3061.2234\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 72ms/step - loss: 42.5696 - val_loss: 650.1195\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 41.6539 - val_loss: 109.9103\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 43.1757 - val_loss: 6538.3125\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 40.6547 - val_loss: 225.0829\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 38.1362 - val_loss: 202.5072\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 37.7462 - val_loss: 90.8744\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 34.1479 - val_loss: 78.1628\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 41.4883 - val_loss: 289.4926\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 33.2354 - val_loss: 104.1604\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 33.0184 - val_loss: 124.7040\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.3708 - val_loss: 105.9737\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 31.0571 - val_loss: 76.6224\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 31.3584 - val_loss: 118.7150\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 34.0969 - val_loss: 74.9658\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 35.2122 - val_loss: 57.3231\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 36.4020 - val_loss: 64.2241\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 34.1627 - val_loss: 72.9531\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.6952 - val_loss: 60.4248\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.3692 - val_loss: 61.3358\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.0973 - val_loss: 49.2259\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 31.7084 - val_loss: 56.8706\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.2048 - val_loss: 50.3072\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 27.6887 - val_loss: 46.7538\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.2866 - val_loss: 48.5648\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 29.5648 - val_loss: 46.2109\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.8385 - val_loss: 47.9851\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.0585 - val_loss: 45.1587\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.5193 - val_loss: 45.0076\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.3514 - val_loss: 47.0617\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.0955 - val_loss: 49.0347\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.9620 - val_loss: 45.8698\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.0419 - val_loss: 46.2088\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.2198 - val_loss: 46.1595\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.3368 - val_loss: 46.2123\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 31.7981 - val_loss: 46.4359\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.4743 - val_loss: 45.9702\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 24.5998 - val_loss: 45.7145\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.9366 - val_loss: 47.1262\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.4566 - val_loss: 46.8347\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 31.2279 - val_loss: 46.2156\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.0275 - val_loss: 46.7972\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.8123 - val_loss: 46.6004\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 26.3326 - val_loss: 45.9463\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.1806 - val_loss: 46.0160\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 28.9722 - val_loss: 46.0685\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.9187 - val_loss: 45.8561\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 31.9068 - val_loss: 45.6993\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d53f5b75d24d41ae907ffac6415d8b96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.024 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.237819…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆█▄▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>38</td></tr><tr><td>best_val_loss</td><td>45.00758</td></tr><tr><td>epoch</td><td>57</td></tr><tr><td>loss</td><td>31.90676</td></tr><tr><td>val_loss</td><td>45.69932</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">electric-vortex-144</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/hy656ov9' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/hy656ov9</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_223511-hy656ov9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-07-01 ---\n",
            "MSE: 423.33423\n",
            "RMSE: 20.575087\n",
            "-------------------------------------------\n",
            "Train shape: (680932, 10, 1), (680932, 4)\n",
            "Val shape: (78530, 10, 1), (78530, 4)\n",
            "Test shape: (76774, 10, 1), (76774, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_225001-z59fuqnt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z59fuqnt' target=\"_blank\">ruby-haze-145</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z59fuqnt' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z59fuqnt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 56s 128ms/step - loss: 69623.3984 - val_loss: 122630.1562\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 991.2825 - val_loss: 123793.8516\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 142.8956 - val_loss: 48359.6016\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 85.6912 - val_loss: 16453.1855\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 84.0889 - val_loss: 3291.8909\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 62.1510 - val_loss: 5860.5537\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 61.1573 - val_loss: 1012.5307\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 65.1943 - val_loss: 64498.8711\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 58.9343 - val_loss: 21609.9570\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 53.2442 - val_loss: 4557.6904\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 52.1507 - val_loss: 66844.1406\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 43.9197 - val_loss: 403.5908\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 37.2974 - val_loss: 39965.3984\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 47.2798 - val_loss: 466.5159\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 35.3902 - val_loss: 55052.0898\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 43.9202 - val_loss: 8051.0581\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 38.3958 - val_loss: 45813.4258\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 35.2718 - val_loss: 2891.2646\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 32.3948 - val_loss: 460.3210\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 40.7865 - val_loss: 519.3215\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 39.0172 - val_loss: 171.4523\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 29.2858 - val_loss: 1409.6183\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 30.3490 - val_loss: 1058.3525\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 30.2296 - val_loss: 8632.8770\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 34.1096 - val_loss: 201.8048\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 31.0333 - val_loss: 447.5237\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 31.3354 - val_loss: 9613.0098\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 36.1779 - val_loss: 8784.4756\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 31.6826 - val_loss: 179.7155\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 34.6722 - val_loss: 326.6308\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 29.2267 - val_loss: 5171.9673\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 28.0864 - val_loss: 849.4394\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.8856 - val_loss: 505.8193\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.7900 - val_loss: 104.9267\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 73ms/step - loss: 25.4514 - val_loss: 129.5730\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.8103 - val_loss: 70.3666\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 28.6483 - val_loss: 292.8843\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.1038 - val_loss: 113.7038\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.6112 - val_loss: 62.0575\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 24.7938 - val_loss: 73.4802\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 26.9354 - val_loss: 41.5764\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.3594 - val_loss: 44.2286\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.3685 - val_loss: 51.6771\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.2727 - val_loss: 39.0504\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.3656 - val_loss: 40.2970\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 26.5087 - val_loss: 41.5500\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 29.5573 - val_loss: 49.9103\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 31.3518 - val_loss: 39.2280\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 26.0886 - val_loss: 38.2564\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 35.3581 - val_loss: 39.7688\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.0567 - val_loss: 40.3178\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.2579 - val_loss: 40.5926\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 24.6932 - val_loss: 42.4788\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 27.9142 - val_loss: 40.7027\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 24.3902 - val_loss: 38.8074\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.8210 - val_loss: 38.5979\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.5600 - val_loss: 39.3064\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.5681 - val_loss: 38.8936\n",
            "Epoch 59/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.7036 - val_loss: 38.4579\n",
            "Epoch 60/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 25.2062 - val_loss: 38.7526\n",
            "Epoch 61/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.9360 - val_loss: 38.8443\n",
            "Epoch 62/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.0828 - val_loss: 39.1302\n",
            "Epoch 63/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 20.5080 - val_loss: 39.3743\n",
            "Epoch 64/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.5217 - val_loss: 38.9148\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab014efc18054082b64c36d22288c589",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▂▁▁▂▁▁▃▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>48</td></tr><tr><td>best_val_loss</td><td>38.2564</td></tr><tr><td>epoch</td><td>63</td></tr><tr><td>loss</td><td>26.5217</td></tr><tr><td>val_loss</td><td>38.91477</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-haze-145</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z59fuqnt' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/z59fuqnt</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_225001-z59fuqnt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-08-01 ---\n",
            "MSE: 600.76654\n",
            "RMSE: 24.510538\n",
            "-------------------------------------------\n",
            "Train shape: (713947, 10, 1), (713947, 4)\n",
            "Val shape: (76774, 10, 1), (76774, 4)\n",
            "Test shape: (77095, 10, 1), (77095, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_230616-wunii6j0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/wunii6j0' target=\"_blank\">super-wood-146</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/wunii6j0' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/wunii6j0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 57s 129ms/step - loss: 70452.1406 - val_loss: 108645.5781\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 982.8450 - val_loss: 77174.7578\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 166.4225 - val_loss: 34087.5312\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 77.8244 - val_loss: 33546.3945\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 81.3238 - val_loss: 5120.4448\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 50.8739 - val_loss: 10592.5938\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 70.5651 - val_loss: 2136.4915\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 47.6205 - val_loss: 18600.6035\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 52.5200 - val_loss: 4385.1089\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 43.5440 - val_loss: 3182.5413\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 44.5274 - val_loss: 4036.8899\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 46.1641 - val_loss: 58710.7109\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 45.2995 - val_loss: 440.2866\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 34.8325 - val_loss: 2807.7632\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 45.8403 - val_loss: 755.1228\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 39.2993 - val_loss: 336.1011\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 35.6636 - val_loss: 613.5728\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 27.9205 - val_loss: 490.4419\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 34.3786 - val_loss: 631.8000\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.8179 - val_loss: 581.9258\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.1544 - val_loss: 3189.7170\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 36.4972 - val_loss: 1069.4384\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 29.2282 - val_loss: 71.0735\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.7119 - val_loss: 1350.4071\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.6508 - val_loss: 3997.0261\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 31.3309 - val_loss: 3490.8931\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 36.3941 - val_loss: 50.9822\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.1598 - val_loss: 81.3828\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.2849 - val_loss: 211.9924\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 38.9861 - val_loss: 188.8164\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.2062 - val_loss: 223.2376\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.5038 - val_loss: 64.8800\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.0440 - val_loss: 194.9021\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.6827 - val_loss: 105.6905\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.4733 - val_loss: 111.6884\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 28.5345 - val_loss: 37.3321\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 31.5175 - val_loss: 62.2755\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.7118 - val_loss: 51.0832\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 30.0497 - val_loss: 142.3475\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 20.8884 - val_loss: 93.0672\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 25.8252 - val_loss: 48.9603\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.8007 - val_loss: 43.4941\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 78ms/step - loss: 27.3283 - val_loss: 37.0935\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.7318 - val_loss: 41.0770\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 25.3282 - val_loss: 37.0056\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.2764 - val_loss: 38.0159\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 26.1953 - val_loss: 33.4853\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.4895 - val_loss: 35.0427\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 23.2089 - val_loss: 33.9537\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 23.8786 - val_loss: 32.8717\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 22.8430 - val_loss: 32.4098\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 21.5952 - val_loss: 32.3704\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.4072 - val_loss: 34.3019\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.4397 - val_loss: 32.9417\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 25.0777 - val_loss: 32.8395\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.4742 - val_loss: 34.2877\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 24.2627 - val_loss: 31.8774\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.1036 - val_loss: 32.3292\n",
            "Epoch 59/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.1307 - val_loss: 33.2197\n",
            "Epoch 60/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 26.5933 - val_loss: 32.2108\n",
            "Epoch 61/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.4133 - val_loss: 32.1363\n",
            "Epoch 62/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.3623 - val_loss: 32.1306\n",
            "Epoch 63/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 24.4816 - val_loss: 32.0159\n",
            "Epoch 64/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.4015 - val_loss: 33.0806\n",
            "Epoch 65/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.1767 - val_loss: 32.5575\n",
            "Epoch 66/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 22.6744 - val_loss: 32.3584\n",
            "Epoch 67/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 21.1149 - val_loss: 32.8499\n",
            "Epoch 68/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 24.7193 - val_loss: 33.1841\n",
            "Epoch 69/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 23.7670 - val_loss: 33.2629\n",
            "Epoch 70/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.6022 - val_loss: 32.0506\n",
            "Epoch 71/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.0525 - val_loss: 31.8922\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f752fe74cf114e7f80924ead3f15667a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.025 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.224691…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>56</td></tr><tr><td>best_val_loss</td><td>31.87735</td></tr><tr><td>epoch</td><td>70</td></tr><tr><td>loss</td><td>28.05248</td></tr><tr><td>val_loss</td><td>31.89218</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">super-wood-146</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/wunii6j0' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/wunii6j0</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_230616-wunii6j0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-09-01 ---\n",
            "MSE: 309.18256\n",
            "RMSE: 17.583588\n",
            "-------------------------------------------\n",
            "Train shape: (740400, 10, 1), (740400, 4)\n",
            "Val shape: (78210, 10, 1), (78210, 4)\n",
            "Test shape: (75249, 10, 1), (75249, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_232420-3a4qnnuw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/3a4qnnuw' target=\"_blank\">ruby-fire-147</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/3a4qnnuw' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/3a4qnnuw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 57s 131ms/step - loss: 71786.3281 - val_loss: 72162.4922\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 15s 76ms/step - loss: 1103.7490 - val_loss: 93821.1875\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 143.9490 - val_loss: 39635.7109\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 15s 79ms/step - loss: 93.1235 - val_loss: 10543.3477\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 77.1528 - val_loss: 56229.3086\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 59.6639 - val_loss: 26486.5410\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 64.6472 - val_loss: 24306.3750\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 45.0631 - val_loss: 19811.2363\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 48.5216 - val_loss: 3954.4832\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 15s 79ms/step - loss: 52.1697 - val_loss: 2665.6448\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 49.7766 - val_loss: 932.6945\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 53.4818 - val_loss: 9868.4297\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 38.5933 - val_loss: 837.7165\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 46.8402 - val_loss: 2412.6218\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 46.5122 - val_loss: 608.6005\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 47.8335 - val_loss: 1148.9442\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 39.4480 - val_loss: 355.3407\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 33.8161 - val_loss: 4530.8896\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 38.6213 - val_loss: 1401.5890\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 35.6392 - val_loss: 593.8354\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 31.0767 - val_loss: 713.3484\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 35.2851 - val_loss: 788.9888\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 34.7908 - val_loss: 67.2687\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.1145 - val_loss: 110.3841\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.2933 - val_loss: 75.5390\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.6748 - val_loss: 132.7057\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.4198 - val_loss: 97.3288\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 35.2463 - val_loss: 425.7937\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.5275 - val_loss: 215.3477\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.1592 - val_loss: 237.5255\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.2538 - val_loss: 112.5701\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.8565 - val_loss: 107.0881\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.3549 - val_loss: 70.1080\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.8431 - val_loss: 88.3099\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.0867 - val_loss: 71.8054\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 27.4324 - val_loss: 89.8922\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.5607 - val_loss: 124.8714\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 30.3004 - val_loss: 91.7155\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.6544 - val_loss: 89.1330\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 25.8146 - val_loss: 64.1339\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.3970 - val_loss: 81.2485\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.7756 - val_loss: 109.5203\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.0432 - val_loss: 73.8465\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.4116 - val_loss: 65.6275\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.2466 - val_loss: 69.5381\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 25.1678 - val_loss: 57.7998\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.8733 - val_loss: 60.1828\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.4595 - val_loss: 55.5406\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.1525 - val_loss: 57.4189\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 27.3305 - val_loss: 60.5192\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.1762 - val_loss: 63.3606\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.6704 - val_loss: 59.4619\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.6853 - val_loss: 59.4697\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 23.5086 - val_loss: 59.8692\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.8332 - val_loss: 57.4838\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 28.3222 - val_loss: 58.7047\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.2111 - val_loss: 56.7751\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 24.3371 - val_loss: 57.2239\n",
            "Epoch 59/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 24.7559 - val_loss: 54.9399\n",
            "Epoch 60/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 24.2859 - val_loss: 56.6173\n",
            "Epoch 61/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.7369 - val_loss: 56.2320\n",
            "Epoch 62/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 26.4310 - val_loss: 54.7974\n",
            "Epoch 63/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 23.7931 - val_loss: 55.3800\n",
            "Epoch 64/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 31.0104 - val_loss: 54.7576\n",
            "Epoch 65/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.1439 - val_loss: 54.9631\n",
            "Epoch 66/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.5558 - val_loss: 55.3365\n",
            "Epoch 67/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.7629 - val_loss: 55.6158\n",
            "Epoch 68/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.2994 - val_loss: 54.8927\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cb63e85178a4c489dc45736c6aeb033",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆█▂▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>63</td></tr><tr><td>best_val_loss</td><td>54.75764</td></tr><tr><td>epoch</td><td>67</td></tr><tr><td>loss</td><td>29.29945</td></tr><tr><td>val_loss</td><td>54.89272</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ruby-fire-147</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/3a4qnnuw' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/3a4qnnuw</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_232420-3a4qnnuw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-10-01 ---\n",
            "MSE: 222.44368\n",
            "RMSE: 14.914546\n",
            "-------------------------------------------\n",
            "Train shape: (765789, 10, 1), (765789, 4)\n",
            "Val shape: (76187, 10, 1), (76187, 4)\n",
            "Test shape: (69124, 10, 1), (69124, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_234143-h4h7year</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/h4h7year' target=\"_blank\">swept-sun-148</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/h4h7year' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/h4h7year</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 57s 130ms/step - loss: 70420.7891 - val_loss: 106622.6797\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 987.5029 - val_loss: 82357.7656\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 78ms/step - loss: 132.1037 - val_loss: 35834.8672\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 74.7071 - val_loss: 22262.2793\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 81.0224 - val_loss: 6835.8799\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 66.2025 - val_loss: 2605.9167\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 64.0494 - val_loss: 5051.5366\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 58.2168 - val_loss: 5113.6509\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 52.8829 - val_loss: 7503.2471\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 53.7352 - val_loss: 3087.2996\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 41.4068 - val_loss: 1549.4331\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 47.1659 - val_loss: 3801.4583\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 50.4967 - val_loss: 1298.4111\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 46.9226 - val_loss: 7436.0312\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 39.3516 - val_loss: 11011.4756\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 44.7259 - val_loss: 3232.6389\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 35.7316 - val_loss: 3563.3369\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 36.3424 - val_loss: 4628.2651\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 38.0062 - val_loss: 821.6190\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 37.5272 - val_loss: 1674.0503\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.3191 - val_loss: 3515.5090\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 36.2224 - val_loss: 371.0111\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 39.8299 - val_loss: 1191.2072\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 36.8033 - val_loss: 511.9954\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 31.6330 - val_loss: 117.0358\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 27.9216 - val_loss: 114.1677\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.1828 - val_loss: 160.1028\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 33.5995 - val_loss: 83.8330\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 27.7817 - val_loss: 59.8339\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.2273 - val_loss: 130.7640\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.7095 - val_loss: 367.7774\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.5541 - val_loss: 61.7468\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.1530 - val_loss: 91.3477\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 32.1045 - val_loss: 50.0426\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.8761 - val_loss: 72.3204\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 29.3235 - val_loss: 109.4748\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 31.1877 - val_loss: 62.6124\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.7687 - val_loss: 66.0279\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 31.9394 - val_loss: 62.7944\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.1583 - val_loss: 56.1529\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 24.3215 - val_loss: 47.5874\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.6067 - val_loss: 60.2710\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.5876 - val_loss: 49.6435\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.4018 - val_loss: 47.9894\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.7439 - val_loss: 45.9431\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.1589 - val_loss: 47.1101\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.3239 - val_loss: 49.6181\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.3118 - val_loss: 50.1677\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.7234 - val_loss: 49.6844\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 27.1853 - val_loss: 45.2103\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 30.7806 - val_loss: 53.0908\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.3832 - val_loss: 45.8048\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 28.2245 - val_loss: 47.2230\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.2422 - val_loss: 46.2182\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.7434 - val_loss: 48.3360\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.0605 - val_loss: 46.8010\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 32.1516 - val_loss: 47.2259\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.4415 - val_loss: 45.9921\n",
            "Epoch 59/1000\n",
            "122/122 [==============================] - 14s 74ms/step - loss: 24.8589 - val_loss: 47.1822\n",
            "Epoch 60/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.1359 - val_loss: 46.0284\n",
            "Epoch 61/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 25.4439 - val_loss: 45.6546\n",
            "Epoch 62/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 26.8677 - val_loss: 45.7908\n",
            "Epoch 63/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.1720 - val_loss: 45.6728\n",
            "Epoch 64/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 30.1926 - val_loss: 45.1620\n",
            "Epoch 65/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 23.1442 - val_loss: 45.4961\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e34a05cb5c54e5885dfc082ebcdefe1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>63</td></tr><tr><td>best_val_loss</td><td>45.16199</td></tr><tr><td>epoch</td><td>64</td></tr><tr><td>loss</td><td>23.14417</td></tr><tr><td>val_loss</td><td>45.49609</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">swept-sun-148</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/h4h7year' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/h4h7year</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_234143-h4h7year/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-11-01 ---\n",
            "MSE: 540.92773\n",
            "RMSE: 23.257853\n",
            "-------------------------------------------\n",
            "Train shape: (791161, 10, 1), (791161, 4)\n",
            "Val shape: (69465, 10, 1), (69465, 4)\n",
            "Test shape: (73808, 10, 1), (73808, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230412_235819-kc26kv6g</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/kc26kv6g' target=\"_blank\">polished-snow-149</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/kc26kv6g' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/kc26kv6g</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           2016        ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 84)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          51000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (496184, 10, 1), (496184, 10, 1)\n",
            "Val shape: (61101, 10, 1), (61101, 10, 1)\n",
            "Epoch 1/1000\n",
            "122/122 [==============================] - 57s 130ms/step - loss: 71439.8672 - val_loss: 117580.9844\n",
            "Epoch 2/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 1013.2366 - val_loss: 89804.2969\n",
            "Epoch 3/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 115.5009 - val_loss: 38866.8945\n",
            "Epoch 4/1000\n",
            "122/122 [==============================] - 14s 78ms/step - loss: 120.2335 - val_loss: 14490.2354\n",
            "Epoch 5/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 81.0020 - val_loss: 915.0966\n",
            "Epoch 6/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 59.0503 - val_loss: 7151.2612\n",
            "Epoch 7/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 54.4392 - val_loss: 20476.3652\n",
            "Epoch 8/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 68.5565 - val_loss: 31935.2129\n",
            "Epoch 9/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 49.7711 - val_loss: 5047.0063\n",
            "Epoch 10/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 47.0761 - val_loss: 1966.5509\n",
            "Epoch 11/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 44.0485 - val_loss: 966.6024\n",
            "Epoch 12/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 47.8606 - val_loss: 3718.7593\n",
            "Epoch 13/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 44.8184 - val_loss: 1513.0812\n",
            "Epoch 14/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 41.5778 - val_loss: 10323.5908\n",
            "Epoch 15/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 37.0941 - val_loss: 11380.3379\n",
            "Epoch 16/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.2465 - val_loss: 11822.0879\n",
            "Epoch 17/1000\n",
            "122/122 [==============================] - 14s 78ms/step - loss: 40.2900 - val_loss: 316.8528\n",
            "Epoch 18/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 34.8291 - val_loss: 1015.4849\n",
            "Epoch 19/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 34.0222 - val_loss: 348.2850\n",
            "Epoch 20/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 32.9983 - val_loss: 139.5972\n",
            "Epoch 21/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.1496 - val_loss: 982.2292\n",
            "Epoch 22/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 34.4430 - val_loss: 245.9864\n",
            "Epoch 23/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 30.0000 - val_loss: 351.5656\n",
            "Epoch 24/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 31.1219 - val_loss: 627.3807\n",
            "Epoch 25/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 32.1300 - val_loss: 318.6087\n",
            "Epoch 26/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 33.9012 - val_loss: 379.7928\n",
            "Epoch 27/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 33.3706 - val_loss: 222.0168\n",
            "Epoch 28/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 25.6558 - val_loss: 269.6374\n",
            "Epoch 29/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 27.8121 - val_loss: 7175.1138\n",
            "Epoch 30/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 32.6421 - val_loss: 2974.2219\n",
            "Epoch 31/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 30.4564 - val_loss: 1104.1108\n",
            "Epoch 32/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.3530 - val_loss: 704.5004\n",
            "Epoch 33/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 32.0123 - val_loss: 216.2857\n",
            "Epoch 34/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.5117 - val_loss: 695.3782\n",
            "Epoch 35/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 28.2281 - val_loss: 310.9242\n",
            "Epoch 36/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 22.4404 - val_loss: 99.5494\n",
            "Epoch 37/1000\n",
            "122/122 [==============================] - 14s 75ms/step - loss: 31.2248 - val_loss: 294.6249\n",
            "Epoch 38/1000\n",
            "122/122 [==============================] - 14s 78ms/step - loss: 29.5929 - val_loss: 53.7315\n",
            "Epoch 39/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 31.4407 - val_loss: 43.5539\n",
            "Epoch 40/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 26.1930 - val_loss: 40.5209\n",
            "Epoch 41/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 27.4615 - val_loss: 74.6821\n",
            "Epoch 42/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 28.9691 - val_loss: 41.7839\n",
            "Epoch 43/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 26.4286 - val_loss: 42.5468\n",
            "Epoch 44/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 26.5160 - val_loss: 46.7135\n",
            "Epoch 45/1000\n",
            "122/122 [==============================] - 15s 79ms/step - loss: 30.7917 - val_loss: 46.1451\n",
            "Epoch 46/1000\n",
            "122/122 [==============================] - 15s 79ms/step - loss: 25.1508 - val_loss: 47.4958\n",
            "Epoch 47/1000\n",
            "122/122 [==============================] - 15s 79ms/step - loss: 26.2941 - val_loss: 35.0019\n",
            "Epoch 48/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 25.4190 - val_loss: 32.9241\n",
            "Epoch 49/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 23.5595 - val_loss: 33.8178\n",
            "Epoch 50/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 24.9097 - val_loss: 35.1825\n",
            "Epoch 51/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 25.0001 - val_loss: 39.1172\n",
            "Epoch 52/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 25.8192 - val_loss: 38.0685\n",
            "Epoch 53/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 26.2897 - val_loss: 36.6044\n",
            "Epoch 54/1000\n",
            "122/122 [==============================] - 15s 76ms/step - loss: 25.4765 - val_loss: 35.0970\n",
            "Epoch 55/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 27.3192 - val_loss: 33.1970\n",
            "Epoch 56/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 28.5249 - val_loss: 32.5337\n",
            "Epoch 57/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 24.7011 - val_loss: 34.6328\n",
            "Epoch 58/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.7786 - val_loss: 33.1560\n",
            "Epoch 59/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 26.9754 - val_loss: 35.6234\n",
            "Epoch 60/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 29.4112 - val_loss: 37.5649\n",
            "Epoch 61/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 24.8103 - val_loss: 34.3136\n",
            "Epoch 62/1000\n",
            "122/122 [==============================] - 14s 76ms/step - loss: 31.2391 - val_loss: 34.3808\n",
            "Epoch 63/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 22.1882 - val_loss: 33.5877\n",
            "Epoch 64/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 27.1916 - val_loss: 34.6998\n",
            "Epoch 65/1000\n",
            "122/122 [==============================] - 14s 77ms/step - loss: 24.3940 - val_loss: 33.5441\n",
            "Epoch 66/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 26.0626 - val_loss: 33.9606\n",
            "Epoch 67/1000\n",
            "122/122 [==============================] - 15s 77ms/step - loss: 29.0372 - val_loss: 34.3389\n",
            "Epoch 68/1000\n",
            "122/122 [==============================] - 15s 78ms/step - loss: 24.4508 - val_loss: 33.5509\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0a58c1d50e04d1f85f85b2e59b24f76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▂▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>55</td></tr><tr><td>best_val_loss</td><td>32.53367</td></tr><tr><td>epoch</td><td>67</td></tr><tr><td>loss</td><td>24.45079</td></tr><tr><td>val_loss</td><td>33.55088</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polished-snow-149</strong> at: <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/kc26kv6g' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/kc26kv6g</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230412_235819-kc26kv6g/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           2016        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 84)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          51000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,871,017\n",
            "Trainable params: 1,863,817\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Predictions for test_start 2015-12-01 ---\n",
            "MSE: 301.75302\n",
            "RMSE: 17.371038\n",
            "-------------------------------------------\n",
            "--- All model predictions ---\n",
            "MSE: 409.09164\n",
            "RMSE: 20.226013\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "num_windows = 12 #84\n",
        "\n",
        "config = {\n",
        "    'LSTM_units': 4,\n",
        "    'Interface_units': 16,\n",
        "    'MLP_units': 600,\n",
        "    'LSTM_timesteps': 10,\n",
        "    'LSTM_layers': 6,\n",
        "    'MLP_layers': 7,\n",
        "    'Bn_momentum': 0.99,\n",
        "    'Lr': 0.005,\n",
        "    'Lr_decay': 0.82,\n",
        "    'Minibatch_size': 4096,\n",
        "    'Min_delta': 0.01 if moneyness else 1,\n",
        "    'Patience': 20,\n",
        "    'Num_features': 3 if moneyness else 4, \n",
        "    'Architecture': 'LSTM-MLP v.5.0',\n",
        "}\n",
        "\n",
        "# Ask before training, so that you don't have to verify later\n",
        "from google.colab import drive\n",
        "if google_colab == True:\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "df_test_combined = pd.DataFrame()\n",
        "\n",
        "checkpoint_time = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
        "\n",
        "for window in range(num_windows):\n",
        "    if moneyness:\n",
        "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike, = create_rw_dataset(window)\n",
        "    else:\n",
        "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset(window)\n",
        "\n",
        "    checkpoint_path = f'./checkpoint/{checkpoint_time}/{train_start}/'\n",
        "\n",
        "    config['Dataset'] = f'{train_start} - {val_start} - {test_start}'\n",
        "\n",
        "    trainer(config = config, project = 'Deep learning for option pricing - rolling windows', checkpoint_path = checkpoint_path)\n",
        "    co = config_object(config)\n",
        "    c_model = create_model(co)\n",
        "    c_model.load_weights(checkpoint_path)\n",
        "    predictions = np.array(c_model(test_x))\n",
        "    print(f'--- Predictions for test_start {test_start} ---')\n",
        "    calculate_error(predictions, test_y)\n",
        "    print('-------------------------------------------')\n",
        "    df_test[\"Prediction\"] = predictions\n",
        "    df_test_combined = pd.concat([df_test_combined, df_test[[\"Quote_date\", \"Price\", \"Prediction\"] + bs_vars]])\n",
        "\n",
        "\n",
        "print(f\"--- All model predictions ---\")\n",
        "calculate_error(df_test_combined[\"Prediction\"], df_test_combined[\"Price\"])\n",
        "print(\"-------------------------------------------\")\n",
        "\n",
        "if google_colab == False:\n",
        "    predictions_path = './predictions/'\n",
        "    if checkpoint_path and not os.path.exists(predictions_path):\n",
        "        os.makedirs(predictions_path)\n",
        "    df_test_combined.to_csv(f'{predictions_path}{datetime.now().strftime(\"%m-%d_%H-%M\")}.csv')\n",
        "\n",
        "if google_colab == True:\n",
        "  from google.colab import drive\n",
        "  path = '/content/drive/My Drive/Predictions/predictions_2015_v5.csv'\n",
        "  with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "    df_test_combined.to_csv(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucgo2McGTnkt"
      },
      "source": [
        "### Load single model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YggplbxMTnkt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19e93ec1-9661-4d2f-e72c-b59eb05a6f71"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (520744, 10, 1), (520744, 4)\n",
            "Val shape: (55791, 10, 1), (55791, 4)\n",
            "Test shape: (57437, 10, 1), (57437, 4)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 4)            384         ['input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 24)           0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_1[1][0]',           \n",
            "                                                                  'sequential_1[2][0]',           \n",
            "                                                                  'sequential_1[3][0]',           \n",
            "                                                                  'sequential_1[4][0]',           \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 600)          15000       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 600)         2400        ['dense_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 600)          0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 600)          360600      ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 600)         2400        ['dense_8[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 600)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 600)          360600      ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 600)         2400        ['dense_9[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 600)          0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 600)          360600      ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 600)         2400        ['dense_10[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 600)          0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 600)          360600      ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 600)         2400        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 600)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 600)          360600      ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 600)         2400        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 600)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            601         ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,833,385\n",
            "Trainable params: 1,826,185\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "ename": "NotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-030cd1a8841c>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'--- Predictions for {test_start} ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;34m'Failed to find any '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[1;32m     33\u001b[0m       \u001b[0;34m'Data type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/03-20_12-35/2014-02-01/"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    'LSTM_units': 4,\n",
        "    'Interface_units': 4,\n",
        "    'MLP_units': 600,\n",
        "    'LSTM_timesteps': 10,\n",
        "    'LSTM_layers': 3,\n",
        "    'MLP_layers': 7,\n",
        "    'Bn_momentum': 0.99,\n",
        "    'Lr': 0.0001,\n",
        "    'Lr_decay': 0.92,\n",
        "    'Minibatch_size': 4096,\n",
        "    'Min_delta': 0.01 if moneyness else 1,\n",
        "    'Patience': 20,\n",
        "    'Num_features': 3 if moneyness else 4, \n",
        "    'Architecture': 'LSTM-MLP v.1.0',\n",
        "}\n",
        "\n",
        "window = 1\n",
        "if moneyness:\n",
        "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike, = create_rw_dataset(window)\n",
        "else:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset(window)\n",
        "\n",
        "checkpoint_path = f'./checkpoint/03-20_12-35/{train_start}/'\n",
        "\n",
        "co = config_object(config)\n",
        "c_model = create_model(co)\n",
        "c_model.load_weights(checkpoint_path)\n",
        "predictions = np.array(c_model(test_x))\n",
        "print(f'--- Predictions for {test_start} ---')\n",
        "calculate_error(predictions, test_y)\n",
        "print('-------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQQfeNDKTnkt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d2a9c27343b49bc9d986128baff0a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f81230d00a0b4f2f9ac75b7e8ac85bd0",
              "IPY_MODEL_d665a0b4a5ec4a89a1b15b5907d8a911"
            ],
            "layout": "IPY_MODEL_1a715a6dad054fffb5405156e915dc6c"
          }
        },
        "f81230d00a0b4f2f9ac75b7e8ac85bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad538477c664ced95153a740b41a69b",
            "placeholder": "​",
            "style": "IPY_MODEL_76aaec3b18584034bb7725df913f9ec1",
            "value": ""
          }
        },
        "d665a0b4a5ec4a89a1b15b5907d8a911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_515397ae7e2e4e13b6636ca57713e8ef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c32db6a2ff0a4b928652cee07368b309",
            "value": 0
          }
        },
        "1a715a6dad054fffb5405156e915dc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad538477c664ced95153a740b41a69b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76aaec3b18584034bb7725df913f9ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "515397ae7e2e4e13b6636ca57713e8ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32db6a2ff0a4b928652cee07368b309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}