{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ors6z0lW-O4"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F_x2HgAW-O6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "from pandas.errors import SettingWithCopyWarning\n",
        "from pandas import to_datetime\n",
        "import statsmodels.api as sm\n",
        "from statsmodels import regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AZMBTsszW-O7"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w5tRqKAW-O8"
      },
      "outputs": [],
      "source": [
        "buy_sell_threshold = 0.15\n",
        "investment_ratio = 0.00005\n",
        "long_short_ratio = 0.1\n",
        "price_cap_lower = 0.5\n",
        "stop_loss = 2\n",
        "starting_balance = 1000000\n",
        "fee = 0.005\n",
        "\n",
        "run_optimizing = False\n",
        "google_colab = False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4DIl0QHAW-O8"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIriweabW-O8",
        "outputId": "b2885a80-58b2-4423-a3ce-8b3e5f32fc28"
      },
      "outputs": [],
      "source": [
        "if google_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !pip install -U -q PyDrive\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    # Authenticate and create the PyDrive client.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    id = \"1PZQLyOiOpKtLt5BVAvWwQEnxZJzvLcD7\"\n",
        "    downloaded = drive.CreateFile({'id':id}) \n",
        "    downloaded.GetContentFile('Full trading data - All models.csv')  \n",
        "    df = pd.read_csv('Full trading data - All models.csv')\n",
        "    id = \"13oSkK3IUv2Dlxbc_QILvLQ9tOlEKpqLk\"\n",
        "    downloaded = drive.CreateFile({'id':id}) \n",
        "    downloaded.GetContentFile('2011_11feb-2023mar_NSS__wo_moneyness_filtering_BID_ASK.csv')  \n",
        "    df_options = pd.read_csv('2011_11feb-2023mar_NSS__wo_moneyness_filtering_BID_ASK.csv')\n",
        "else:\n",
        "    # Set the path to the root directory\n",
        "    path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
        "    # Read dataframes using Dask\n",
        "    df = pd.read_csv(path + '/data/trading/Full trading data - All models - wo missing-filtering.csv')\n",
        "    df_options = pd.read_csv(path + '/data/processed_data/2011_11feb-2023mar_NSS__wo_moneyness_filtering_BID_ASK.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vkY0XkF1W-O-"
      },
      "source": [
        "### Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mtnq69jW-O-"
      },
      "outputs": [],
      "source": [
        "# Filter so its just data for 2015\n",
        "#df = df[(df[\"Quote_date\"] >= \"2015-01-01\") & (df[\"Quote_date\"] <= \"2018-12-31\")]\n",
        "#df = df[(df[\"Expiry_date\"] >= \"2015-01-01\") & (df[\"Expiry_date\"] <= \"2018-12-31\")]\n",
        "\n",
        "# Choos 5% of the data randomly\n",
        "#df = df.sample(frac=0.1, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk3ZLcorW-O-"
      },
      "outputs": [],
      "source": [
        "lstm_mlp = False\n",
        "bs_rolling = False\n",
        "bs_garch = False\n",
        "bs_iv = False\n",
        "heston = False\n",
        "mlp = True\n",
        "\n",
        "if lstm_mlp:\n",
        "    # Out of Quote_date\tExpire_date\tPrice\tBid\tAsk\tUnderlying_last\tStrike\tTTM\tDelta\tIV\tR\tPrice_drop\tRolling\tGARCH\tBS-IV\tHeston\tLSTM-MLP, drop Rolling, GARCH, BS-IV, Heston\n",
        "    df = df[['Quote_date', 'Expiry_date', 'Price', 'Bid', 'Ask', 'Underlying_last', 'Strike', 'TTM', 'Delta', 'IV', 'R', 'Price_drop', 'Option_ID', 'LSTM-MLP']]\n",
        "    # Rename LSTM-MLP to Prediction\n",
        "    df = df.rename(columns={'LSTM-MLP': 'Prediction'})\n",
        "elif bs_rolling:\n",
        "    df = df[['Quote_date', 'Expiry_date', 'Price', 'Bid', 'Ask', 'Underlying_last', 'Strike', 'TTM', 'Delta', 'IV', 'R', 'Price_drop', 'Option_ID', 'Rolling']]\n",
        "    df = df.rename(columns={'Rolling': 'Prediction'})\n",
        "elif bs_garch:\n",
        "    df = df[['Quote_date', 'Expiry_date', 'Price', 'Bid', 'Ask', 'Underlying_last', 'Strike', 'TTM', 'Delta', 'IV', 'R', 'Price_drop', 'Option_ID', 'GARCH']]\n",
        "    df = df.rename(columns={'GARCH': 'Prediction'})\n",
        "elif bs_iv:\n",
        "    df = df[['Quote_date', 'Expiry_date', 'Price', 'Bid', 'Ask', 'Underlying_last', 'Strike', 'TTM', 'Delta', 'IV', 'R', 'Price_drop', 'Option_ID', 'BS-IV']]\n",
        "    df = df.rename(columns={'BS-IV': 'Prediction'})\n",
        "elif heston:\n",
        "    df = df[['Quote_date', 'Expiry_date', 'Price', 'Bid', 'Ask', 'Underlying_last', 'Strike', 'TTM', 'Delta', 'IV', 'R', 'Price_drop', 'Option_ID', 'Heston']]\n",
        "    df = df.rename(columns={'Heston': 'Prediction'})\n",
        "elif mlp:\n",
        "    df = df[['Quote_date', 'Expiry_date', 'Price', 'Bid', 'Ask', 'Underlying_last', 'Strike', 'TTM', 'Delta', 'IV', 'R', 'Price_drop', 'Option_ID', 'MLP']]\n",
        "    df = df.rename(columns={'MLP': 'Prediction'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remane Expire_date to Expiry_date in df_options\n",
        "df_options = df_options.rename(columns={'Expire_date': 'Expiry_date'})\n",
        "df_options[\"Option_ID\"] = df_options[\"Expiry_date\"].astype(str) + \"-\" + df_options[\"Strike\"].astype(str)\n",
        "# Filter after 2015\n",
        "df_options = df_options[(df_options[\"Quote_date\"] >= \"2015-01-01\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_combined = pd.merge(df_options, df, how='left', on=['Quote_date', 'Expiry_date', 'Strike', 'Option_ID'])\n",
        "# Keep only Quote_date, expiry_date, Bid, Ask, Underlying_last and Option_ID from df_options and only the Prediction column from df\n",
        "df_combined = df_combined[['Quote_date', 'Expiry_date', 'Bid_x', 'Ask_x', 'Underlying_last_x', \"Price_x\", \"Delta_x\", \"TTM_x\", \"R_x\", 'Option_ID', 'Prediction']]\n",
        "df_combined = df_combined.rename(columns={'Bid_x': 'Bid', 'Ask_x': 'Ask', 'Underlying_last_x': 'Underlying_last', 'Price_x': 'Price', 'Delta_x': 'Delta', 'TTM_x': 'TTM', 'R_x': 'R'})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NZn7Iw7GW-O_"
      },
      "source": [
        "# Trading functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COtHaYsIW-O_"
      },
      "outputs": [],
      "source": [
        "def generate_buy_sell_signals(df, buy_threshold, sell_threshold):\n",
        "    buy_signal = (df['Prediction'] - df['Ask']) / df['Ask'] >= buy_threshold\n",
        "    sell_signal = (df['Bid'] - df['Prediction']) / df['Bid'] >= sell_threshold\n",
        "    return buy_signal, sell_signal\n",
        "\n",
        "\n",
        "def trader(df, buy_signal, sell_signal, starting_balance, price_cap_lower, investment_ratio, long_short_ratio, fee, stop_loss):\n",
        "    df['Expiry_date'] = pd.to_datetime(df['Expiry_date'])\n",
        "    df['Quote_date'] = pd.to_datetime(df['Quote_date'])\n",
        "    df = df[df['Expiry_date'] <= df['Quote_date'].max()]\n",
        "    \n",
        "    df['Signal'] = 0\n",
        "    df.loc[buy_signal, 'Signal'] = 1\n",
        "    df.loc[sell_signal, 'Signal'] = -1\n",
        "\n",
        "    df['Position_this_opt'] = 0\n",
        "    df['Balance'] = -1000000    # Makes it easy to spot if balance has not been updated correctly\n",
        "\n",
        "    df = df.sort_values('Quote_date')\n",
        "    df['Option_ID'] = df['Option_ID'].astype(str)\n",
        "\n",
        "    position_dict = {id:0 for id in df['Option_ID'].unique()}\n",
        "    first_date = df['Quote_date'].min()\n",
        "    total_balance_dict = {first_date: starting_balance}\n",
        "\n",
        "    number_of_long_positions = 0\n",
        "    number_of_short_positions = 0\n",
        "    entry_prices = {}\n",
        "\n",
        "    def operation(row):\n",
        "        nonlocal number_of_long_positions\n",
        "        nonlocal number_of_short_positions\n",
        "        if row['Quote_date'] not in total_balance_dict.keys():\n",
        "            total_balance_dict[row['Quote_date']] = total_balance_dict[max(total_balance_dict.keys())]\n",
        "\n",
        "        balance = total_balance_dict[row['Quote_date']]\n",
        "        position = position_dict[row['Option_ID']]\n",
        "\n",
        "        # If price below cap, do nothing\n",
        "        if row[\"Bid\"] < price_cap_lower:\n",
        "            row[\"Position_this_opt\"] = position\n",
        "            row[\"Balance\"] = balance\n",
        "            position_dict[row['Option_ID']] = position\n",
        "            total_balance_dict[row['Quote_date']] = balance\n",
        "            return row\n",
        "\n",
        "        # Calculate net ratio\n",
        "        if number_of_long_positions + number_of_short_positions == 0:\n",
        "            net_ratio = 0\n",
        "        else:\n",
        "            net_ratio = (number_of_long_positions - number_of_short_positions) / (number_of_long_positions + number_of_short_positions)\n",
        "\n",
        "        # Buy \n",
        "        if row['Signal'] == 1 and position <= 0 and row[\"Quote_date\"] != row[\"Expiry_date\"] and balance > 100 and net_ratio < long_short_ratio and row[\"Ask\"] != 0 and row[\"Prediction\"] != np.nan:\n",
        "            amount_to_invest = balance * investment_ratio\n",
        "            if amount_to_invest <= balance:\n",
        "                balance -= amount_to_invest * (1 + fee)\n",
        "                position += amount_to_invest / row['Ask']\n",
        "                number_of_long_positions += 1\n",
        "                entry_prices[row['Option_ID']] = row['Ask']\n",
        "\n",
        "        # Sell\n",
        "        elif row['Signal'] == -1 and position >= 0 and row[\"Quote_date\"] != row[\"Expiry_date\"] and balance > 100 and net_ratio > -long_short_ratio and row[\"Bid\"] != 0 and row[\"Prediction\"] != np.nan:\n",
        "            amount_to_sell = balance * investment_ratio\n",
        "            balance += amount_to_sell * (1 - fee)\n",
        "            position -= amount_to_sell / row['Bid']\n",
        "            number_of_short_positions += 1\n",
        "            entry_prices[row['Option_ID']] = row['Bid'] \n",
        "\n",
        "        # Check if the stop-loss should be triggered\n",
        "        if row['Option_ID'] in entry_prices:\n",
        "            entry_price = entry_prices[row['Option_ID']]\n",
        "            current_price = row['Ask'] if position > 0 else row['Bid']  # Check ask for long and bid for short\n",
        "            # Long\n",
        "            if position > 0 and (entry_price - current_price) / entry_price >= stop_loss:\n",
        "                balance += position * row[\"Bid\"] * (1 - fee) # Sell at bid price\n",
        "                position = 0\n",
        "                number_of_long_positions -= 1\n",
        "                del entry_prices[row['Option_ID']]\n",
        "            # Short\n",
        "            elif position < 0 and  (current_price - entry_price) / entry_price >= stop_loss:\n",
        "                balance -= position * row[\"Ask\"] * (1 + fee) # Buy at ask price\n",
        "                position = 0\n",
        "                number_of_short_positions -= 1\n",
        "                del entry_prices[row['Option_ID']]\n",
        "\n",
        "        # Expire\n",
        "        elif row[\"Quote_date\"] == row[\"Expiry_date\"] and position != 0:\n",
        "            intrinsic_value = max(0, row['Underlying_last'] - row['Strike'])\n",
        "            adjustment = intrinsic_value if position > 0 else -intrinsic_value\n",
        "            balance += adjustment * abs(position)\n",
        "            if position < 0:\n",
        "                number_of_short_positions -= 1\n",
        "            elif position > 0:\n",
        "                number_of_long_positions -= 1\n",
        "            position = 0\n",
        "        \n",
        "        \n",
        "        row['Position_this_opt'] = position\n",
        "        position_dict[row['Option_ID']] = position\n",
        "        total_balance_dict[row['Quote_date']] = balance\n",
        "        row['Balance'] = balance\n",
        "        return row\n",
        "\n",
        "    df = df.apply(operation, axis=1)\n",
        "    df.loc[(df['Position_this_opt'] == 0), 'Balance'] = df['Quote_date'].map(total_balance_dict)\n",
        "    return df\n",
        "\n",
        "def calculate_options_value(df):\n",
        "    df['Options_value'] = 0\n",
        "    for date in df['Quote_date'].unique():\n",
        "        # Net value\n",
        "        options_value_sum = (df.loc[df['Quote_date'] == date, 'Position_this_opt'] * df.loc[df['Quote_date'] == date, 'Price']).sum()\n",
        "        df.loc[df['Quote_date'] == date, 'Options_value'] = options_value_sum\n",
        "        # Absolute value\n",
        "        long_options_value_sum = (df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] > 0), 'Position_this_opt'] * df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] > 0), 'Price']).sum()\n",
        "        short_options_value_sum = (df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] < 0), 'Position_this_opt'] * df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] < 0), 'Price']).sum()\n",
        "        df.loc[df['Quote_date'] == date, 'Long_options_value'] = long_options_value_sum\n",
        "        df.loc[df['Quote_date'] == date, 'Short_options_value'] = short_options_value_sum\n",
        "\n",
        "        # Average delta value of all options combined\n",
        "        # (position * price * delta) / (position * price)\n",
        "        long_options_delta_sum = (df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] > 0), 'Position_this_opt'] * df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] > 0), 'Price'] * df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] > 0), 'Delta']).sum()\n",
        "        short_options_delta_sum = (df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] < 0), 'Position_this_opt'] * df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] < 0), 'Price'] * df.loc[(df['Quote_date'] == date) & (df['Position_this_opt'] < 0), 'Delta']).sum()        \n",
        "        if long_options_value_sum + short_options_value_sum == 0:\n",
        "            average_delta = 0\n",
        "        else:\n",
        "            average_delta = (long_options_delta_sum + short_options_delta_sum) / (abs(long_options_value_sum) + abs(short_options_value_sum))\n",
        "\n",
        "        df.loc[df['Quote_date'] == date, 'Average_delta'] = average_delta\n",
        "    df['Total_value'] = df['Balance'] + df['Options_value']\n",
        "    return df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9ajSbiuMW-O_"
      },
      "source": [
        "### Analysis functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiHomkR8W-O_"
      },
      "outputs": [],
      "source": [
        "def sharpe_ratio(df):\n",
        "    df_sharpe = df.copy()\n",
        "    # Make dataframe with 1 month risk free rate\n",
        "    df_rf = df_sharpe.loc[(df_sharpe[\"TTM\"] >= (20/365)) & (df_sharpe[\"TTM\"] <= (40/365))] \n",
        "    df_rf = df_rf.groupby('Quote_date').last()[\"R\"]\n",
        "\n",
        "    # Original dataframe\n",
        "    df_group = df.groupby('Quote_date').last()\n",
        "    df_group[\"Returns\"] = df_group[\"Total_value\"].pct_change().fillna(0)\n",
        "\n",
        "    # Excess returns\n",
        "    df_group[\"Excess_Returns\"] = df_group[\"Returns\"] - df_rf / 252\n",
        "\n",
        "    # Sharpe ratio\n",
        "    sharpe_ratio = np.sqrt(252) * (df_group[\"Excess_Returns\"].mean() / df_group[\"Excess_Returns\"].std())\n",
        "    return sharpe_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odlaqecvW-PA"
      },
      "outputs": [],
      "source": [
        "def sharpe_ratio_monthly(df):\n",
        "    df_sharpe = df.copy()\n",
        "    df_sharpe[\"YYYY-MM\"] = df_sharpe[\"Quote_date\"].dt.strftime(\"%Y-%m\")\n",
        "    \n",
        "    # Find the risk-free rate for each month from a row with the same YYYY-MM and TTM close to one month\n",
        "    df_rf = df_sharpe.loc[(df_sharpe[\"TTM\"] >= (25/365)) & (df_sharpe[\"TTM\"] <= (35/365))]  # Get the rows with TTM close to one month\n",
        "    df_rf = df_rf.groupby(\"YYYY-MM\").last()[\"R\"]\n",
        "    \n",
        "    df_sharpe = df_sharpe.groupby(\"YYYY-MM\").last()\n",
        "    df_sharpe[\"Returns\"] = df_sharpe[\"Total_value\"].pct_change()\n",
        "    \n",
        "    df_sharpe[\"Excess_Returns\"] = df_sharpe[\"Returns\"] - df_rf / 12\n",
        "    sharpe_ratio = np.sqrt(12) * (df_sharpe[\"Excess_Returns\"].mean() / df_sharpe[\"Excess_Returns\"].std())\n",
        "    \n",
        "    return sharpe_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sortino_ratio(df):\n",
        "    df_sharpe = df.copy()\n",
        "    # Make dataframe with 1 month risk free rate\n",
        "    df_rf = df_sharpe.loc[(df_sharpe[\"TTM\"] >= (25/365)) & (df_sharpe[\"TTM\"] <= (35/365))] \n",
        "    df_rf = df_rf.groupby('Quote_date').last()[\"R\"]\n",
        "\n",
        "    df_group = df.groupby('Quote_date').last()\n",
        "    df_group['Excess_Returns'] = df_group['Total_value'].pct_change().fillna(0) - df_rf / 252\n",
        "\n",
        "    sortino_ratio = np.sqrt(252) * (df_group[\"Excess_Returns\"].mean() / df_group.loc[df_group[\"Excess_Returns\"] < 0, \"Excess_Returns\"].std())\n",
        "    return sortino_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def capm(df):\n",
        "    df_rf = df.loc[(df[\"TTM\"] >= (10/365)) & (df[\"TTM\"] <= (31/365))] \n",
        "    df_rf = df_rf.groupby('Quote_date').last()[\"R\"]\n",
        "\n",
        "    df_group = df.groupby('Quote_date').last()\n",
        "    df_group['Year'] = df_group.index.year\n",
        "    df_group[\"Returns\"] = df_group[\"Total_value\"].pct_change().fillna(0)\n",
        "    df_group[\"Underlying_Returns\"] = df_group[\"Underlying_last\"].pct_change().fillna(0)\n",
        "    df_group[\"Excess_Returns\"] = df_group[\"Returns\"] - df_rf / 252\n",
        "    df_group[\"Excess_Underlying_Returns\"] = df_group[\"Underlying_Returns\"] - df_rf / 252\n",
        "\n",
        "    # Make return the first day of the year always 0\n",
        "    df_group['First_day_of_year'] = df_group.groupby('Year')['Total_value'].transform('idxmin')\n",
        "    df_group.loc[df_group.index == df_group['First_day_of_year'], 'Excess_Returns'] = 0\n",
        "    df_group.loc[df_group.index == df_group['First_day_of_year'], 'Excess_Underlying_Returns'] = 0\n",
        "    df_group.drop(columns=['Year', 'First_day_of_year'], inplace=True)\n",
        "\n",
        "    y = df_group[\"Excess_Returns\"]\n",
        "    X = df_group[\"Excess_Underlying_Returns\"]\n",
        "    print(y.isna().sum())\n",
        "    print(X.isna().sum())\n",
        "    y = y.fillna(0)\n",
        "    X = X.fillna(0)\n",
        "\n",
        "    X = sm.add_constant(X)\n",
        "\n",
        "    model = sm.OLS(y, X)\n",
        "    results = model.fit()\n",
        "\n",
        "    alpha = results.params['const']\n",
        "    beta = results.params['Excess_Underlying_Returns']\n",
        "\n",
        "    # Calculate t-statistics\n",
        "    t_stats = results.tvalues\n",
        "    alpha_t_statistic = t_stats['const'] * 252\n",
        "    beta_t_statistic = t_stats['Excess_Underlying_Returns']\n",
        "\n",
        "    # Get the p-values\n",
        "    p_values = results.pvalues\n",
        "    alpha_p_value = p_values['const']\n",
        "    beta_p_value = p_values['Excess_Underlying_Returns']\n",
        "\n",
        "    # Standard Errors\n",
        "    std_err = results.bse\n",
        "    alpha_std_err = std_err['const'] * 252\n",
        "    beta_std_err = std_err['Excess_Underlying_Returns']\n",
        "\n",
        "    def significance_marker(p):\n",
        "        if p < 0.01:\n",
        "            return \"***\"\n",
        "        elif p < 0.05:\n",
        "            return \"**\"\n",
        "        elif p < 0.1:\n",
        "            return \"*\"\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    print(f\"Alpha: {alpha} SE: {alpha_std_err} p-value: {alpha_p_value} {significance_marker(alpha_p_value)}\")\n",
        "    print(f\"Beta: {beta} SE: {beta_std_err} p-value: {beta_p_value} {significance_marker(beta_p_value)}\")\n",
        "\n",
        "    return alpha, beta, alpha_std_err, beta_std_err, alpha_p_value, beta_p_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7u_taPQW-PA"
      },
      "outputs": [],
      "source": [
        "def max_drawdown(df):\n",
        "    df_group = df.groupby('Quote_date').last()\n",
        "    df_group['Roll_Max'] = df_group['Total_value'].cummax()\n",
        "    df_group['Drawdown'] = df_group['Total_value'] / df_group['Roll_Max'] - 1.0\n",
        "    df_group['Drawdown'].min()\n",
        "    return df_group['Drawdown'].min() * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WYloSjZW-PA"
      },
      "outputs": [],
      "source": [
        "def print_results(df, starting_balance):\n",
        "    ending_balance = df['Balance'].iloc[-1]\n",
        "    profit = ending_balance - starting_balance\n",
        "    num_trades = df[df[\"Price\"] > 1][\"Signal\"].abs().sum()\n",
        "    profit_per_trade = profit / num_trades\n",
        "\n",
        "    df['Quote_date'] = pd.to_datetime(df['Quote_date'])\n",
        "    trading_days = df['Quote_date'].unique().shape[0] - 1\n",
        "    profit_per_day = profit / trading_days\n",
        "    num_days = (df['Quote_date'].max() - df['Quote_date'].min()).days\n",
        "\n",
        "    annualized_return = ((ending_balance / starting_balance)**(365/num_days) - 1)*100\n",
        "\n",
        "    print(f\"Starting balance: {starting_balance}\")\n",
        "    print(f\"Ending balance: {ending_balance.round(0)}\")\n",
        "    print(f\"Profit: {profit.round(0)}\")\n",
        "    print(f\"Profit per trade: {profit_per_trade.round(2)}\")\n",
        "    print(f\"Profit per trading day: {profit_per_day.round(2)}\")\n",
        "    print(f\"Sharpe ratio: {sharpe_ratio_monthly(df).round(2)}\")\n",
        "    print(f\"CAPM alpha: {capm_alpha(df).round(2)}\")\n",
        "    print(f\"Annualized return in percent: {annualized_return.round(2)}\")\n",
        "    print(f\"Max drawdown: {max_drawdown(df).round(2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znX2Ap1wW-PB"
      },
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\", font='serif', font_scale=1.2)\n",
        "\n",
        "color = '#1982C4'\n",
        "color2 = '#FF595E'\n",
        "color3 = '#8AC926'\n",
        "color4 = \"#FFCA3A\"\n",
        "color5 = \"#6A4C93\"\n",
        "\n",
        "def plot(df):\n",
        "    # Just keep one row per Quote_date, and that should be the last row\n",
        "    df = df.groupby('Quote_date').last()\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    ax1.plot(df['Total_value'], label='Total value', color=color)\n",
        "    ax1.plot(df['Balance'], label='Cash', color=color2)\n",
        "    #ax1.plot(df['Options_value'], label='Net value of options', color=color3)\n",
        "    ax1.plot(df[\"Long_options_value\"], label=\"Value of long position\", color=color5)\n",
        "    ax1.plot(df[\"Short_options_value\"], label=\"Value of short position\", color=color3)\n",
        "\n",
        "    # Use gausian filter to smooth delta\n",
        "    #df['Average_delta'] = gaussian_filter1d(df['Average_delta'], sigma=1)\n",
        "\n",
        "    # Plot delta on seperate y-axis\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(df['Average_delta'], label='Delta', color=color4) \n",
        "    \n",
        "    ax1.set_title('Portfolio value over time')\n",
        "\n",
        "    # Make plot smaller\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Create a legend for all the lines\n",
        "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "\n",
        "    lines = lines1 + lines2\n",
        "    labels = labels1 + labels2\n",
        "\n",
        "    ax1.legend(lines, labels, loc=0)\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TZpN3YOyW-PB"
      },
      "source": [
        "## Run the code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run by year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6vumNgSW-PB"
      },
      "outputs": [],
      "source": [
        "if run_optimizing == False:    \n",
        "    # Initialize an empty DataFrame to store the results\n",
        "    results = pd.DataFrame(columns=[\"Year\", \"Starting balance\", \"Ending balance\", \"Profit\", \"Profit per trade\", \"Profit per trading day\", \n",
        "                                    \"Sharpe ratio\", \"Sortino ratio\", \"Annualized return in percent\", \"Max drawdown\", \"CAPM alpha\", \"CAPM beta\", \"CAPM alpha p-value\", \"CAPM beta p-value\"])\n",
        "\n",
        "    # Get the list of years present in the data\n",
        "    df_combined['Quote_date'] = pd.to_datetime(df_combined['Quote_date'])\n",
        "    years = df_combined['Quote_date'].dt.year.unique()\n",
        "\n",
        "    # Sort the years\n",
        "    years.sort()\n",
        "\n",
        "    total_dataframe_for_analysis = pd.DataFrame()\n",
        "    # Iterate over each year\n",
        "    for year in years:\n",
        "        df_year = df_combined[df_combined['Quote_date'].dt.year == year].copy()\n",
        "        \n",
        "        if not df_year.empty:\n",
        "            # Execute operations\n",
        "            buy_signal, sell_signal = generate_buy_sell_signals(df_year, buy_sell_threshold, buy_sell_threshold)\n",
        "            df_year = trader(df_year, buy_signal, sell_signal, starting_balance, price_cap_lower, investment_ratio, long_short_ratio, fee, stop_loss)\n",
        "            df_year = calculate_options_value(df_year)\n",
        "\n",
        "            # Calculate metrics\n",
        "            ending_balance = df_year['Balance'].iloc[-1]\n",
        "            profit = ending_balance - starting_balance\n",
        "            num_trades = df_year[df_year[\"Price\"] > 1][\"Signal\"].abs().sum()\n",
        "            profit_per_trade = profit / num_trades\n",
        "\n",
        "            trading_days = df_year['Quote_date'].unique().shape[0] - 1\n",
        "            profit_per_day = profit / trading_days\n",
        "            num_days = (df_year['Quote_date'].max() - df_year['Quote_date'].min()).days\n",
        "\n",
        "            annualized_return = ((ending_balance / starting_balance)**(365/num_days) - 1)*100\n",
        "\n",
        "            alpha, beta, alpha_std_err, beta_std_err, alpha_p_value, beta_p_value = capm(df_year)\n",
        "\n",
        "            plot(df_year)\n",
        "\n",
        "            # Print number of nan values\n",
        "            # Drop all rows with nan values\n",
        "            df_year = df_year.dropna()            \n",
        "            # Create a DataFrame for this year's metrics\n",
        "            year_metrics = pd.DataFrame({\n",
        "                \"Year\": [year], \n",
        "                \"Starting balance\": [starting_balance], \n",
        "                \"Ending balance\": [ending_balance.round(0)], \n",
        "                \"Profit\": [profit.round(0)], \n",
        "                \"Profit per trade\": [profit_per_trade.round(2)], \n",
        "                \"Profit per trading day\": [profit_per_day.round(2)],\n",
        "                \"Sharpe ratio\": [sharpe_ratio(df_year).round(2)],\n",
        "                \"Sortino ratio\": [sortino_ratio(df_year).round(2)], \n",
        "                \"Annualized return in percent\": [annualized_return.round(2)], \n",
        "                \"Max drawdown\": [max_drawdown(df_year).round(2)],\n",
        "                \"CAPM alpha\": [(alpha*100).round(2)],\n",
        "                \"CAPM beta\": [beta.round(2)],\n",
        "                \"CAPM alpha p-value\": [alpha_p_value.round(2)],\n",
        "                \"CAPM beta p-value\": [beta_p_value.round(2)]\n",
        "            })\n",
        "            # Add metrics to the results DataFrame\n",
        "            results = pd.concat([results, year_metrics])\n",
        "\n",
        "            total_dataframe_for_analysis = pd.concat([total_dataframe_for_analysis, df_year])\n",
        "\n",
        "    # Reset index of the results DataFrame\n",
        "    results.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Print the results DataFrame\n",
        "    display(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(total_dataframe_for_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate capm for the total dataframe ignoring 2023\n",
        "alpha, beta, alpha_std_err, beta_std_err, alpha_p_value, beta_p_value = capm(total_dataframe_for_analysis[total_dataframe_for_analysis['Quote_date'].dt.year != 2023])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Only keep needed columns\n",
        "results = results[[\"Year\", \"Starting balance\", \"Ending balance\", \"Profit\", \"Profit per trade\", \"Profit per trading day\", \"Sharpe ratio\", \"Sortino ratio\", \"Annualized return in percent\", \"Max drawdown\", \"CAPM alpha\", \"CAPM beta\", \"CAPM alpha p-value\", \"CAPM beta p-value\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Only keep needed columns\n",
        "results = results[[\"Year\",  \"Sharpe ratio\", \"Sortino ratio\", \"Annualized return in percent\", \"Max drawdown\", \"CAPM alpha\"]]\n",
        "\n",
        "# Drop 2023\n",
        "results = results[results[\"Year\"] != 2023]\n",
        "\n",
        "\n",
        "# Add a final row to the results DataFrame with the average metrics\n",
        "results.loc[\"Average\"] = results.mean()\n",
        "# Drop Profit per trade\tProfit per trading day\n",
        "# Only keep needed columns\n",
        "results = results[[\"Year\", \"Sharpe ratio\", \"Sortino ratio\", \"Annualized return in percent\", \"Max drawdown\", \"CAPM alpha\"]]\n",
        "\n",
        "\n",
        "# Rename the columns to  Year &  Starting &  Ending &  Profit &  Sharpe  &  alpha &  Return &  MDD \\\\\n",
        "results.columns = [\"Year\", \"Sharpe\", \"Sortino\", \"Return\", \"MDD\", \"alpha\"]\n",
        "# Round to 2 decimals\n",
        "float_cols = [\"Sharpe\", \"alpha\", \"Return\", \"MDD\"]\n",
        "# Turn the columns into floats\n",
        "results[float_cols] = results[float_cols].astype(float)\n",
        "\n",
        "# Rename the columns to  Year &  Starting &  Ending &  Profit &  Sharpe  &  alpha &  Return &  MDD \\\\\n",
        "results.columns = [\"Year\", \"Sharpe\", \"Sortino\", \"Return\", \"MDD\", \"alpha\"]\n",
        "\n",
        "results[float_cols] = results[float_cols].round(2)\n",
        "print(results.to_latex(index=False, float_format=\"%.2f\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m9ParidnW-PB"
      },
      "source": [
        "### Post analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6hDVveTW-PB"
      },
      "outputs": [],
      "source": [
        "if run_optimizing == False:\n",
        "    plot(total_dataframe_for_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if google_colab == True:\n",
        "    if lstm_mlp:\n",
        "        total_dataframe_for_analysis.to_csv('/content/drive/My Drive/01. Masters Thesis - Shared/07. Trading/Results/LSTM_MLP_v2.csv')\n",
        "    if bs_rolling:\n",
        "        total_dataframe_for_analysis.to_csv('/content/drive/My Drive/01. Masters Thesis - Shared/07. Trading/Results/BS_Rolling_v2.csv')\n",
        "    if bs_garch:\n",
        "        total_dataframe_for_analysis.to_csv('/content/drive/My Drive/01. Masters Thesis - Shared/07. Trading/Results/BS_GARCH_v2.csv')\n",
        "    if bs_iv:\n",
        "        total_dataframe_for_analysis.to_csv('/content/drive/My Drive/01. Masters Thesis - Shared/07. Trading/Results/BS_IV_v2.csv')\n",
        "    if heston:\n",
        "        total_dataframe_for_analysis.to_csv('/content/drive/My Drive/01. Masters Thesis - Shared/07. Trading/Results/Heston_v2.csv')\n",
        "    if mlp:\n",
        "        total_dataframe_for_analysis.to_csv('/content/drive/My Drive/01. Masters Thesis - Shared/07. Trading/Results/MLP_v2.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tk4zn6QHW-PB"
      },
      "source": [
        "## Threshold search"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This should only be done in-sample before testing out-of-sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1z1DoZUW-PC"
      },
      "outputs": [],
      "source": [
        "if run_optimizing:\n",
        "    # Initialize wandb\n",
        "    !pip install wandb\n",
        "    import wandb\n",
        "    wandb.login(key=\"b47bcf387a0571c5520c58a13be35cda8ada0a99\")\n",
        "\n",
        "    # Define the hyperparameters\n",
        "    sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'name': '2015-2018 - v12',\n",
        "    'metric': {\n",
        "        'goal': 'maximize', \n",
        "        'name': 'alpha'\n",
        "        },\n",
        "    'parameters': {\n",
        "        'buy_threshold': {\n",
        "            'values': [0.06, 0.1, 0.12]},\n",
        "        'sell_threshold': {\n",
        "            'values': [0.06, 0.1, 0.12]},\n",
        "        'price_cap_lower': {\n",
        "            'values': [1, 2]},\n",
        "        'investment_ratio': {\n",
        "            'values': [5e-4, 5e-5, 5e-6]},\n",
        "        'long_short_ratio': {\n",
        "            'values': [0.05, 0.3]}\n",
        "        }\n",
        "    }\n",
        "    sweep_id = wandb.sweep(sweep=sweep_config, project='options-trading') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVTB3565W-PC"
      },
      "outputs": [],
      "source": [
        "if run_optimizing:\n",
        "    def find_best_thresholds(df = df):\n",
        "        run = wandb.init(project = \"options-trading\")\n",
        "        df = df.copy()\n",
        "        buy_signal, sell_signal = generate_buy_sell_signals(df, run.config.buy_threshold, run.config.sell_threshold)\n",
        "        df = trader(df, buy_signal, sell_signal, starting_balance=100000, price_cap_lower = run.config.price_cap_lower, investment_ratio = run.config.investment_ratio, long_short_ratio = run.config.long_short_ratio)\n",
        "        df = calculate_options_value(df)\n",
        "        run.log({\"buy_threshold\": run.config.buy_threshold, \"sell_threshold\": run.config.sell_threshold, \"sharpe_ratio\": sharpe_ratio_monthly(df), \"ending_balance\": df['Balance'].iloc[-1], \"number_of_trades\": df['Signal'].abs().sum(), \"alpha\": capm_alpha(df), \"long_short_ratio\": run.config.long_short_ratio, \"price_cap_lower\": run.config.price_cap_lower, \"investment_ratio\": run.config.investment_ratio})\n",
        "        # Wandb callback\n",
        "        print_results(df, 100000)\n",
        "        plot(df)\n",
        "        run.finish()\n",
        "\n",
        "    wandb.agent(sweep_id=sweep_id, function=find_best_thresholds, project='options-trading', count = 1000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
