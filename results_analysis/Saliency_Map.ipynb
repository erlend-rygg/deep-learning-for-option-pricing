{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2MNO3kPTnkd"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlTtOWVUD6YH"
      },
      "source": [
        "### Model decisions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOQkqhqFTnkg",
        "outputId": "68840d04-3209-4c8d-d1d6-8052ffba8a74"
      },
      "outputs": [],
      "source": [
        "# Weights and Biases\n",
        "!pip install -q wandb\n",
        "# Tensorflow\n",
        "!pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4PZBtROGD6YJ"
      },
      "outputs": [],
      "source": [
        "previous_loading = False\n",
        "google_colab = False\n",
        "moneyness = False\n",
        "lags = 80\n",
        "hyperparameter_search = False\n",
        "training_size = 991232\n",
        "random_seed = 0\n",
        "finance_computers = False\n",
        "fc_path = 'M:/Master/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovc8FFP6D6YJ",
        "outputId": "0248b095-1aa2-45c9-c67b-e585f088ba1c"
      },
      "outputs": [],
      "source": [
        "if google_colab == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8xVVTnPD6YJ"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Bfwvf6vGTnki"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, LSTM, Concatenate, Dense, BatchNormalization, LeakyReLU\n",
        "from keras.activations import tanh\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from tensorflow import square, reduce_mean\n",
        "from tensorflow.keras.losses import MSE\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.math import multiply\n",
        "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError\n",
        "from math import log\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fduF6iTTnkj",
        "outputId": "9f3093f0-b37b-43fd-9436-26ee6ecff39a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merlendrygg\u001b[0m (\u001b[33mavogadro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/hjalmarjacobvinje/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If running in colab, insert your wandb key here\n",
        "\n",
        "#import config\n",
        "#Erlend\n",
        "wandb.login(key='3cae81eb56be3190be5bb48c571e69933071df69')\n",
        "# Hjalmar\n",
        "#wandb.login(key=\"b47bcf387a0571c5520c58a13be35cda8ada0a99\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJGDiGMLTnkl"
      },
      "source": [
        "# Load, split and normalize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI1j3mQWTnkl"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "OKcl8WWJTnkl",
        "outputId": "7cfa9ca5-49b5-4eed-8b26-c911179e113d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Quote_date</th>\n",
              "      <th>Price</th>\n",
              "      <th>Underlying_last</th>\n",
              "      <th>Strike</th>\n",
              "      <th>TTM</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>207.490</td>\n",
              "      <td>1132.99</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.00050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>182.500</td>\n",
              "      <td>1132.99</td>\n",
              "      <td>950.0</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.00050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>157.500</td>\n",
              "      <td>1132.99</td>\n",
              "      <td>975.0</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.00050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>132.600</td>\n",
              "      <td>1132.99</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.00050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>107.705</td>\n",
              "      <td>1132.99</td>\n",
              "      <td>1025.0</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.00050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12057638</th>\n",
              "      <td>13739049</td>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>217.750</td>\n",
              "      <td>4109.88</td>\n",
              "      <td>4700.0</td>\n",
              "      <td>1.726027</td>\n",
              "      <td>0.04198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12057639</th>\n",
              "      <td>13739050</td>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>180.000</td>\n",
              "      <td>4109.88</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>1.726027</td>\n",
              "      <td>0.04198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12057640</th>\n",
              "      <td>13739051</td>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>146.550</td>\n",
              "      <td>4109.88</td>\n",
              "      <td>4900.0</td>\n",
              "      <td>1.726027</td>\n",
              "      <td>0.04198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12057641</th>\n",
              "      <td>13739052</td>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>118.200</td>\n",
              "      <td>4109.88</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>1.726027</td>\n",
              "      <td>0.04198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12057642</th>\n",
              "      <td>13739053</td>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>94.400</td>\n",
              "      <td>4109.88</td>\n",
              "      <td>5100.0</td>\n",
              "      <td>1.726027</td>\n",
              "      <td>0.04198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12057643 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  Quote_date    Price  Underlying_last  Strike       TTM  \\\n",
              "0                  0  2010-01-04  207.490          1132.99   925.0  0.008219   \n",
              "1                  1  2010-01-04  182.500          1132.99   950.0  0.008219   \n",
              "2                  2  2010-01-04  157.500          1132.99   975.0  0.008219   \n",
              "3                  3  2010-01-04  132.600          1132.99  1000.0  0.008219   \n",
              "4                  4  2010-01-04  107.705          1132.99  1025.0  0.008219   \n",
              "...              ...         ...      ...              ...     ...       ...   \n",
              "12057638    13739049  2023-03-31  217.750          4109.88  4700.0  1.726027   \n",
              "12057639    13739050  2023-03-31  180.000          4109.88  4800.0  1.726027   \n",
              "12057640    13739051  2023-03-31  146.550          4109.88  4900.0  1.726027   \n",
              "12057641    13739052  2023-03-31  118.200          4109.88  5000.0  1.726027   \n",
              "12057642    13739053  2023-03-31   94.400          4109.88  5100.0  1.726027   \n",
              "\n",
              "                R  \n",
              "0         0.00050  \n",
              "1         0.00050  \n",
              "2         0.00050  \n",
              "3         0.00050  \n",
              "4         0.00050  \n",
              "...           ...  \n",
              "12057638  0.04198  \n",
              "12057639  0.04198  \n",
              "12057640  0.04198  \n",
              "12057641  0.04198  \n",
              "12057642  0.04198  \n",
              "\n",
              "[12057643 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if google_colab:\n",
        "    import tensorflow as tf\n",
        "    # Print info\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "        print('Not connected to a GPU')\n",
        "    else:\n",
        "        print(gpu_info)\n",
        "    \n",
        "    from psutil import virtual_memory\n",
        "    ram_gb = virtual_memory().total / 1e9\n",
        "    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "    if ram_gb < 20:\n",
        "        print('Not using a high-RAM runtime')\n",
        "    else:\n",
        "        print('You are using a high-RAM runtime!')\n",
        "\n",
        "    # Code to read csv file into Colaboratory:\n",
        "    !pip install -U -q PyDrive\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    # Authenticate and create the PyDrive client.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    id = \"1Doyuyo_VDOmJf0CLo5kl9XzMTfhGtxiR\"\n",
        "    downloaded = drive.CreateFile({'id':id}) \n",
        "    downloaded.GetContentFile('2010-2023_NSS_filtered_vF.csv')  \n",
        "    df_read = pd.read_csv('2010-2023_NSS_filtered_vF.csv')\n",
        "elif finance_computers:\n",
        "    file = fc_path + \"/data/processed_data/2010-2023_NSS_filtered_vF.csv\"\n",
        "    df_read = pd.read_csv(file)\n",
        "else:\n",
        "    file = \"../data/processed_data/2010-2023_NSS_filtered_vF.csv\"\n",
        "    df_read = pd.read_csv(file)\n",
        "\n",
        "display(df_read)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdbRyWt1D6YM"
      },
      "source": [
        "### Create lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpcmhVq6Tnkm",
        "outputId": "76e1f117-2b43-49d7-9c34-f65a919cdbfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Unnamed: 0  Quote_date    Price  Underlying_last  Strike       TTM  \\\n",
            "292779        381812  2011-09-01  304.355          1203.96   900.0  0.002740   \n",
            "292780        381813  2011-09-01  279.345          1203.96   925.0  0.002740   \n",
            "292781        381814  2011-09-01  254.355          1203.96   950.0  0.002740   \n",
            "292782        381815  2011-09-01  229.350          1203.96   975.0  0.002740   \n",
            "292783        381816  2011-09-01  204.350          1203.96  1000.0  0.002740   \n",
            "...              ...         ...      ...              ...     ...       ...   \n",
            "11654831    13280615  2022-12-30  362.600          3839.81  4300.0  1.975342   \n",
            "11654832    13280616  2022-12-30  319.150          3839.81  4400.0  1.975342   \n",
            "11654833    13280617  2022-12-30  279.000          3839.81  4500.0  1.975342   \n",
            "11654834    13280618  2022-12-30  241.950          3839.81  4600.0  1.975342   \n",
            "11654835    13280619  2022-12-30  208.800          3839.81  4700.0  1.975342   \n",
            "\n",
            "                 R  Underlying_return  Underlying_1  Underlying_2  ...  \\\n",
            "292779    0.000200          -0.011576      0.004147      0.002595  ...   \n",
            "292780    0.000200          -0.011576      0.004147      0.002595  ...   \n",
            "292781    0.000200          -0.011576      0.004147      0.002595  ...   \n",
            "292782    0.000200          -0.011576      0.004147      0.002595  ...   \n",
            "292783    0.000200          -0.011576      0.004147      0.002595  ...   \n",
            "...            ...                ...           ...           ...  ...   \n",
            "11654831  0.044146          -0.002300      0.017343     -0.012034  ...   \n",
            "11654832  0.044146          -0.002300      0.017343     -0.012034  ...   \n",
            "11654833  0.044146          -0.002300      0.017343     -0.012034  ...   \n",
            "11654834  0.044146          -0.002300      0.017343     -0.012034  ...   \n",
            "11654835  0.044146          -0.002300      0.017343     -0.012034  ...   \n",
            "\n",
            "          Underlying_71  Underlying_72  Underlying_73  Underlying_74  \\\n",
            "292779        -0.007682       0.002126       0.008706      -0.000496   \n",
            "292780        -0.007682       0.002126       0.008706      -0.000496   \n",
            "292781        -0.007682       0.002126       0.008706      -0.000496   \n",
            "292782        -0.007682       0.002126       0.008706      -0.000496   \n",
            "292783        -0.007682       0.002126       0.008706      -0.000496   \n",
            "...                 ...            ...            ...            ...   \n",
            "11654831      -0.017354      -0.011082       0.006893      -0.007175   \n",
            "11654832      -0.017354      -0.011082       0.006893      -0.007175   \n",
            "11654833      -0.017354      -0.011082       0.006893      -0.007175   \n",
            "11654834      -0.017354      -0.011082       0.006893      -0.007175   \n",
            "11654835      -0.017354      -0.011082       0.006893      -0.007175   \n",
            "\n",
            "          Underlying_75  Underlying_76  Underlying_77  Underlying_78  \\\n",
            "292779        -0.006122      -0.008045       0.004978      -0.011207   \n",
            "292780        -0.006122      -0.008045       0.004978      -0.011207   \n",
            "292781        -0.006122      -0.008045       0.004978      -0.011207   \n",
            "292782        -0.006122      -0.008045       0.004978      -0.011207   \n",
            "292783        -0.006122      -0.008045       0.004978      -0.011207   \n",
            "...                 ...            ...            ...            ...   \n",
            "11654831      -0.011553       0.003606      -0.043355       0.010645   \n",
            "11654832      -0.011553       0.003606      -0.043355       0.010645   \n",
            "11654833      -0.011553       0.003606      -0.043355       0.010645   \n",
            "11654834      -0.011553       0.003606      -0.043355       0.010645   \n",
            "11654835      -0.011553       0.003606      -0.043355       0.010645   \n",
            "\n",
            "          Underlying_79  Underlying_80  \n",
            "292779         0.008149       0.004642  \n",
            "292780         0.008149       0.004642  \n",
            "292781         0.008149       0.004642  \n",
            "292782         0.008149       0.004642  \n",
            "292783         0.008149       0.004642  \n",
            "...                 ...            ...  \n",
            "11654831       0.015417       0.006492  \n",
            "11654832       0.015417       0.006492  \n",
            "11654833       0.015417       0.006492  \n",
            "11654834       0.015417       0.006492  \n",
            "11654835       0.015417       0.006492  \n",
            "\n",
            "[11362057 rows x 88 columns]\n"
          ]
        }
      ],
      "source": [
        "df = df_read\n",
        "del df_read\n",
        "\n",
        "if hyperparameter_search:\n",
        "    df = df[df['Quote_date'] <= '2015-02-01']\n",
        "\n",
        "# Group the data by Quote Date and calculate the mean for Underlying Price\n",
        "df_agg = df.groupby('Quote_date').mean().reset_index()\n",
        "\n",
        "# Values to returns\n",
        "df_agg[\"Underlying_return\"] = df_agg[\"Underlying_last\"].pct_change()\n",
        "\n",
        "# Add the Underlying Price Lag column\n",
        "for i in range(1, lags + 1):\n",
        "    df_agg['Underlying_' + str(i)] = df_agg['Underlying_return'].shift(i)\n",
        "\n",
        "df = pd.merge(df, df_agg[['Quote_date', 'Underlying_return'] + ['Underlying_' + str(i) for i in range(1, lags + 1)]], on='Quote_date', how='left')\n",
        "\n",
        "# Filter df between 2014-01-01 and 2022-12-31\n",
        "df = df[(df[\"Quote_date\"] >= \"2011-09-01\") & (df[\"Quote_date\"] <= \"2022-12-31\")]\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1fuXIvmTnkn"
      },
      "source": [
        "### Format input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKAFyCmTTnko",
        "outputId": "161a7525-ae78-43ba-9e29-faa2f965ea68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------Dataframe dates--------------\n",
            "Train: 2011-09-01 - 2014-08-29\n",
            "Val: 2014-09-02 - 2014-09-30\n",
            "Test: 2014-10-01 - 2014-12-31\n",
            "-------------------------------------------\n",
            "Train shape: (991232, 80, 1), (991232, 4)\n",
            "Val shape: (54323, 80, 1), (54323, 4)\n",
            "Test shape: (177109, 80, 1), (177109, 4)\n"
          ]
        }
      ],
      "source": [
        "# Format settings\n",
        "max_timesteps = lags\n",
        "bs_vars = ['Moneyness', 'TTM', 'R'] if moneyness else ['Underlying_last', 'Strike', 'TTM', 'R']\n",
        "underlying_lags = [f'Underlying_{i}' for i in range (max_timesteps - 1, 0, -1)] + ['Underlying_return']\n",
        "\n",
        "def create_rw_dataset(window_number = 0, df = None):\n",
        "    '''Creates dataset for a single rolling window period offsett by the window number'''\n",
        "\n",
        "    # Create train, validation and test set split points\n",
        "    test_months = 3\n",
        "    train_start = datetime(2011,9,1) + relativedelta(months=window_number * test_months)\n",
        "    val_start = train_start + relativedelta(months=3*12)\n",
        "    test_start = val_start + relativedelta(months = 1 + test_months) if hyperparameter_search else val_start + relativedelta(months = 1)\n",
        "    test_end = test_start + relativedelta(months=test_months)\n",
        "    train_start = str(train_start.date())\n",
        "    val_start = str(val_start.date())\n",
        "    test_start = str(test_start.date())\n",
        "    test_end = str(test_end.date())\n",
        "\n",
        "        \n",
        "    # Split train and validation data\n",
        "    df_train = df[(df['Quote_date'] >= train_start) & (df['Quote_date'] < val_start)]\n",
        "    df_val = df[(df['Quote_date'] >= val_start) & (df['Quote_date'] < test_start)]\n",
        "    df_test = df[(df['Quote_date'] >= test_start) & (df['Quote_date'] < test_end)]\n",
        "\n",
        "    del df\n",
        "\n",
        "    # Extract target values\n",
        "    train_y = (df_train['Price'] / df_train['Strike']).to_numpy() if moneyness else df_train['Price'].to_numpy()\n",
        "    val_y = (df_val['Price'] / df_val['Strike']).to_numpy() if moneyness else df_val['Price'].to_numpy()\n",
        "    test_y = (df_test['Price'] / df_test['Strike']).to_numpy() if moneyness else df_test['Price'].to_numpy()\n",
        "\n",
        "    # If usining moneyness, extract strike\n",
        "    if moneyness:\n",
        "        train_strike = df_train['Strike'].to_numpy()\n",
        "        val_strike = df_val['Strike'].to_numpy()\n",
        "        test_strike = df_test['Strike'].to_numpy()\n",
        "\n",
        "\n",
        "    # Print earliest and latest date in every dataframe used\n",
        "    print(\"--------------Dataframe dates--------------\")\n",
        "    print(f\"Train: {df_train['Quote_date'].min()} - {df_train['Quote_date'].max()}\")\n",
        "    print(f\"Val: {df_val['Quote_date'].min()} - {df_val['Quote_date'].max()}\")\n",
        "    print(f\"Test: {df_test['Quote_date'].min()} - {df_test['Quote_date'].max()}\")\n",
        "    print(\"-------------------------------------------\")\n",
        "\n",
        "    # Convert dataframes to numpy arrays\n",
        "    train_x = [df_train[underlying_lags].to_numpy(), df_train[bs_vars].to_numpy()]\n",
        "    val_x = [df_val[underlying_lags].to_numpy(), df_val[bs_vars].to_numpy()]\n",
        "    test_x = [df_test[underlying_lags].to_numpy(), df_test[bs_vars].to_numpy()]\n",
        "\n",
        "    del df_train\n",
        "    del df_val\n",
        "\n",
        "    # Scale features based on training set\n",
        "    underlying_scaler = MinMaxScaler()\n",
        "    train_x[0] = underlying_scaler.fit_transform(train_x[0].flatten().reshape(-1, 1)).reshape(train_x[0].shape)\n",
        "    val_x[0] = underlying_scaler.transform(val_x[0].flatten().reshape(-1,1)).reshape(val_x[0].shape)\n",
        "    test_x[0] = underlying_scaler.transform(test_x[0].flatten().reshape(-1,1)).reshape(test_x[0].shape)\n",
        "\n",
        "    bs_scaler = MinMaxScaler()\n",
        "    train_x[1] = bs_scaler.fit_transform(train_x[1])\n",
        "    val_x[1] = bs_scaler.transform(val_x[1])\n",
        "    test_x[1] = bs_scaler.transform(test_x[1])\n",
        "\n",
        "\n",
        "    # Shuffle training set\n",
        "    np.random.seed(random_seed)\n",
        "    shuffle = np.random.permutation(len(train_x[0]))\n",
        "    train_x = [train_x[0][shuffle], train_x[1][shuffle]]\n",
        "    train_y = train_y[shuffle]\n",
        "\n",
        "    # Extract training set\n",
        "    train_x = [train_x[0][:training_size], train_x[1][:training_size]]\n",
        "    train_y = train_y[:training_size]\n",
        "\n",
        "    if moneyness:\n",
        "        train_strike = train_strike[shuffle][:training_size]\n",
        "\n",
        "    # Reshape data to fit LSTM\n",
        "    train_x = [train_x[0].reshape(len(train_x[0]), max_timesteps, 1), train_x[1]]\n",
        "    val_x = [val_x[0].reshape(len(val_x[0]), max_timesteps, 1), val_x[1]]\n",
        "    test_x = [test_x[0].reshape(len(test_x[0]), max_timesteps, 1), test_x[1]]\n",
        "\n",
        "    print(f'Train shape: {train_x[0].shape}, {train_x[1].shape}')\n",
        "    print(f'Val shape: {val_x[0].shape}, {val_x[1].shape}')\n",
        "    print(f'Test shape: {test_x[0].shape}, {test_x[1].shape}')\n",
        "\n",
        "    if moneyness:\n",
        "        return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike,\n",
        "    return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test\n",
        "\n",
        "# Create the dataset for the first rolling window period\n",
        "if moneyness:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike = create_rw_dataset(df=df)\n",
        "else:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset(df=df)\n",
        "    if hyperparameter_search:\n",
        "        del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "31Qsg5AcAHS-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_saliency_map(model, input_data, percentage=0.02):\n",
        "    n_samples = len(input_data[0])\n",
        "    sample_size = int(n_samples * percentage)\n",
        "    \n",
        "    # Randomly select a subset of samples\n",
        "    idx = np.random.choice(n_samples, sample_size, replace=False)\n",
        "    input_data_underlying_sample = tf.convert_to_tensor(input_data[0][idx], dtype=tf.float32)\n",
        "    input_data_bs_sample = tf.convert_to_tensor(input_data[1][idx], dtype=tf.float32)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(input_data_underlying_sample)\n",
        "        tape.watch(input_data_bs_sample)\n",
        "        output = model([input_data_underlying_sample, input_data_bs_sample])\n",
        "\n",
        "    grads = tape.gradient(output, [input_data_underlying_sample, input_data_bs_sample])\n",
        "    grads_underlying = grads[0]\n",
        "    grads_bs = grads[1]\n",
        "\n",
        "    saliency_map_underlying = np.mean(np.abs(grads_underlying.numpy()), axis=0)\n",
        "    saliency_map_bs = np.mean(np.abs(grads_bs.numpy()), axis=0)\n",
        "\n",
        "    return saliency_map_underlying, saliency_map_bs\n",
        "\n",
        "\n",
        "\n",
        "input_data = train_x  # or use val_x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZmPAetLSAPXE"
      },
      "outputs": [],
      "source": [
        "model = load_model(f'model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZT_Q2nvuBOLz"
      },
      "outputs": [],
      "source": [
        "saliency_map_underlying, saliency_map_bs = compute_saliency_map(model, input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvIIJ9BjHALI",
        "outputId": "0ba699da-68c9-4434-a2e4-51c79385761a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saliency_map_underlying shape: (80, 1)\n",
            "saliency_map_bs shape: (4,)\n",
            "saliency_map_bs shape: (4, 1)\n",
            "[[1822.6469 ]\n",
            " [3314.0334 ]\n",
            " [ 360.9834 ]\n",
            " [  74.55522]]\n",
            "[[ 1.4579371]\n",
            " [ 4.632706 ]\n",
            " [ 8.211611 ]\n",
            " [10.954626 ]\n",
            " [13.114001 ]\n",
            " [14.92432  ]\n",
            " [16.41222  ]\n",
            " [17.71966  ]\n",
            " [18.881113 ]\n",
            " [19.906038 ]\n",
            " [20.848652 ]\n",
            " [21.67782  ]\n",
            " [22.499826 ]\n",
            " [23.22376  ]\n",
            " [23.929852 ]\n",
            " [24.614902 ]\n",
            " [25.258356 ]\n",
            " [25.846985 ]\n",
            " [26.473284 ]\n",
            " [27.029541 ]\n",
            " [27.569786 ]\n",
            " [28.071095 ]\n",
            " [28.575287 ]\n",
            " [29.042067 ]\n",
            " [29.482733 ]\n",
            " [29.938616 ]\n",
            " [30.325136 ]\n",
            " [30.723433 ]\n",
            " [31.083633 ]\n",
            " [31.425888 ]\n",
            " [31.72545  ]\n",
            " [31.976746 ]\n",
            " [32.22938  ]\n",
            " [32.421623 ]\n",
            " [32.65192  ]\n",
            " [32.810394 ]\n",
            " [32.938778 ]\n",
            " [33.00454  ]\n",
            " [33.06929  ]\n",
            " [33.0878   ]\n",
            " [33.07341  ]\n",
            " [33.026188 ]\n",
            " [32.93582  ]\n",
            " [32.813416 ]\n",
            " [32.645084 ]\n",
            " [32.39636  ]\n",
            " [32.136818 ]\n",
            " [31.83548  ]\n",
            " [31.447115 ]\n",
            " [31.029903 ]\n",
            " [30.567327 ]\n",
            " [30.056103 ]\n",
            " [29.466026 ]\n",
            " [28.863064 ]\n",
            " [28.197355 ]\n",
            " [27.470951 ]\n",
            " [26.754515 ]\n",
            " [25.97157  ]\n",
            " [25.220943 ]\n",
            " [24.452072 ]\n",
            " [23.666306 ]\n",
            " [22.872673 ]\n",
            " [22.174566 ]\n",
            " [21.486935 ]\n",
            " [21.041586 ]\n",
            " [20.623404 ]\n",
            " [20.48434  ]\n",
            " [20.59039  ]\n",
            " [21.052334 ]\n",
            " [21.647411 ]\n",
            " [22.708069 ]\n",
            " [24.16762  ]\n",
            " [25.68358  ]\n",
            " [27.39794  ]\n",
            " [28.964796 ]\n",
            " [30.813204 ]\n",
            " [31.905266 ]\n",
            " [31.628408 ]\n",
            " [29.136574 ]\n",
            " [34.08761  ]]\n",
            "The sum of the saliency map for the underlying is: 2092.26318359375\n",
            "The sum of the saliency map for the bs is: 5572.21875\n",
            "The proportion of the saliency map for the underlying is:  0.27298167\n"
          ]
        }
      ],
      "source": [
        "print(f'saliency_map_underlying shape: {saliency_map_underlying.shape}')\n",
        "print(f'saliency_map_bs shape: {saliency_map_bs.shape}')\n",
        "saliency_map_bs = np.reshape(saliency_map_bs, (-1, 1))\n",
        "print(f'saliency_map_bs shape: {saliency_map_bs.shape}')\n",
        "print(saliency_map_bs)\n",
        "print(saliency_map_underlying)\n",
        "\n",
        "# Sum of saliency map for underlying\n",
        "saliency_map_underlying_sum = np.sum(saliency_map_underlying)\n",
        "print(f'The sum of the saliency map for the underlying lags is: {saliency_map_underlying_sum}')\n",
        "# Sum of saliency map for bs\n",
        "saliency_map_bs_sum = np.sum(saliency_map_bs)\n",
        "print(f'The sum of the saliency map for the bs is: {saliency_map_bs_sum}')\n",
        "print(\"The proportion of the saliency map for the underlying lags is: \", saliency_map_underlying_sum / (saliency_map_underlying_sum + saliency_map_bs_sum))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "2qvgDT_UBP2K",
        "outputId": "965903ea-4b03-4f96-a169-1da99756ef0a"
      },
      "outputs": [
        {
          "ename": "SystemError",
          "evalue": "PY_SSIZE_T_CLEAN macro must be defined for '#' formats",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    340\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/backend_bases.py:2042\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2037\u001b[0m     \u001b[39m# call adjust_bbox to save only the given area\u001b[39;00m\n\u001b[1;32m   2038\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2039\u001b[0m         \u001b[39m# When bbox_inches == \"tight\", it saves the figure twice.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m         \u001b[39m# The first save command (to a BytesIO) is just to estimate\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m         \u001b[39m# the bounding box of the figure.\u001b[39;00m\n\u001b[0;32m-> 2042\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[1;32m   2043\u001b[0m             io\u001b[39m.\u001b[39;49mBytesIO(),\n\u001b[1;32m   2044\u001b[0m             dpi\u001b[39m=\u001b[39;49mdpi,\n\u001b[1;32m   2045\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[1;32m   2046\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[1;32m   2047\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[1;32m   2048\u001b[0m             dryrun\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2049\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2050\u001b[0m         renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_cachedRenderer\n\u001b[1;32m   2051\u001b[0m         bbox_artists \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbbox_extra_artists\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:522\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     metadata\u001b[39m.\u001b[39mupdate(user_metadata)\n\u001b[1;32m    520\u001b[0m \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(renderer, dpi\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdpi), \\\n\u001b[1;32m    521\u001b[0m         cbook\u001b[39m.\u001b[39mopen_file_cm(filename_or_obj, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fh:\n\u001b[0;32m--> 522\u001b[0m     _png\u001b[39m.\u001b[39;49mwrite_png(renderer\u001b[39m.\u001b[39;49m_renderer, fh,\n\u001b[1;32m    523\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi, metadata\u001b[39m=\u001b[39;49mmetadata)\n",
            "\u001b[0;31mSystemError\u001b[0m: PY_SSIZE_T_CLEAN macro must be defined for '#' formats"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "SystemError",
          "evalue": "PY_SSIZE_T_CLEAN macro must be defined for '#' formats",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    340\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
            "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/backend_bases.py:2042\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2037\u001b[0m     \u001b[39m# call adjust_bbox to save only the given area\u001b[39;00m\n\u001b[1;32m   2038\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2039\u001b[0m         \u001b[39m# When bbox_inches == \"tight\", it saves the figure twice.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m         \u001b[39m# The first save command (to a BytesIO) is just to estimate\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m         \u001b[39m# the bounding box of the figure.\u001b[39;00m\n\u001b[0;32m-> 2042\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[1;32m   2043\u001b[0m             io\u001b[39m.\u001b[39;49mBytesIO(),\n\u001b[1;32m   2044\u001b[0m             dpi\u001b[39m=\u001b[39;49mdpi,\n\u001b[1;32m   2045\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[1;32m   2046\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[1;32m   2047\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[1;32m   2048\u001b[0m             dryrun\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2049\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2050\u001b[0m         renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_cachedRenderer\n\u001b[1;32m   2051\u001b[0m         bbox_artists \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbbox_extra_artists\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:522\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     metadata\u001b[39m.\u001b[39mupdate(user_metadata)\n\u001b[1;32m    520\u001b[0m \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(renderer, dpi\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdpi), \\\n\u001b[1;32m    521\u001b[0m         cbook\u001b[39m.\u001b[39mopen_file_cm(filename_or_obj, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fh:\n\u001b[0;32m--> 522\u001b[0m     _png\u001b[39m.\u001b[39;49mwrite_png(renderer\u001b[39m.\u001b[39;49m_renderer, fh,\n\u001b[1;32m    523\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi, metadata\u001b[39m=\u001b[39;49mmetadata)\n",
            "\u001b[0;31mSystemError\u001b[0m: PY_SSIZE_T_CLEAN macro must be defined for '#' formats"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Saliency map for underlying history\n",
        "bs_variables = ['Underlying', 'Strike Price', 'Time to Maturity', 'Rent']\n",
        "plt.imshow(saliency_map_bs, cmap='viridis', aspect='auto')\n",
        "# Create axis ticks\n",
        "ax = plt.gca()\n",
        "plt.colorbar()\n",
        "plt.xlabel('Timesteps')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Saliency Map - Underlying History')\n",
        "plt.show()\n",
        "\n",
        "# Saliency map for underlying history\n",
        "lag_steps = [x for x in range(-max_timesteps, 0)]\n",
        "plt.imshow(saliency_map_underlying, cmap='viridis', aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.yticks(range(len(lag_steps)), lag_steps)\n",
        "#ax = plt.gca()\n",
        "#ax.yaxis.set_major_locator(ticker.MultipleLocator(base=5))\n",
        "plt.xlabel('Timesteps')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
