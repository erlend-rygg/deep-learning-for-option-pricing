{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 Run\n",
    "This file takes in the file written as a .csv from naive.ipynb. The output is used by compare.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 12:49:38.419456: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from math import log, sqrt, pi, exp\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    \"\"\"Read a single file and return a dataframe\"\"\"\n",
    "    return pd.read_csv(file, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = '../data/processed_data/2010-2022_filtered.csv'\n",
    "df = pd.read_csv(file, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Quote_date</th>\n",
       "      <th>Expire_date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Underlying_last</th>\n",
       "      <th>Strike</th>\n",
       "      <th>TTM</th>\n",
       "      <th>R</th>\n",
       "      <th>Moneyness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>207.490</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>925.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.224854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>182.500</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>950.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.192621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>157.500</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>975.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.162041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>132.600</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.132990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>107.705</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.105356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895723</th>\n",
       "      <td>13536141</td>\n",
       "      <td>13536141</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>362.600</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>721</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.892979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895724</th>\n",
       "      <td>13536142</td>\n",
       "      <td>13536142</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>319.150</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>721</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.872684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895725</th>\n",
       "      <td>13536143</td>\n",
       "      <td>13536143</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>279.000</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>721</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.853291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895726</th>\n",
       "      <td>13536144</td>\n",
       "      <td>13536144</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>241.950</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>721</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.834741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895727</th>\n",
       "      <td>13536145</td>\n",
       "      <td>13536145</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2024-12-20</td>\n",
       "      <td>208.800</td>\n",
       "      <td>3839.81</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>721</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.816981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11895728 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0.1  Unnamed: 0  Quote_date Expire_date    Price  \\\n",
       "0                    0           0  2010-01-04  2010-01-07  207.490   \n",
       "1                    1           1  2010-01-04  2010-01-07  182.500   \n",
       "2                    2           2  2010-01-04  2010-01-07  157.500   \n",
       "3                    3           3  2010-01-04  2010-01-07  132.600   \n",
       "4                    4           4  2010-01-04  2010-01-07  107.705   \n",
       "...                ...         ...         ...         ...      ...   \n",
       "11895723      13536141    13536141  2022-12-30  2024-12-20  362.600   \n",
       "11895724      13536142    13536142  2022-12-30  2024-12-20  319.150   \n",
       "11895725      13536143    13536143  2022-12-30  2024-12-20  279.000   \n",
       "11895726      13536144    13536144  2022-12-30  2024-12-20  241.950   \n",
       "11895727      13536145    13536145  2022-12-30  2024-12-20  208.800   \n",
       "\n",
       "          Underlying_last  Strike  TTM     R  Moneyness  \n",
       "0                 1132.99   925.0    3  0.05   1.224854  \n",
       "1                 1132.99   950.0    3  0.05   1.192621  \n",
       "2                 1132.99   975.0    3  0.05   1.162041  \n",
       "3                 1132.99  1000.0    3  0.05   1.132990  \n",
       "4                 1132.99  1025.0    3  0.05   1.105356  \n",
       "...                   ...     ...  ...   ...        ...  \n",
       "11895723          3839.81  4300.0  721  4.41   0.892979  \n",
       "11895724          3839.81  4400.0  721  4.41   0.872684  \n",
       "11895725          3839.81  4500.0  721  4.41   0.853291  \n",
       "11895726          3839.81  4600.0  721  4.41   0.834741  \n",
       "11895727          3839.81  4700.0  721  4.41   0.816981  \n",
       "\n",
       "[11895728 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "garch = False\n",
    "rolling_avg = False\n",
    "implied_vol = True\n",
    "test_pq = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_pq:\n",
    "    # Assuming your dataframe is named `df`\n",
    "    df_unique_dates = df[['Quote_date', 'Underlying_last']].drop_duplicates()\n",
    "\n",
    "    df_unique_dates['log_returns'] = np.log(df_unique_dates['Underlying_last']) - np.log(df_unique_dates['Underlying_last'].shift(1))\n",
    "    df_unique_dates = df_unique_dates[['Quote_date', 'log_returns']].dropna()\n",
    "\n",
    "    # Define a function to fit GARCH models and return AIC and BIC\n",
    "    def fit_garch_aic_bic(log_returns, p, q):\n",
    "        model = arch_model(log_returns, vol='Garch', p=p, q=q, dist='Normal')\n",
    "        results = model.fit(disp='off')\n",
    "        return results.aic, results.bic\n",
    "\n",
    "    # Test GARCH models with different p and q values\n",
    "    pq_values = [(1, 1), (1, 2), (2, 1), (2, 2), (1, 3), (3, 1), (2, 3), (3, 2), (3, 3), (4, 1), (1, 4), (4, 2), (2, 4), (4, 4)]\n",
    "\n",
    "    aic_bic_values = [fit_garch_aic_bic(df_unique_dates['log_returns'], p, q) for p, q in pq_values]\n",
    "    aic_values, bic_values = zip(*aic_bic_values)\n",
    "\n",
    "    # Find the best p and q values based on AIC and BIC\n",
    "    best_pq_aic = pq_values[np.argmin(aic_values)]\n",
    "    best_pq_bic = pq_values[np.argmin(bic_values)]\n",
    "    print(f\"Best GARCH model based on AIC: GARCH({best_pq_aic[0]},{best_pq_aic[1]})\")\n",
    "    print(f\"Best GARCH model based on BIC: GARCH({best_pq_bic[0]},{best_pq_bic[1]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if garch:\n",
    "    df_unique_dates = df[['Quote_date', 'Underlying_last']].drop_duplicates()\n",
    "\n",
    "    df_unique_dates['log_returns'] = np.log(df_unique_dates['Underlying_last']) - np.log(df_unique_dates['Underlying_last'].shift(1))\n",
    "    df_unique_dates = df_unique_dates[['Quote_date', 'log_returns']].dropna()\n",
    "\n",
    "    # Define GARCH(1,1) model\n",
    "    model = arch_model(df_unique_dates['log_returns'], vol='Garch', p=1, q=1, dist='Normal')\n",
    "\n",
    "    # Fit the model\n",
    "    results = model.fit(update_freq=5)\n",
    "\n",
    "    # Predict the volatility (annualized)\n",
    "    df_unique_dates['predicted_volatility'] =  results.conditional_volatility * np.sqrt(252)\n",
    "\n",
    "    # Merge the predicted volatility with the original dataframe\n",
    "    df = df.merge(df_unique_dates[['Quote_date', 'predicted_volatility']], on='Quote_date', how='left')\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rolling_avg:    \n",
    "    # Add volatility column with 30 day rolling standard deviation of Underlying_last\n",
    "\n",
    "    # New dataframe without duplicate Quote_dates\n",
    "    df2 = df.drop_duplicates(subset=['Quote_date'])\n",
    "\n",
    "    # Calculate volatility\n",
    "    df2['rolling_volatility'] = np.log(df2[\"Underlying_last\"] / df2[\"Underlying_last\"].shift()).rolling(30).std()*(252**0.5)\n",
    "\n",
    "    # Matching volatility in df2 to df\n",
    "    df['rolling_volatility'] = df['Quote_date'].map(df2.set_index('Quote_date')['rolling_volatility'])\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implied vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/x86_p6511l95p594k6qnb98h0000gn/T/ipykernel_15602/3418861453.py:8: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5 * vol**2) * T) / (vol * np.sqrt(T))\n",
      "/var/folders/wk/x86_p6511l95p594k6qnb98h0000gn/T/ipykernel_15602/3418861453.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  d1 = (np.log(S/K) + (r + 0.5 * vol**2) * T) / (vol * np.sqrt(T))\n"
     ]
    }
   ],
   "source": [
    "if implied_vol:\n",
    "    import numpy as np\n",
    "    from scipy.stats import norm\n",
    "    from scipy.optimize import brentq\n",
    "\n",
    "    def implied_volatility(target_value, S, K, T, r):\n",
    "        def option_price(vol):\n",
    "            d1 = (np.log(S/K) + (r + 0.5 * vol**2) * T) / (vol * np.sqrt(T))\n",
    "            d2 = d1 - vol * np.sqrt(T)\n",
    "            return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2) - target_value\n",
    "        try:\n",
    "            return brentq(option_price, 1e-6, 1)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    # Apply the function to the DataFrame\n",
    "    df['Implied_volatility'] = df.apply(lambda row: implied_volatility(row['Price'], row['Underlying_last'], row['Strike'], row['TTM'], row['R']), axis=1)\n",
    "    len_before = len(df)\n",
    "    df = df.dropna()\n",
    "    len_after = len(df)\n",
    "    print(f\"Number of rows dropped: {len_before - len_after}, which is {round((len_before - len_after)/len_before*100, 2)}% of the original dataframe\")\n",
    "\n",
    "    # Calculate the average implied volatility for each date\n",
    "    avg_implied_vol_df = df.groupby('Quote_date')['Implied_volatility'].mean().reset_index()\n",
    "\n",
    "    # Add a new column with the average implied volatility shifted by one row\n",
    "    avg_implied_vol_df['avg_implied_vol_t-1'] = avg_implied_vol_df['Implied_volatility'].shift(1)\n",
    "\n",
    "    # Merge the avg_implied_vol_df DataFrame back to the original df DataFrame\n",
    "    df = df.merge(avg_implied_vol_df[['Quote_date', 'avg_implied_vol_t-1']], on='Quote_date', how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-Scholes formula for call options\n",
    "def d1(S,K,T,r,sigma):\n",
    "    x1 = S.apply(lambda x : log(x)) - K.apply(lambda x : log(x))\n",
    "    x2 = (r + ((sigma.apply(lambda x : x**2)) / 2)) * T\n",
    "    x3 = sigma * T.apply(lambda x: sqrt(x))\n",
    "    return  (x1 + x2) / x3\n",
    "\n",
    "def d2(S,K,T,r,sigma):\n",
    "    return d1(S,K,T,r,sigma) - sigma * T.apply(lambda x : sqrt(x))  \n",
    "\n",
    "def bs_call(S,K,T,r,sigma):\n",
    "    T = T/365\n",
    "    r = r/100\n",
    "    return S * d1(S,K,T,r,sigma).apply(lambda x : norm.cdf(x)) - K * (-r*T).apply(lambda x : exp(x)) * d2(S,K,T,r,sigma).apply(lambda x : norm.cdf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rolling_avg:\n",
    "    df[\"Volatility\"] = df[\"rolling_volatility\"]\n",
    "if garch:\n",
    "    df[\"Volatility\"] = df[\"predicted_volatility\"]\n",
    "if implied_vol:\n",
    "    df[\"Volatility\"] = df[\"avg_implied_vol_t-1\"]\n",
    "    \n",
    "df[\"BS\"] = bs_call(df[\"Underlying_last\"], df[\"Strike\"], df[\"TTM\"], df[\"R\"], df[\"Volatility\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for full period 66.07943242950758\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE for full period\", np.sqrt(np.mean((df['BS'] - df['Price'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "df.to_csv('../data/predictions/BS_IV_avg.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
