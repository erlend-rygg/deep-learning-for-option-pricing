{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path, filenames):\n",
    "    \"\"\"Reads all files and returns a dataframe\"\"\"\n",
    "    return pd.concat((pd.read_csv(path + f, skipinitialspace=True) for f in filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_opt = \"./data/raw_data/\"\n",
    "filenames_opt = [\"spx_eod_\" + str(year) + (str(month) if month >= 10 else \"0\" + str(month)) + \".csv\" for year in range(2020, 2022) for month in range(1, 13)] + [\"spx_eod_2022\" + (str(month) if month >= 10 else \"0\" + str(month)) + \".csv\" for month in range(1, 13)]\n",
    "df = read_files(path_opt, filenames_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5919382\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_options(df_opt, call = True):\n",
    "    \"\"\"Cleans up column names and add time to maturity (TTM)\"\"\"\n",
    "    keys = {key: key[key.find(\"[\")+1:key.find(\"]\")][0] + key[key.find(\"[\")+1:key.find(\"]\")][1:].lower()  for key in df_opt.keys()}\n",
    "    df_opt = df_opt.rename(columns=keys)\n",
    "\n",
    "    if call:\n",
    "        keys = {\"C_ask\": \"Ask\", \"C_bid\": \"Bid\"}\n",
    "    else:\n",
    "        keys = {\"P_ask\": \"Ask\", \"P_bid\": \"Bid\"}\n",
    "    df_opt = df_opt.rename(columns=keys)\n",
    "\n",
    "    df_opt[\"Quote_date\"] = pd.to_datetime(df_opt[\"Quote_date\"])\n",
    "    df_opt[\"Expire_date\"] = pd.to_datetime(df_opt[\"Expire_date\"])\n",
    "    df_opt[\"TTM\"] = df_opt.apply(lambda row: (row.Expire_date - row.Quote_date).days, axis = 1)\n",
    "    df_opt[\"Price\"] = (df_opt[\"Ask\"] + df_opt[\"Bid\"])/2\n",
    "\n",
    "    columns = [\"Quote_date\", \"Expire_date\", \"Price\", \"Underlying_last\", \"Strike\", \"TTM\"]\n",
    "    df_opt = df_opt[columns]\n",
    "    df_opt = df_opt[(df_opt[\"TTM\"] != 0) & (df_opt[\"TTM\"] <= 365*3)]\n",
    "    return df_opt[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1026 rows in by dropping NaNs of processed options\n"
     ]
    }
   ],
   "source": [
    "df = process_options(df)\n",
    "\n",
    "# Remove NaNs\n",
    "df_len_before = len(df)\n",
    "df = df.dropna()\n",
    "df_len_after = len(df)\n",
    "print(\"Dropped \" + str(df_len_before - df_len_after) + \" rows in by dropping NaNs of processed options\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quote_date']= pd.to_datetime(df['Quote_date'])\n",
    "df[\"Moneyness\"] = df.apply(lambda row: row.Underlying_last/row.Strike, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/x86_p6511l95p594k6qnb98h0000gn/T/ipykernel_96250/821960197.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_agg = df.groupby('Quote_date').mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Group the data by Quote Date and calculate the mean for Underlying Price\n",
    "df_agg = df.groupby('Quote_date').mean().reset_index()\n",
    "\n",
    "# Values to returns\n",
    "df_agg[\"Underlying_return\"] = df_agg[\"Underlying_last\"].pct_change()\n",
    "\n",
    "lags = 90\n",
    "\n",
    "# Add the Underlying Price Lag column\n",
    "for i in range(1, lags + 1):\n",
    "    df_agg['Underlying_' + str(i)] = df_agg['Underlying_return'].shift(i)\n",
    "\n",
    "df = pd.merge(df, df_agg[['Quote_date', \"Underlying_return\"] + ['Underlying_' + str(i) for i in range(1, lags + 1)]], on='Quote_date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(\"2021-01-01\")\n",
    "df = df[df['Quote_date'] >= start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows in removing NaNs after lagging\n"
     ]
    }
   ],
   "source": [
    "df_len_before = len(df)\n",
    "df = df.dropna()\n",
    "df_len_after = len(df)\n",
    "print(\"Dropped \" + str(df_len_before - df_len_after) + \" rows in removing NaNs after lagging\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rates(df_r):\n",
    "    \"\"\"Renames rate duration\"\"\"\n",
    "    df_r[\"Date\"] = pd.to_datetime(df_r[\"Date\"])\n",
    "    keys = {  \"Date\" : \"Quote_date\",\n",
    "                                    \"1 Mo\": 30,\n",
    "                                    \"3 Mo\": 90,\n",
    "                                    \"6 Mo\": 180,\n",
    "                                    \"1 Yr\": 365,\n",
    "                                    \"2 Yr\": 365*2,\n",
    "                                    \"3 Yr\": 365*3,\n",
    "                                    \"5 Yr\": 365*5,\n",
    "                                    \"7 Yr\": 365*7,\n",
    "                                    \"10 Yr\": 365*10}\n",
    "    df_r = df_r.rename(columns = keys)\n",
    "    return df_r[keys.values()]\n",
    "\n",
    "def combine_opt_rates(df_opt, df_r):\n",
    "    df_opt = pd.merge(df_opt, df_r, on =\"Quote_date\", how = \"left\")\n",
    "    rates = list(df_r.columns)\n",
    "    rates.remove(\"Quote_date\")\n",
    "    df_opt[\"TTM_diff\"] = df_opt[\"TTM\"].apply(lambda x: (np.abs(np.array(rates) - x)).argmin())\n",
    "    df_opt[\"R\"] = df_opt[[\"TTM_diff\"] + rates].values.tolist()\n",
    "    df_opt[\"R\"] = df_opt[\"R\"].apply(lambda x: x[int(x[0]+1)])\n",
    "    df_opt = df_opt.drop(rates + [\"TTM_diff\"], axis=1)\n",
    "    df_opt_len_before = len(df_opt)\n",
    "    df_opt = df_opt.dropna()\n",
    "    df_opt_len_after = len(df_opt)\n",
    "    print(\"Dropped \" + str(df_opt_len_before - df_opt_len_after) + \" rows in rate matching\")\n",
    "    return df_opt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 104119 rows in rate matching\n"
     ]
    }
   ],
   "source": [
    "df_r = pd.concat((pd.read_csv(\"./data/raw_data/\" + f, skipinitialspace=True) for f in [\"daily-treasury-rates.csv\", \"yield-curve-rates-1990-2021.csv\"]))\n",
    "df_r = process_rates(df_r)\n",
    "df = combine_opt_rates(df, df_r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/processed_data/2021_2022.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
