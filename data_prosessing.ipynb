{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path, filenames):\n",
    "    \"\"\"Reads all files and returns a dataframe\"\"\"\n",
    "    return pd.concat((pd.read_csv(path + f, skipinitialspace=True) for f in filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_opt = \"./data/raw_data/\"\n",
    "filenames_opt = [\"spx_eod_\" + str(year) + (str(month) if month >= 10 else \"0\" + str(month)) + \".csv\" for year in range(2010, 2022) for month in range(1, 13)] + [\"spx_eod_2022\" + (str(month) if month >= 10 else \"0\" + str(month)) + \".csv\" for month in range(1, 13)]\n",
    "df = read_files(path_opt, filenames_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_after_first_read = len(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_options(df_opt, call = True):\n",
    "    \"\"\"Cleans up column names and add time to maturity (TTM)\"\"\"\n",
    "    keys = {key: key[key.find(\"[\")+1:key.find(\"]\")][0] + key[key.find(\"[\")+1:key.find(\"]\")][1:].lower()  for key in df_opt.keys()}\n",
    "    df_opt = df_opt.rename(columns=keys)\n",
    "\n",
    "    if call:\n",
    "        keys = {\"C_ask\": \"Ask\", \"C_bid\": \"Bid\"}\n",
    "    else:\n",
    "        keys = {\"P_ask\": \"Ask\", \"P_bid\": \"Bid\"}\n",
    "    df_opt = df_opt.rename(columns=keys)\n",
    "\n",
    "    df_opt[\"Quote_date\"] = pd.to_datetime(df_opt[\"Quote_date\"])\n",
    "    df_opt[\"Expire_date\"] = pd.to_datetime(df_opt[\"Expire_date\"])\n",
    "    df_opt[\"TTM\"] = df_opt.apply(lambda row: (row.Expire_date - row.Quote_date).days, axis = 1)\n",
    "    df_opt[\"Price\"] = (df_opt[\"Ask\"] + df_opt[\"Bid\"])/2\n",
    "\n",
    "    columns = [\"Quote_date\", \"Expire_date\", \"Price\", \"Underlying_last\", \"Strike\", \"TTM\"]\n",
    "    df_opt = df_opt[columns]\n",
    "    return df_opt[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_options(df)\n",
    "len_after_process = len(df)\n",
    "\n",
    "df = df.dropna()\n",
    "len_after_nan = len(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rates(df_r):\n",
    "    \"\"\"Renames rate duration\"\"\"\n",
    "    df_r[\"Date\"] = pd.to_datetime(df_r[\"Date\"])\n",
    "    keys = {  \"Date\" : \"Quote_date\",\n",
    "                                    \"1 Mo\": 30,\n",
    "                                    \"3 Mo\": 90,\n",
    "                                    \"6 Mo\": 180,\n",
    "                                    \"1 Yr\": 365,\n",
    "                                    \"2 Yr\": 365*2,\n",
    "                                    \"3 Yr\": 365*3,\n",
    "                                    \"5 Yr\": 365*5,\n",
    "                                    \"7 Yr\": 365*7,\n",
    "                                    \"10 Yr\": 365*10}\n",
    "    df_r = df_r.rename(columns = keys)\n",
    "    return df_r[keys.values()]\n",
    "\n",
    "def combine_opt_rates(df_opt, df_r):\n",
    "    df_opt = pd.merge(df_opt, df_r, on =\"Quote_date\", how = \"left\")\n",
    "    rates = list(df_r.columns)\n",
    "    rates.remove(\"Quote_date\")\n",
    "    df_opt[\"TTM_diff\"] = df_opt[\"TTM\"].apply(lambda x: (np.abs(np.array(rates) - x)).argmin())\n",
    "    df_opt[\"R\"] = df_opt[[\"TTM_diff\"] + rates].values.tolist()\n",
    "    df_opt[\"R\"] = df_opt[\"R\"].apply(lambda x: x[int(x[0]+1)])\n",
    "    df_opt = df_opt.drop(rates + [\"TTM_diff\"], axis=1)\n",
    "    df_opt = df_opt.ffill()\n",
    "    df_opt_len_before = len(df_opt)\n",
    "    df_opt = df_opt.dropna()\n",
    "    df_opt_len_after = len(df_opt)\n",
    "    print(\"Dropped \" + str(df_opt_len_before - df_opt_len_after) + \" rows in rate matching\")\n",
    "    return df_opt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows in rate matching\n"
     ]
    }
   ],
   "source": [
    "df_r = pd.concat((pd.read_csv(\"./data/raw_data/\" + f, skipinitialspace=True) for f in [\"daily-treasury-rates.csv\", \"yield-curve-rates-1990-2021.csv\"]))\n",
    "df_r = process_rates(df_r)\n",
    "df = combine_opt_rates(df, df_r)\n",
    "len_after_rate_matching = len(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing lost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 13547394 rows, and ended up with 13536349 rows\n",
      "Dropped 11045 rows in total\n",
      "Which is 0.08%\n",
      "0 rows dropped in process_options\n",
      "11045 rows dropped in dropna\n",
      "0 rows dropped in rate matching\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting with \" + str(len_after_first_read) + \" rows, and ended up with \" + str(len_after_rate_matching) + \" rows\")\n",
    "print(\"Dropped \" + str(len_after_first_read - len_after_rate_matching) + \" rows in total\")\n",
    "print(\"Which is \" + str(round((len_after_first_read - len_after_rate_matching)/len_after_first_read*100, 2)) + \"%\")\n",
    "print(len_after_first_read-len_after_process, \"rows dropped in process_options\")\n",
    "print(len_after_process-len_after_nan, \"rows dropped in dropna\")\n",
    "print(len_after_nan-len_after_rate_matching, \"rows dropped in rate matching\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/processed_data/2010-2022.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
